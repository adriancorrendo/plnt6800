{
  "hash": "e5744a0cfd74ff229d4732a86559780d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Models IV: Mixed Models II\"\nauthor: \"Dr. Adrian Correndo\"\ndate: \"2025-03-12\"\ncategories: [linear models, R, statistics, agriculture]\nabstract-title: 'Summary'\nabstract: 'This tutorial provides a tidy workflow to analyze another case of common mixed model in agriculture: Repeated-measures.'\nformat:\n  html:\n    toc: true\n    toc-location: left\n    toc-depth: 4\n    number-sections: true\n    table-class: \"table table-striped table-hover\"\neditor: source\nexecute:\n  echo: true\n  warning: false\n  message: false\nsmooth-scroll: true\nbibliography: references.bib\nlink-citations: TRUE\n---\n\n\n\n\n\n\n# What are repeated measures models?\n\nRepeated measures models are a type of statistical model used when the same experimental unit is measured multiple times under different conditions or over time. These models account for the fact that repeated observations from the same unit (e.g., plant, plot, soil location) are not independent but correlated.\n\nIn agriculture, repeated measures designs are common in various scenarios, including:\n\n\t•\tTime-based measurements: Tracking crop growth, soil nutrients, or yield over multiple time points. Or also treatments applied to the same unit over time such as fertilization trials where the same plots receive different treatments over multiple years.\n\t•\tSpatially repeated measurements: Soil properties at different depths, plant characteristics at multiple canopy levels, or yield components across field zones.\n\n## Mixed Models for Repeated Measures\n\nLinear mixed models (LMMs) are typically used for analyzing repeated measures because they allow us to include:\n\t1.\tFixed effects – Factors of interest, such as treatments, depths, or environmental conditions.\n\t2.\tRandom effects – Sources of variability, such as plot-to-plot differences or repeated observations on the same soil core.\n\n# Case Study\n\nToday, we are going to reproduce the analysis I've performed myself for one of my publications few years ago [@correndo2021]. Particularly, we are going to reproduce [**Figure 2**](https://www.nature.com/articles/s41598-021-90297-1#Fig2)\n\n![](images/paste-26DDB04C.png)\n\nFor this paper, we have data from 4 different locations. We tested the levels of soil potassium fertility, hereinafter as soil test K (STK), in long-term experiments (2000-2009) where the treatments of interest were: (i) Control (unfertilized), (ii) NPS (fertilized with NPS), and (iii) Pristine conditions (No Ag-history).\n\nAt each plot/sample, the STK was measured at five-consecutive soil depths (0-20, 20-40, 40-60, 60-80, and 80-100 cm). Thus, they we took \"repeated measurements\" over the space.\n\nWe were NOT interested in comparing locations since they had very different previous history, and crop rotation, so confounding effects may have obscured the inference. Therefore, site was not a factor under consideration, and all the analysis were fitted independently by site.\n\n## Required packages for today\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pacman)\np_load(\"readxl\") # To open/save excel files\np_load('dplyr', \"tidyr\",\"purrr\", \"forcats\", \"stringr\") # Data wrangling\np_load(\"nlme\", \"lme4\") # Mixed models libraries\np_load(\"broom\", \"broom.mixed\") # Managing models results\np_load(\"performance\") # Check assumptions and performance\np_load(\"emmeans\",\"multcomp\",\"multcompView\",\n         \"car\", \"multilevelmod\") # Aov and mult comp\np_load(\"ggplot2\") # Figures\np_load(\"agricolae\") # Miscellaneous functions\np_load(\"agridat\") # For data\n```\n:::\n\n\n\n\n## Data\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read data\n# File online? Try this...\nurl_rm <- \"https://raw.githubusercontent.com/adriancorrendo/tidymixedmodelsweb/refs/heads/master/data/02_repeated_measures_data.csv\"\n\n# Read file\nrm_data_00 <- \n  read.csv(url_rm) \n\nrm_data_01 <- \n  rm_data_00 %>% \n  # We need to create PLOT column to identify subject (Exp. Unit for Rep. Measures)\n  ## Option 1, use \"unite\"\n  unite(data = ., col = PLOT, BLOCK,TREAT, sep = \"_\", remove=FALSE) %>%\n  # OR\n  ## Option 2, use cur_group_id\n  # Identify Subplot\n  ungroup() %>% \n  group_by(BLOCK, TREAT) %>% # Don't need to add SITE here\n  # Create unique plot ID # Needed for Repeated Measures\n  mutate(plot = cur_group_id(), .after = PLOT) %>% \n  ungroup() %>% \n  ## Transform to factor if needed\n  mutate(depth = as.integer(DEPTH), # Needed for CorAR1\n         DEPTH = as.factor(DEPTH),\n         plot = factor(plot),\n         BLOCK = factor(BLOCK),\n         SITE = factor(SITE), \n                       #levels = c(\"site_1\", \"site_2\", \"site_3\", \"site_4\"), \n                       #labels = c(\"Balducchi\", \"San Alfredo\", \"La Blanca\", \"La Hansa\")\n         TREAT = factor(TREAT)\n         )\n```\n:::\n\n\n\n\n## Exploratory analysis\n\nNow, let's use several functions to explore the data.\n\n### glimpse()\n\nFirst, the `glimpse()` function from dplyr\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Glimpse from dplyr\ndplyr::glimpse(rm_data_01)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 180\nColumns: 8\n$ SITE  <fct> site_1, site_1, site_1, site_1, site_1, site_1, site_1, site_1, …\n$ PLOT  <chr> \"I_Control\", \"I_Control\", \"I_Control\", \"I_Control\", \"I_Control\",…\n$ plot  <fct> 1, 1, 1, 1, 1, 4, 4, 4, 4, 4, 7, 7, 7, 7, 7, 2, 2, 2, 2, 2, 5, 5…\n$ TREAT <fct> Control, Control, Control, Control, Control, Control, Control, C…\n$ BLOCK <fct> I, I, I, I, I, II, II, II, II, II, III, III, III, III, III, I, I…\n$ DEPTH <fct> 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, …\n$ STK   <int> 105, 83, 103, 110, 127, 119, 98, 106, 107, 109, 132, 100, 96, 10…\n$ depth <int> 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, 30, 50, 70, 90, 10, …\n```\n\n\n:::\n:::\n\n\n\n\n### skim()\n\nThen, the `skim()` function from skmir\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Skim from skimr\nskimr::skim(rm_data_01)\n```\n\n::: {.cell-output-display}\n\nTable: Data summary\n\n|                         |           |\n|:------------------------|:----------|\n|Name                     |rm_data_01 |\n|Number of rows           |180        |\n|Number of columns        |8          |\n|_______________________  |           |\n|Column type frequency:   |           |\n|character                |1          |\n|factor                   |5          |\n|numeric                  |2          |\n|________________________ |           |\n|Group variables          |None       |\n\n\n**Variable type: character**\n\n|skim_variable | n_missing| complete_rate| min| max| empty| n_unique| whitespace|\n|:-------------|---------:|-------------:|---:|---:|-----:|--------:|----------:|\n|PLOT          |         0|             1|   5|  12|     0|        9|          0|\n\n\n**Variable type: factor**\n\n|skim_variable | n_missing| complete_rate|ordered | n_unique|top_counts                         |\n|:-------------|---------:|-------------:|:-------|--------:|:----------------------------------|\n|SITE          |         0|             1|FALSE   |        4|sit: 45, sit: 45, sit: 45, sit: 45 |\n|plot          |         0|             1|FALSE   |        9|1: 20, 2: 20, 3: 20, 4: 20         |\n|TREAT         |         0|             1|FALSE   |        3|Con: 60, NPS: 60, Pri: 60          |\n|BLOCK         |         0|             1|FALSE   |        3|I: 60, II: 60, III: 60             |\n|DEPTH         |         0|             1|FALSE   |        5|10: 36, 30: 36, 50: 36, 70: 36     |\n\n\n**Variable type: numeric**\n\n|skim_variable | n_missing| complete_rate|   mean|    sd| p0|    p25| p50|    p75| p100|hist  |\n|:-------------|---------:|-------------:|------:|-----:|--:|------:|---:|------:|----:|:-----|\n|STK           |         0|             1| 181.84| 63.09| 74| 138.75| 174| 221.25|  406|▅▇▅▂▁ |\n|depth         |         0|             1|  50.00| 28.36| 10|  30.00|  50|  70.00|   90|▇▇▇▇▇ |\n\n\n:::\n:::\n\n\n\n\n### ggplot()\n\nAnd let's use ggplot2 for a better look\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Boxplot\nrm_data_01 %>% \n  dplyr::select(-depth) %>% \n  # Plot\nggplot() + \n  # Boxplots\n  geom_boxplot(aes(x = reorder(DEPTH, desc(DEPTH)), y = STK, fill = TREAT))+\n  # Axis labels\n  labs(x = \"Soil depth (cm)\", y = \"STK (g/m2)\")+\n  # Plot by site\n  facet_wrap(~SITE)+\n  # Flip axes\n  coord_flip()+\n  # Set scale type\n  scale_x_discrete()+\n  # Change theme\n  tidybayes::theme_tidybayes()\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/rm_ggplot-1.png){width=672}\n:::\n:::\n\n\n\n\n### Additional data manipulation?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrm_data_02 <-rm_data_01 %>% \n  # Create a grouping variable (WHY?) # Needed for HetVar\n  mutate(GROUP = case_when(TREAT == \"Pristine\" ~ \"Pristine\",\n                           TRUE ~ \"Agriculture\"))\n```\n:::\n\n\n\n\n\n## Candidate Models\n\nI'm sorry for this, but the most important step is ALWAYS to write down the model.\n\n### Formulae\n\n#### m0. Block Fixed\n\nIn a traditional approach blocks are defined as fixed, affecting the mean of the expected value. Yet there is no consensus about treating blocks as fixed or as random. For more information, read @Dixon_2016.\n\nLet's define the model. For simplification (and avoid writing interaction terms), here we are going to consider that $\\tau_i$ is the \"treatment\".\n\n$$ y_{ij} = \\mu + \\tau_i + \\beta_j + \\epsilon_{ij} $$\n\n$$ \\epsilon_{ij} \\sim N(0, \\sigma^2_{e} )$$ where $\\mu$ represents the overall mean (if intercept is used), $\\tau_i$ is the effect of treatment-j over $\\mu$, $\\beta_j$ is the effect of block-j over $\\mu$, and $\\epsilon_{ij}$ is the random effect of each experimental unit.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# SIMPLEST MODEL\nfit_block_fixed <- function(x){\n  lm(# Response variable\n     STK ~ \n       # Fixed\n       TREAT + DEPTH + TREAT:DEPTH + BLOCK,\n     # Data\n     data = x)\n  }\n```\n:::\n\n\n\n\n#### m1. Block Random\n\nAn alternative approach is considering a MIXED MODEL, where blocks are considered \"random\". Basically, we add a term to the model that it is expected to show a \"null\" overall effect over the mean of the variable of interest but introduces \"noise\". By convention, a random effect is expected to have an expected value equal to zero but a positive variance as follows: $$ y_{ij} = \\mu + \\tau_i + \\beta_j + \\epsilon_{ij} $$ $$ \\beta_j \\sim N(0, \\sigma^2_{b} )$$ $$ \\epsilon_{ij} \\sim N(0, \\sigma^2_{e} )$$ Similar than before, $\\mu$ represents the overall mean (if intercept is used), $\\tau_i$ is the effect of treatment-j over $\\mu$, $\\beta_j$ is the \"random\" effect of block-j over $\\mu$, and $\\epsilon_{ij}$ is the random effect of each experimental unit.\n\nSo what's the difference? Simply specifying this component: $$ \\beta_j \\sim N(0, \\sigma^2_b) $$, which serves to model the variance.\n\nHow do we write that?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK\nfit_block_random <- function(x){\n  nlme::lme(\n    # Fixed\n    STK ~ TREAT + DEPTH + TREAT:DEPTH,\n    # Random\n    random = ~1|BLOCK,\n    # Data\n    data = x)\n  }\n```\n:::\n\n\n\n\n### Models w/ correlated ERRORS\n\nUntil here all sounds easy. However, we are (potentially) missing a key component. All measures involving DEPTH have been taken from the same \"subjects\" (experimental units/plots). So we do have \"repeated measures\" over space. Thus, it is highly likely that using depth implies the need to adjust the error correlation and covariance structure. Let's explore some options...\n\n#### m2. m1 + CompSymm\n\nCompound symmetry is the simplest covariance structure, where we include a within-subject correlated errors. It is basically the same we do with including BLOCKS as random. We are telling the model that the observations within a given \"depth\" \"share\" something, they have something in common (the error).\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/compound symmetry error correlation structure\nfit_corsymm <- function(x){\n  lme(# Response Variable\n      STK ~\n        # Fixed\n        TREAT + DEPTH + TREAT:DEPTH,\n        # Random\n        random = ~1|BLOCK,\n        # Identify subject where repeated measure happens\n        # Plots nested within blocks.\n        correlation = corCompSymm(form = ~ DEPTH |BLOCK/PLOT), \n     # Data   \n     data=x) }\n```\n:::\n\n\n\n\n#### m3. m1 + CorAR1\n\nThe autoregressive of first order structure (CorAR1) considers correlations dependent of the \"distance\". Thus, correlation of error is expected to be the highest between adjacent depths (e.g. 0-20 and 20-40 cm), and a systematically decrease with the distance. For example, the correlation between depth 1 and depth 2 would be $\\rho^{depth_2-depth_1}$, and then less and less, ending with the correlation between depth 5 and depth 1 equal to $\\rho^{depth_5-depth_1}$.\n\n::: callout-caution\nAn important detail here is that CorAR1 structure is only applicable for evenly spaced intervals!\n:::\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/ auto-regressive of 1st order as error correlation structure\nfit_ar1 <- function(x){lme(STK ~ TREAT + DEPTH + TREAT:DEPTH,\n                       random = ~1|BLOCK,\n                       correlation=corAR1(form=~depth|BLOCK/PLOT),\n                       data=x)}\n```\n:::\n\n\n\n\n#### m4. m2 + HetVar\n\nDid you know that we can \"relax\" the assumption about homogeneity of variance? Oftentimes we have data that shows different variability depending on the level of a given factor or variable.\n\nIn the STK dataset, we observed that the \"Pristine\" treatment (or agriculture condition) present a higher variability compared to Control and NPS treatments, probably linked to higher values of STK. Variance is modeled by adding a \"weight\". This \"weight\" could be a function of a continuous variable (e.g. fertilizer rate?) or, like in our case, based on a \"categorical\" variable.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# RANDOM BLOCK w/compound symmetry error correlation structure + Heterogeneous Variance\nfit_corsymm_hetvar <- function(x){\n  lme(# Response variable\n      STK ~ \n        # Fixed\n        TREAT + DEPTH + TREAT:DEPTH,\n        # Random  \n        random = ~1|BLOCK,\n        # Correlation\n        correlation = corCompSymm(form = ~ DEPTH |BLOCK/PLOT),\n        # Variance\n        weights = varComb(varIdent(form= ~1|GROUP)),\n      # Data\n      data=x) }\n```\n:::\n\n\n\n\n### Fit\n\nRun the candidate models\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSTK_models <- \n  rm_data_02 %>% \n  # Let's group data to run multiple locations|datasets at once\n  group_by(SITE) %>% \n  # Store the data per location using nested arrangement\n  nest() %>% \n  # BLOCK as FIXED \n  mutate(model_0 = map(data, fit_block_fixed)) %>% \n  # BLOCK as RANDOM\n  mutate(model_1 = map(data, fit_block_random)) %>% \n  # COMPOUND SYMMETRY\n  mutate(model_2 = map(data, fit_corsymm)) %>% \n  # AUTO-REGRESSIVE ORDER 1\n  mutate(model_3 = map(data, fit_ar1)) %>% \n  # COMPOUND SYMMETRY + HETEROSKEDASTIC\n  mutate(model_4 = map(data,  fit_corsymm_hetvar) ) %>%\n    \n  # Data wrangling\n  pivot_longer(cols = c(model_0:model_4), # show alternative 'contains' model\n               names_to = \"model_id\",\n               values_to = \"model\") %>% \n  # Map over model column\n  mutate(results = map(model, broom.mixed::augment )) %>% \n  # Performance\n  mutate(performance = map(model, broom.mixed::glance )) %>% \n  # Extract AIC\n  mutate(AIC = map(performance, ~.x$AIC)) %>% \n  # Extract coefficients\n  mutate(coef = map(model, ~coef(.x))) %>% \n  # Visual-check plots\n  mutate(checks = map(model, ~performance::check_model(.))) %>% \n  ungroup()\n```\n:::\n\n\n\n\n### Check assumptions\n\nChecking assumptions is always important. To learn more about data exploration, tools to detect outliers, heterogeneity of variance, collinearity, dependence of observations, problems with interactions, among others, I highly recommend reading [@Zuur_etal_2010].\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Extracting by site\nsite_1_models <- STK_models %>% dplyr::filter(SITE == \"site_1\")\nsite_2_models <- STK_models %>% dplyr::filter(SITE == \"site_3\")\nsite_3_models <- STK_models %>% dplyr::filter(SITE == \"site_4\")\nsite_4_models <- STK_models %>% dplyr::filter(SITE == \"site_2\")\n```\n:::\n\n\n\n\n::: panel-tabset\n## Site 1\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_1_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/unnamed-chunk-2-1.png){width=576}\n:::\n:::\n\n\n\n\n## Site 2\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_2_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/unnamed-chunk-3-1.png){width=576}\n:::\n:::\n\n\n\n\n## Site 3\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_3_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/unnamed-chunk-4-1.png){width=576}\n:::\n:::\n\n\n\n\n## Site 4\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(site_4_models %>% dplyr::filter(model_id == \"model_0\"))$checks[[1]]\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/unnamed-chunk-5-1.png){width=576}\n:::\n:::\n\n\n\n:::\n\n### Model Selection\n\nCompare models performance\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Visual model selection\nbest_STK_models <- \n  STK_models %>% \n  group_by(SITE) %>% \n  # Use case_when to identify the best model\n  mutate(best_model = \n           case_when(AIC == min(as.numeric(AIC)) ~ \"Yes\",\n                     TRUE ~ \"No\")) %>% \n  ungroup()\n\n# Plot\nbest_STK_models %>% \n  ggplot()+\n  geom_point(aes(x = model_id, y = as.numeric(AIC), \n                 color = best_model, shape = best_model), \n             size = 3)+\n  facet_wrap(~SITE)\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/rm_selection-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# Final models\nselected_models <- best_STK_models %>% dplyr::filter(best_model == \"Yes\")\n```\n:::\n\n\n\n\n### ANOVA\n\nEstimate the effects of factors under study (and their interaction)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodels_effects <- \n  selected_models %>%\n  # Type 3 Sum of Squares (Partial SS, when interactions are present)\n  mutate(ANOVA = map(model, ~Anova(., type = 3)) )\n\n# Extract ANOVAS\nmodels_effects$ANOVA[[1]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: STK\n              Chisq Df Pr(>Chisq)    \n(Intercept) 326.261  1  < 2.2e-16 ***\nTREAT        39.994  2  2.067e-09 ***\nDEPTH        12.637  4   0.013191 *  \nTREAT:DEPTH  21.827  8   0.005247 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmodels_effects$ANOVA[[2]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: STK\n              Chisq Df Pr(>Chisq)    \n(Intercept) 794.721  1  < 2.2e-16 ***\nTREAT        21.394  2  2.261e-05 ***\nDEPTH        67.224  4  8.743e-14 ***\nTREAT:DEPTH  52.957  8  1.099e-08 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmodels_effects$ANOVA[[3]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: STK\n             Chisq Df Pr(>Chisq)    \n(Intercept) 84.604  1  < 2.2e-16 ***\nTREAT       50.791  2  9.353e-12 ***\nDEPTH       42.200  4  1.516e-08 ***\nTREAT:DEPTH 21.773  8   0.005355 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n\n```{.r .cell-code}\nmodels_effects$ANOVA[[4]]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nAnalysis of Deviance Table (Type III tests)\n\nResponse: STK\n              Chisq Df Pr(>Chisq)    \n(Intercept) 876.934  1  < 2.2e-16 ***\nTREAT       262.921  2  < 2.2e-16 ***\nDEPTH        22.364  4  0.0001696 ***\nTREAT:DEPTH 107.841  8  < 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n\n\n\n## Means comparison\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# MULTCOMPARISON\n# emmeans and cld multcomp\n# We need to specify ourselves the most important interaction to perform the comparisons\nmult_comp <- \n  models_effects %>% \n  # Comparisons estimates (emmeans)\n  mutate(mc_estimates = map(model, ~emmeans(., ~ TREAT*DEPTH))) %>% \n  # Assign letters and p-value adjustment (multcomp)\n  mutate(mc_letters = \n           map(mc_estimates, \n               ~as.data.frame( \n                 # By specifies a strata or level to assign the letters\n                 cld(., by = \"DEPTH\", decreasing = TRUE, details=FALSE,\n                     reversed=TRUE, alpha=0.05,  adjust = \"tukey\", Letters=LETTERS))))\n```\n:::\n\n\n\n\n## Plot\n\nNow, we are going to reproduce [**Figure 2**](https://www.nature.com/articles/s41598-021-90297-1#Fig2)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Create data frame for plot\nplot_df <- mult_comp %>% \n  dplyr::select(SITE, mc_letters) %>% \n  unnest(mc_letters)\n\n# Define your own colors\nmy_colors <- c(\"#ffaa00\", \"#7E5AA0\", \"#5c9c8c\")\n\n# Create the plot\nSTK_plot <-\n  plot_df %>% \n  # We need to re-express DEPTH from factor to character, and then to numeric\n  mutate(DEPTH = as.numeric(as.character(DEPTH)))  %>% \n  # Re-order levels of the factors\n  mutate(TREAT = fct_relevel(TREAT,\"Control\", \"NPS\", \"Pristine\")) %>% \n  mutate(SITE = fct_relevel(SITE,\"site_1\", \"site_2\", \"site_3\", \"site_4\")) %>% \n  # Create plot\n  ggplot()+\n  # 01. LAYOUT\n  ## Subplots\n  facet_wrap(~SITE, nrow = 2)+\n  ## Axis titles\n  labs(x = \"Soil depth (cm)\", y = bquote(~NH[4]*'OAc-K (g' ~m^-2*')'))+\n  # 02. GEOMETRIES\n  ## i. Points\n  geom_point(aes(x = DEPTH, y = emmean,\n                 fill= TREAT,\n                 shape = TREAT),\n             size = 3, col = \"black\")+\n  ## Adjust shape aesthetics\n  scale_shape_manual(name=\"Fertilizer Scenario\", values=c(24,23,21),\n                     guide=\"legend\")+\n  scale_colour_manual(name=\"Fertilizer Scenario\",\n                    values = my_colors,\n                    guide='legend')+\n  scale_fill_manual(name=\"Fertilizer Scenario\",\n                    values = my_colors,\n                    guide='legend')+\n  ## ii. Add error bar\n  geom_errorbar(width = 0.25, aes(x = DEPTH, color = TREAT, \n                                 ymin = emmean-2*SE, ymax = emmean+2*SE))+\n  ## iii. Add line\n  geom_line(size = 0.5,aes(x = DEPTH, y = emmean, color = TREAT))+\n  # 03. ADJUST XY AXIS\n  ## Reverse the scale\n  scale_x_reverse(breaks=seq(0, 100, 20), limits = c(100,0))+\n  coord_flip()+\n  # 04. THEME\n  theme_bw()+\n  theme(strip.text = element_text(size = rel(1.25)),\n        strip.background = element_blank(),\n        # Grid\n        panel.grid = element_blank(),\n        # Axis\n        axis.title = element_text(size = rel(1.5)),\n        axis.text = element_text(size = rel(1.25), color = \"black\"),\n        # Legend\n        legend.position = \"top\", legend.title = element_blank(),\n        legend.text = element_text(size = rel(1.25))        )\n\nSTK_plot\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/rm_plot-1.png){width=768}\n:::\n:::\n\n\n\n\n### Figure with caption\n\n::: {layout-col=\"1\"}\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nSTK_plot\n```\n\n::: {.cell-output-display}\n![](models_05_files/figure-html/unnamed-chunk-6-1.png){width=960}\n:::\n:::\n\n\n\n\n**Figure 2**. Soil profiles of STK ($g~m^{-2}$) under three different conditions: pristine soils (green circles), under grain cropping from 2000 to 2009 with no fertilizers added (Control, orange triangles), and under grain cropping from 2000 to 2009 with N, P, plus S fertilization (NPS, purple diamonds). Overlapping error bars indicate absence of significant differences between scenarios by soil depths combinations (Tukey's HSD, p \\< 0.05).\n:::\n\n\n",
    "supporting": [
      "models_05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}