---
title: "Advanced Data Wrangling in R"
author: "Dr. Adrian Correndo"
date: "2025-01-29"
categories: [data wrangling, dplyr, tidyr, case study]
format:
  html:
    toc: true
    toc-location: left
    toc-depth: 4
    number-sections: true
    table-class: "table table-striped table-hover"
  pdf:
    number-sections: true
editor: source
smooth-scroll: true
bibliography: ../../references.bib
link-citations: TRUE
---

**Description** <br/>

This class dives deeper into the world of R data wrangling, covering advanced techniques and their applications. We'll explore complex functions and join operations essential for real-world data analysis.

**Required packages for today** <br/>

```{r eval=TRUE, warning=FALSE, message=FALSE}
library(pacman)
p_load(dplyr, tidyr, stringr, lubridate, janitor)
```

# Review of Previous Lessons

|  |  |
|----|----|
| ![](https://dplyr.tidyverse.org/logo.png){.absolute top="0" right="0" height="45%"} | ![](https://tidyr.tidyverse.org/logo.png){.absolute top="0" right="0" height="45%"} |

Quick recap of essential data wrangling functions: 

::: panel-tabset
## `dplyr` 
-   `mutate()`

-   `filter()`
-   `select()`
-   `slice()`, `slice_head()`, `slice_tail()`, `slice_sample()`
-   `rename()`

-   `arrange()`
-   `distinct()`
-   `count()`

-   `glimpse()`
-   `summarise()`
-   `group_by`

## `tidyr`

-   `unite()`
-   `separate()`
-   `pivot_longer()`
-   `pivot_wider()`
-   `case_when()`
-   `nest()` 
-   `unnest()` 

## `skimr`

- `skim()`

:::

# Complex Joins

In data analysis, combining data from different sources is often necessary. Here, we'll use `dplyr`'s join functions to merge datasets based on common keys.

## Example: Merging Weather and Crop Yield Data

-   `left_join()`: Includes all records from the left dataset and the matched records from the right dataset. If there is no match, the result is NA in the columns of the right dataset.

```{r }
weather_data <- tibble(
  date = seq(as.Date("2024-04-01"), as.Date("2024-10-01"), by = "month"),
  precipitation = c(20, 40, 60, 80, 50, 30, 2),
  temperature = c(15, 18, 25, 30, 22, 16, 12)
)

forage_data <- tibble(
  date = seq(as.Date("2024-04-01"), as.Date("2024-10-01"), by = "month"),
  forage_yield = c(500, 1200, 3000, 4000, 2800, 1500, 0)
)

# Merge data
left_joined_data <- left_join(weather_data, forage_data, by = "date")
```

-   `right_join()`: Includes all records from the right dataset and the matched records from the left dataset. If there is no match, the result is NA in the columns of the left dataset.

```{r }
# Merge data
right_joined_data <- right_join(weather_data, forage_data, by = "date")
```

-   `full_join()`: Includes all records when there is a match in the keys of the left or right datasets. If there is no match, the result is NA in the columns of the dataset that does not have a match.

```{r full-join}
# Merge data
full_joined_data <- full_join(weather_data, forage_data, by = "date")
```

# Date Handling with `lubridate`

![](https://lubridate.tidyverse.org/logo.png){.absolute top="0" right="0" height="25%"}

Using `lubridate`, we can extract various date components for analysis.

```{r date-features}
weather_data_dates <- weather_data %>%
  mutate(
    year_month_day = format(date, "%Y_%m_%d"),
    day_of_year = yday(date),
    day_of_month = mday(date),
    week_of_year = week(date),
    month_name = month(date, label = TRUE, abbr = FALSE)
  )
glimpse(weather_data_dates)
```

# Data Cleaning with `janitor`

![](https://sfirke.github.io/janitor/reference/figures/logo_small.png){.absolute top="0" right="0" height="25%"}

Sometimes, datasets come with inconsistent column names, which can cause issues in analysis.

```{r messy-data}
messy_weather_data <- tibble(
  `Date Recorded` = seq(as.Date("2024-04-01"), as.Date("2024-10-01"), by = "month"),
  `Precipitation (mm)` = c(20, 40, 60, 80, 50, 30, 2),
  `Temperature..(C,)` = c(15, 18, 25, 30, 22, 16, 12)
)

clean_weather_data <- messy_weather_data %>% clean_names()
clean_weather_data
```

# Checking Data Quality

After merging, it's crucial to check for missing values and duplicates:

```{r data-quality}
data_quality_summary <- full_joined_data %>%
  summarise(across(everything(), ~ sum(is.na(.)), .names = "missing_{.col}"))

duplicate_rows <- full_joined_data %>% get_dupes()

data_quality_summary
duplicate_rows
```

# Final Thoughts and Resources

Data wrangling is a crucial step in data analysis, ensuring datasets are clean, structured, and ready for further exploration. By leveraging `dplyr`, `tidyr`, `janitor`, and `lubridate`, we can efficiently manage and transform our data to extract meaningful insights.

For further reading and practice, consider the following resources:

-   [R for Data Science](https://r4ds.had.co.nz/) by Hadley Wickham & Garrett Grolemund
-   [tidyverse documentation](https://www.tidyverse.org/)
-   [lubridate cheatsheet](https://evoldyn.gitlab.io/evomics-2018/ref-sheets/R_lubridate.pdf)
-   [Data Wrangling with R](https://rstudio-conf-2020.github.io/data-wrangling/) - A comprehensive tutorial

Keep practicing and experimenting with different datasets to solidify your understanding. Happy coding!
