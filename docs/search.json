[
  {
    "objectID": "coding/week_06/11_weather.html",
    "href": "coding/week_06/11_weather.html",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "",
    "text": "Description\nThis lesson provides a step-by-step guide on retrieving and processing daily-weather data using R. It covers downloading data from DAYMET and processing it to generate weather summaries useful for agricultural research.\nThis tutorial focuses on how to:\nRequired packages\nlibrary(pacman)\np_load(dplyr, tidyr, stringr) # Data wrangling\np_load(purrr) # Iteration\np_load(lubridate) # Date operations\np_load(kableExtra) # Table formatting to better display\np_load(daymetr) # Weather data from Daymet\np_load(skimr) # Summarizing weather data\np_load(vegan) # Shannon Diversity Index\np_load(writexl)",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#how-to-cite-the-daymetr-package",
    "href": "coding/week_06/11_weather.html#how-to-cite-the-daymetr-package",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "2.1 How to cite the daymetr package",
    "text": "2.1 How to cite the daymetr package\n\nHufkens K., Basler J. D., Milliman T. Melaas E., Richardson A.D. 2018 An integrated phenology modelling framework in R: Phenology modelling with phenor. Methods in Ecology & Evolution, 9: 1-10. https://doi.org/10.1111/2041-210X.12970",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#evapotranspiration",
    "href": "coding/week_06/11_weather.html#evapotranspiration",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "2.2 Evapotranspiration",
    "text": "2.2 Evapotranspiration\nDaymet does not provide data on reference evapotranspiration (\\(\\text{ET}_0\\)). However, it is possible to estimate \\(\\text{ET}_0\\) using the Hargreaves and Samani approach, which only requires temperature information (Hargreaves and Samani, 1985; Raziei and Pereira, 2013). Nonetheless, the \\(\\text{ET}_{0-HS}\\) equation is reported to give unreliable estimates for daily \\(ET0\\) and therefore it should be used for 10-day periods at the shortest (Cobaner et al., 2017). \n\n2.2.1 Constants\n\n# Constants for ET0 (Cobaner et al., 2017)\n# Solar constant:\nGsc &lt;- 0.0820 # (MJ m-2 min-1)\n# Radiation adjustment coefficient (Samani, 2004)\nkRs &lt;- 0.17",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#function-to-retrieve",
    "href": "coding/week_06/11_weather.html#function-to-retrieve",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "2.3 Function to retrieve",
    "text": "2.3 Function to retrieve\n\n# Name of functions using dots (.) instead of underscore (_)\n# We keep underscore for other objects\nweather.daymet &lt;- function(input, dpp = 0){ \n  # Downloads the daily weather data from the DAYMET database and process it\n  # Args:\n  #  input = input file containing the locations and the start & end dates for the time series\n  #  dpp = days prior to the Start\n  # Returns:\n  #  a tibble of DAYMET weather variables for the requested time period\n  # STEP 1. Make use of metadata (locations and dates)\n  input %&gt;%\n    dplyr::mutate(\n      Weather = purrr::pmap(list(ID = ID,\n                                 # Rename vars to avoid conflicts\n                                 lat = latitude,\n                                 lon = longitude,\n                                 sta = Start - dpp,\n                                 end = End),\n                                        \n   # STEP 2. Retrieving daymet data:\n              function(ID, lat, lon, sta, end) {\n                daymetr::download_daymet(site = ID,\n                                         lat = lat, \n                                         lon = lon,\n                                       # Extracting year from date:\n                                       start = as.numeric(substr(sta, 1, 4)),\n                                       end = as.numeric(substr(end, 1, 4)),\n                                       internal = TRUE, \n                                       simplify = TRUE)})) %&gt;% \n    \n    # STEP 3. Organizing dataframe (Re-arranging rows and columns)\n    dplyr::mutate(Weather = Weather %&gt;% \n                # i. Adjusting dates format with lubridate and map()\n                purrr::map(~ \n                  dplyr::mutate(., \n                   Date = as.Date(as.numeric(yday) - 1, # Day of the year\n                   origin = paste0(year, '-01-01')),\n                   Year = year(Date),\n                   Month = month(Date),\n                   Day = mday(Date))) %&gt;%\n                # ii. Select columns of interest\n                purrr::map(~ \n                  dplyr::select(., yday, Year, Month, Day,\n                                Date, measurement, value)) %&gt;%\n                # iii. Re-arrange columns wider\n                purrr::map(~ \n                  tidyr::pivot_wider(.,\n                      names_from = measurement, values_from = value)) %&gt;%\n                # iv. Renaming variables with rename_with()\n                    purrr::map(~ rename_with(., ~c(\n                      \"DOY\",   # Date as Day of the year\n                      \"Year\",  # Year\n                      \"Month\", # Month \n                      \"Day\",   # Day of the month\n                      \"Date\",  # Date as normal format\n                      \"DL\",    # Day length (sec)\n                      \"PP\",    # Precipitation (mm)\n                      \"Rad\",   # Radiation (W/m2)\n                      \"SWE\",   # Snow water (kg/m2)\n                      \"Tmax\",  # Max. temp. (degC)\n                      \"Tmin\",  # Min. temp. (degC)\n                      \"VPD\")))) %&gt;%   # Vap Pres Def (Pa)\n    # STEP 4. Processing data given start and ending dates:\n    dplyr::mutate(Weather = purrr::pmap(list(sta = Start - dpp, \n                                             end = End, \n                                             data = Weather), # Requested period\n                                        function(sta, end, data) {\n                                          dplyr::filter(data, Date &gt;= sta & Date &lt;= end) \n                                          })) %&gt;%\n    # STEP 5. Unnest\n    tidyr::unnest(cols = c(Weather)) %&gt;% \n    \n    # STEP 6. Converting units and adding extra variables:\n    dplyr::mutate(Rad = Rad*0.000001*DL, # Radiation (W/m2 to MJ/m2)\n                  Tmean = (Tmax+Tmin)/2, # Mean temperature (degC),\n                  VPD = VPD / 1000, # VPD (Pa to kPa),\n                  # Creating variables for ET0 estimation:\n                  lat_rad = latitude*0.0174533,\n                  dr = 1 + 0.033*cos((2*pi/365)*DOY),\n                  Sd = 0.409*sin((2*pi/365)*DOY - 1.39),\n                  ws = acos(-tan(lat_rad)*tan(Sd)),\n                  Ra = (24*60)/(pi) * Gsc * dr * (ws*sin(lat_rad)*sin(Sd) + cos(lat_rad)*sin(ws)),\n                  ET0_HS = 0.0135 * kRs * (Ra / 2.45) * (sqrt(Tmax-Tmin)) * (Tmean + 17.8),\n                  # Extreme PP events\n                  EPE_i = case_when((PP &gt; 25) ~ 1, TRUE ~ 0),\n                  # Extreme Temp events\n                  ETE_i = case_when((Tmax &gt;= 30) ~ 1, TRUE ~ 0),\n                  # Day length (hours)\n                  DL = (DL/60)/60 \n                  ) %&gt;% \n    dplyr::select(-lat_rad, -dr, -Sd, -ws, -Ra)\n  \n}",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#run-retrieving-function",
    "href": "coding/week_06/11_weather.html#run-retrieving-function",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "2.4 Run retrieving function",
    "text": "2.4 Run retrieving function\n\n# Specify input = dataframe containing sites-data \n# Specify Days prior planting. Default is dpp = 0. Here we use dpp = 30.\n\ndf_weather_daymet &lt;- weather.daymet(input = df_input, dpp = 30)\n\n# Overview of the variables (useful checking for missing values):\nskimr::skim(df_weather_daymet)\n\n\nData summary\n\n\nName\ndf_weather_daymet\n\n\nNumber of rows\n911\n\n\nNumber of columns\n25\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nDate\n5\n\n\nnumeric\n17\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n1\n1\n0\n3\n0\n\n\nCrop\n0\n1\n4\n7\n0\n2\n0\n\n\nSite\n0\n1\n5\n10\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nStart\n0\n1\n2002-04-25\n2010-05-20\n2005-05-01\n3\n\n\nEnd\n0\n1\n2002-09-30\n2010-10-10\n2006-09-30\n3\n\n\nFlo\n0\n1\n2002-07-20\n2010-07-15\n2006-07-21\n3\n\n\nSeFi\n0\n1\n2002-08-08\n2010-08-15\n2006-08-10\n3\n\n\nDate\n0\n1\n2002-03-26\n2010-10-10\n2005-12-23\n911\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlatitude\n0\n1\n43.20\n1.03\n42.45\n42.45\n42.45\n43.65\n45.08\n▇▁▃▁▂\n\n\nlongitude\n0\n1\n-80.33\n2.49\n-81.88\n-81.88\n-81.88\n-80.40\n-75.35\n▇▃▁▁▂\n\n\nDOY\n0\n1\n184.55\n78.43\n1.00\n128.00\n185.00\n242.00\n365.00\n▂▆▇▇▂\n\n\nYear\n0\n1\n2005.63\n2.56\n2002.00\n2005.00\n2005.00\n2006.00\n2010.00\n▆▇▇▁▅\n\n\nMonth\n0\n1\n6.58\n2.57\n1.00\n5.00\n7.00\n8.00\n12.00\n▃▇▇▇▃\n\n\nDay\n0\n1\n15.83\n8.88\n1.00\n8.00\n16.00\n24.00\n31.00\n▇▇▆▇▆\n\n\nDL\n0\n1\n13.17\n1.88\n8.89\n12.06\n13.68\n14.78\n15.44\n▂▂▃▅▇\n\n\nPP\n0\n1\n2.53\n5.31\n0.00\n0.00\n0.00\n2.74\n45.09\n▇▁▁▁▁\n\n\nRad\n0\n1\n16.23\n6.78\n1.40\n11.31\n16.61\n21.63\n29.86\n▃▆▇▇▃\n\n\nSWE\n0\n1\n0.98\n4.86\n0.00\n0.00\n0.00\n0.00\n41.65\n▇▁▁▁▁\n\n\nTmax\n0\n1\n18.74\n9.40\n-7.32\n12.90\n21.21\n26.16\n34.99\n▁▃▅▇▅\n\n\nTmin\n0\n1\n8.95\n8.13\n-15.01\n2.83\n10.31\n15.21\n24.83\n▁▃▅▇▃\n\n\nVPD\n0\n1\n1.26\n0.61\n0.19\n0.75\n1.21\n1.70\n3.14\n▇▇▇▃▁\n\n\nTmean\n0\n1\n13.84\n8.60\n-11.16\n7.73\n16.12\n20.52\n28.40\n▁▃▅▇▆\n\n\nET0_HS\n0\n1\n3.33\n1.66\n0.26\n2.03\n3.48\n4.69\n7.13\n▆▆▇▇▂\n\n\nEPE_i\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nETE_i\n0\n1\n0.06\n0.23\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\n\n\n# Exporting data as a .csv file\n# write.csv(df.weather.daymet, row.names = FALSE, na = '', file = paste0(path, 'Output_daymet.csv'))",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#define-time-intervals",
    "href": "coding/week_06/11_weather.html#define-time-intervals",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "3.1 Define time intervals",
    "text": "3.1 Define time intervals\nIn this section we create time intervals during the cropping season using pre-specified dates as columns at the initial data table with site information. \nThe user can apply: i) a unique seasonal interval (season), ii) even intervals (even), or iii) customized intervals (custom). \n\n3.1.1 Full-season interval\n\n# Defining season-intervals\nseason_interval &lt;- \n  df_input %&gt;%\n  dplyr::mutate(Interval = \"Season\") %&gt;%\n  dplyr::rename(Start.in = Start, End.in = End) %&gt;%\n  dplyr::select(ID, Site, Interval, Start.in, End.in)\n\n# Creating a table to visualize results\nkable(season_interval) %&gt;% \n  kable_styling(latex_options = c(\"striped\"),\n                position = \"center\", font_size = 10)\n\n\n\n\nID\nSite\nInterval\nStart.in\nEnd.in\n\n\n\n\n1\nElora\nSeason\n2002-04-25\n2002-09-30\n\n\n2\nRidgetown\nSeason\n2005-05-01\n2006-09-30\n\n\n3\nWinchester\nSeason\n2010-05-20\n2010-10-10\n\n\n\n\n\n\n\n\n\n3.1.2 Even-intervals\n\n# Number of intervals:\nn &lt;- 4 \n# Days prior planting:\ndpp &lt;- 30 \n\n# Defining even-intervals:\neven_intervals &lt;- \n  df_input %&gt;% \n  # Create new data:\n  dplyr::mutate(Intervals = \n          purrr::map2(.x = Start, .y = End,\n                      .f = ~ data.frame(\n                    Interval = c(\"Prev\", # Prior to start date \n                                 LETTERS[0:n]), # Each interval from start date\n                      # Start\n                      Start.in = c(.x - dpp, seq.Date(.x, .y + 1, length.out = n + 1)[1:n]),                              # End\n                      End.in = c(.x - 1, seq.Date(.x, .y + 1, length.out = n + 1)[2:(n + 1)]))) ) %&gt;% \n  # Selecting columns:\n  dplyr::select(ID, Site, Intervals) %&gt;% \n  tidyr::unnest(cols = c(Intervals))\n\n# Creating a table to visualize results\nkable(even_intervals) %&gt;% \n  kable_styling(latex_options = c(\"striped\"), \n                position = \"center\", font_size = 10)\n\n\n\n\nID\nSite\nInterval\nStart.in\nEnd.in\n\n\n\n\n1\nElora\nPrev\n2002-03-26\n2002-04-24\n\n\n1\nElora\nA\n2002-04-25\n2002-06-03\n\n\n1\nElora\nB\n2002-06-03\n2002-07-13\n\n\n1\nElora\nC\n2002-07-13\n2002-08-22\n\n\n1\nElora\nD\n2002-08-22\n2002-10-01\n\n\n2\nRidgetown\nPrev\n2005-04-01\n2005-04-30\n\n\n2\nRidgetown\nA\n2005-05-01\n2005-09-07\n\n\n2\nRidgetown\nB\n2005-09-07\n2006-01-15\n\n\n2\nRidgetown\nC\n2006-01-15\n2006-05-24\n\n\n2\nRidgetown\nD\n2006-05-24\n2006-10-01\n\n\n3\nWinchester\nPrev\n2010-04-20\n2010-05-19\n\n\n3\nWinchester\nA\n2010-05-20\n2010-06-25\n\n\n3\nWinchester\nB\n2010-06-25\n2010-07-31\n\n\n3\nWinchester\nC\n2010-07-31\n2010-09-05\n\n\n3\nWinchester\nD\n2010-09-05\n2010-10-11\n\n\n\n\n\n\n\n\n\n3.1.3 Custom-intervals\n\n# Count the number of interval columns (assuming intervals start at column \"Start\")\ni &lt;- df_input %&gt;% dplyr::select(Start:last_col()) %&gt;% ncol()\n\n# Defining custom-intervals\ncustom_intervals &lt;- \n  df_input %&gt;% \n  dplyr::mutate(Intervals = # Create\n                  purrr::pmap(# List of object to iterate over\n                              .l = list(x = Start - dpp,\n                                        y = Start,\n                                        z = Flo,\n                                        m = SeFi,\n                                        k = End),\n                              # The function to run\n                              .f = function(x, y, z, m, k) {\n                      data.frame(# New data\n                        Interval = c(LETTERS[1:i]),\n                        Name = c(\"Prev\", \"Plant-Flo\", \"Flo-SeFi\", \"SeFi-End\"),\n                        Start.in = c(x, y, z, m),\n                        End.in = c(y-1, z-1, m-1, k))}\n                    )) %&gt;% \n  # Selecting columns:\n  dplyr::select(ID,, Site, Intervals) %&gt;% \n  tidyr::unnest(cols = c(Intervals))\n\n# Creating a table to visualize results:\nkable(custom_intervals) %&gt;% \n  kable_styling(latex_options = c(\"striped\"), position = \"center\", font_size = 10)\n\n\n\n\nID\nSite\nInterval\nName\nStart.in\nEnd.in\n\n\n\n\n1\nElora\nA\nPrev\n2002-03-26\n2002-04-24\n\n\n1\nElora\nB\nPlant-Flo\n2002-04-25\n2002-07-19\n\n\n1\nElora\nC\nFlo-SeFi\n2002-07-20\n2002-08-07\n\n\n1\nElora\nD\nSeFi-End\n2002-08-08\n2002-09-30\n\n\n2\nRidgetown\nA\nPrev\n2005-04-01\n2005-04-30\n\n\n2\nRidgetown\nB\nPlant-Flo\n2005-05-01\n2006-07-20\n\n\n2\nRidgetown\nC\nFlo-SeFi\n2006-07-21\n2006-08-09\n\n\n2\nRidgetown\nD\nSeFi-End\n2006-08-10\n2006-09-30\n\n\n3\nWinchester\nA\nPrev\n2010-04-20\n2010-05-19\n\n\n3\nWinchester\nB\nPlant-Flo\n2010-05-20\n2010-07-14\n\n\n3\nWinchester\nC\nFlo-SeFi\n2010-07-15\n2010-08-14\n\n\n3\nWinchester\nD\nSeFi-End\n2010-08-15\n2010-10-10",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#summary-function",
    "href": "coding/week_06/11_weather.html#summary-function",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "3.2 Summary function",
    "text": "3.2 Summary function\nFor each of the period or interval of interest a variety of variables can be created. Here, we present a set of variables that can capture environmental variations that might be missing by analyzing standard weather data (precipitations, temperature, radiation). These variables represent an example that was used for studying influence of weather in corn yields by Correndo et al. (2021). \n\n# Defining the function to summarize DAYMET and/or NASA-POWER\nsummary.daymet &lt;- function(input, intervals) {\n  # Creates summaries of the DAYMET daily data over the requested period\n  # Args:\n  #  input = a weather data object such as df.weather.daymet with the daily weather data\n  #  intervals = a tibble with the start and end date for the summary period\n  # STEP 1. \n  intervals %&gt;%\n    # NOTE: mergeing on ID only as the key, so remove Site:\n    dplyr::select(-Site) %&gt;%\n    # Merging weather data:\n    dplyr::left_join(input %&gt;%\n                     # Nesting weather data back for each site-ID:\n                     dplyr::select_if(names(.) %in% \n                                        c(\"ID\", \"Crop\", \"Site\",\n                                          \"Date\",\"DL\", \"PP\", \n                                          \"Rad\", \"Tmax\", \"Tmin\",\n                                          \"Tmean\", \"VPD\", \"ET0_HS\")) %&gt;%\n                     dplyr::group_by(ID, Crop, Site) %&gt;% \n                     tidyr::nest(Weather = -c(ID, Crop, Site)) %&gt;%\n                     dplyr::ungroup(), \n                   by = c(\"ID\")) %&gt;% \n    # STEP 2. Create Weather column filtering for desired period only.\n    dplyr::mutate(Weather = purrr::pmap(\n      .l = list(x = Start.in,\n                y = End.in, \n                data = Weather),\n      # Filter function\n      .f = function(x, y, data) {\n        dplyr::filter(data, Date &gt;= x & Date &lt; y)} ) ) %&gt;% \n    \n    # STEP 3. Calculation of variables (daily) that will be useful to summarize the intervals \n    dplyr::mutate(Weather = Weather %&gt;% \n      # User must adapt depending on the crop (these ay be corn-specific)\n        purrr::map(~ mutate(.,\n                            # Extreme Precip. event:\n                            EPEi = case_when(PP &gt; 25 ~1, TRUE ~ 0),\n                            # Extreme Temp. event:\n                            ETEi = case_when(Tmax &gt;= 30 ~1, TRUE ~ 0), \n                            # Tmax factor,  crop heat units (CHU):\n                            Ymax = case_when(Tmax &lt; 10 ~ 0, \n                                    TRUE ~ 3.33*(Tmax-10) - 0.084*(Tmax-10)),\n                            # Tmin factor, Crop heat units (CHU):\n                            Ymin = case_when(Tmin &lt; 4.44 ~ 0, \n                                    TRUE ~ 1.8*(Tmin-4.44)), \n                            # Daily CHU:\n                            Yavg = (Ymax + Ymin)/2,\n                            # For WHEAT (diff. base temp and winter negatives)\n                            # # Tmin threshold Growing Degrees:\n                            # Gmin = case_when(Tmin &gt;= 0 ~ Tmin, TRUE ~ 0),\n                            # # Tmax threshold Growing Degrees:\n                            # Gmax = case_when(Tmax &gt; 30 ~ 30,\n                            #                  Tmin &lt; 0 ~ 0, \n                            #                  between(Tmax, 0, 30) ~ Tmax),\n                            # # Daily Growing Degree Units:\n                            # GDU = ((Gmin + Gmax)/2) - 0,\n                            # GDD_c = cumsum(GDU) \n                            # For CORN, SOYBEAN (Base temp = 10)\n                            # Tmin threshold Growing Degrees:\n                            Gmin = case_when(Tmin &gt;= 10 ~ Tmin, TRUE ~ 10),\n                            # Tmax threshold Growing Degrees:\n                            Gmax = case_when(Tmax &lt;= 30 ~ Tmax, TRUE ~ 30),\n                            # Daily Growing Degree Units:\n                            GDU = ((Gmin + Gmax)/2) - 10) ) ) %&gt;% \n    \n    # STEP 4. Summary for each variable over the period of interest:\n    dplyr::mutate(\n      # Duration of interval (days):\n      Dur = Weather %&gt;% purrr::map(~nrow(.)),\n      # Accumulated PP (mm):\n      PP = Weather %&gt;% purrr::map(~sum(.$PP)),\n      # Mean Temp (C):\n      Tmean = Weather %&gt;% purrr::map(~mean(.$Tmean)),\n      # Accumulated Rad (MJ/m2):\n      Rad = Weather %&gt;% purrr::map(~sum(.$Rad)),\n      # Accumulated VPD (kPa):\n      VPD = Weather %&gt;% purrr::map(~sum(.$VPD)),\n      # Accumulated ET0 (mm):\n      ET0_HS = Weather %&gt;% purrr::map(~sum(.$ET0_HS)),\n      # Number of ETE (#):\n      ETE = Weather %&gt;% purrr::map(~sum(.$ETEi)),\n      # Number of EPE (#):\n      EPE = Weather %&gt;% purrr::map(~sum(.$EPEi)),\n      # Accumulated Crop Heat Units (CHU):\n      CHU = Weather %&gt;% purrr::map(~sum(.$Yavg)),\n      # Shannon Diversity Index for PP:\n      SDI = Weather %&gt;% purrr::map(~ vegan::diversity(.$PP, index = \"shannon\")/log(length(.$PP))),\n      # Accumulated Growing Degree Days (GDD):\n      GDD =  Weather %&gt;% purrr::map(~sum(.$GDU))) %&gt;% \n    \n    # Additional indices and final units:\n    dplyr::select(-Weather) %&gt;% \n    # DS: `cols` is now required when using unnest()\n    tidyr::unnest(cols = c(Dur, PP, Tmean, Rad, VPD, ET0_HS, ETE, EPE, CHU, SDI, GDD)) %&gt;% \n    dplyr::mutate(\n      # Photo-thermal quotient (Q):\n      Q_chu = Rad/CHU,\n      Q_gdd = Rad/GDD,\n      # Abundant and Well Distributed Water:\n      AWDR = PP*SDI) \n  }",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#run-summaries",
    "href": "coding/week_06/11_weather.html#run-summaries",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "3.3 Run summaries",
    "text": "3.3 Run summaries\n\n3.3.1 Seasonal\n\n# Run the summary\n# input = dataframe containing the data (from daymet).\n# intervals = type of intervals (season, custom or even)\n\nseason_summary_daymet &lt;-\n  summary.daymet(input = df_weather_daymet,\n                           intervals = season_interval)\n\n# Skim data\nskimr::skim(season_summary_daymet)\n\n\nData summary\n\n\nName\nseason_summary_daymet\n\n\nNumber of rows\n3\n\n\nNumber of columns\n20\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nDate\n2\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n1\n1\n0\n3\n0\n\n\nInterval\n0\n1\n6\n6\n0\n1\n0\n\n\nCrop\n0\n1\n4\n7\n0\n2\n0\n\n\nSite\n0\n1\n5\n10\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nStart.in\n0\n1\n2002-04-25\n2010-05-20\n2005-05-01\n3\n\n\nEnd.in\n0\n1\n2002-09-30\n2010-10-10\n2006-09-30\n3\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nDur\n0\n1\n272.67\n211.73\n143.00\n150.50\n158.00\n337.50\n517.00\n▇▁▁▁▃\n\n\nPP\n0\n1\n683.57\n395.63\n361.53\n462.75\n563.98\n844.58\n1125.19\n▇▇▁▁▇\n\n\nTmean\n0\n1\n16.04\n3.20\n12.55\n14.63\n16.70\n17.78\n18.85\n▇▁▁▇▇\n\n\nRad\n0\n1\n4359.96\n2895.00\n2394.44\n2697.73\n3001.02\n5342.72\n7684.42\n▇▁▁▁▃\n\n\nVPD\n0\n1\n358.94\n237.60\n218.15\n221.77\n225.40\n429.33\n633.26\n▇▁▁▁▃\n\n\nET0_HS\n0\n1\n925.30\n517.24\n594.03\n627.29\n660.56\n1090.94\n1521.32\n▇▁▁▁▃\n\n\nETE\n0\n1\n17.67\n3.79\n15.00\n15.50\n16.00\n19.00\n22.00\n▇▁▁▁▃\n\n\nEPE\n0\n1\n2.67\n2.52\n0.00\n1.50\n3.00\n4.00\n5.00\n▇▁▇▁▇\n\n\nCHU\n0\n1\n6368.17\n3463.65\n4274.61\n4369.18\n4463.75\n7414.95\n10366.15\n▇▁▁▁▃\n\n\nSDI\n0\n1\n0.74\n0.03\n0.71\n0.74\n0.76\n0.76\n0.76\n▃▁▁▁▇\n\n\nGDD\n0\n1\n1677.80\n742.37\n1208.96\n1249.85\n1290.73\n1912.22\n2533.71\n▇▁▁▁▃\n\n\nQ_chu\n0\n1\n0.66\n0.11\n0.54\n0.62\n0.70\n0.72\n0.74\n▃▁▁▁▇\n\n\nQ_gdd\n0\n1\n2.46\n0.59\n1.86\n2.17\n2.48\n2.76\n3.03\n▇▁▇▁▇\n\n\nAWDR\n0\n1\n513.54\n307.39\n257.93\n343.01\n428.09\n641.35\n854.62\n▇▇▁▁▇\n\n\n\n\n# Creating a table to visualize results\nkbl(season_summary_daymet) %&gt;%\n  kable_styling(font_size = 7, position = \"center\", \n                latex_options = c(\"scale_down\"))\n\n\n\n\nID\nInterval\nStart.in\nEnd.in\nCrop\nSite\nDur\nPP\nTmean\nRad\nVPD\nET0_HS\nETE\nEPE\nCHU\nSDI\nGDD\nQ_chu\nQ_gdd\nAWDR\n\n\n\n\n1\nSeason\n2002-04-25\n2002-09-30\nCorn\nElora\n158\n361.53\n16.70405\n3001.020\n218.1533\n660.5558\n16\n0\n4274.608\n0.7134269\n1208.965\n0.7020574\n2.482305\n257.9252\n\n\n2\nSeason\n2005-05-01\n2006-09-30\nCorn\nRidgetown\n517\n1125.19\n12.55279\n7684.417\n633.2642\n1521.3225\n22\n5\n10366.150\n0.7595347\n2533.715\n0.7412990\n3.032866\n854.6209\n\n\n3\nSeason\n2010-05-20\n2010-10-10\nSoybean\nWinchester\n143\n563.98\n18.85315\n2394.440\n225.3956\n594.0311\n15\n3\n4463.745\n0.7590440\n1290.725\n0.5364196\n1.855113\n428.0856\n\n\n\n\n\n\n\n\n\n3.3.2 Even\n\n# Run the summary\n# input = dataframe containing the data (from daymet).\n# intervals = type of intervals (season, custom or even)\n\neven_summary_daymet &lt;-\n  summary.daymet(input = df_weather_daymet,\n                           intervals = even_intervals)\n\n# Skim data\nskimr::skim(even_summary_daymet)\n\n\nData summary\n\n\nName\neven_summary_daymet\n\n\nNumber of rows\n15\n\n\nNumber of columns\n20\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n4\n\n\nDate\n2\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n1\n1\n0\n3\n0\n\n\nInterval\n0\n1\n1\n4\n0\n5\n0\n\n\nCrop\n0\n1\n4\n7\n0\n2\n0\n\n\nSite\n0\n1\n5\n10\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nStart.in\n0\n1\n2002-03-26\n2010-09-05\n2005-09-07\n15\n\n\nEnd.in\n0\n1\n2002-04-24\n2010-10-11\n2006-01-15\n15\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nDur\n0\n1\n60.53\n43.22\n29.00\n36.00\n39.00\n84.50\n130.00\n▇▁▁▁▃\n\n\nPP\n0\n1\n153.76\n92.73\n45.94\n92.45\n113.04\n208.32\n364.82\n▇▃▂▂▁\n\n\nTmean\n0\n1\n14.46\n6.40\n4.11\n8.35\n18.00\n19.57\n22.11\n▃▃▁▁▇\n\n\nRad\n0\n1\n981.82\n680.51\n402.74\n595.51\n707.50\n924.39\n2563.53\n▇▂▁▁▂\n\n\nVPD\n0\n1\n76.45\n62.46\n21.08\n37.52\n62.84\n77.33\n218.10\n▇▆▁▁▂\n\n\nET0_HS\n0\n1\n201.85\n152.45\n63.49\n117.28\n174.13\n198.55\n576.34\n▇▇▁▁▂\n\n\nETE\n0\n1\n3.53\n4.34\n0.00\n0.00\n2.00\n6.00\n14.00\n▇▃▂▁▁\n\n\nEPE\n0\n1\n0.60\n0.74\n0.00\n0.00\n0.00\n1.00\n2.00\n▇▁▅▁▂\n\n\nCHU\n0\n1\n1329.55\n1267.41\n170.96\n502.82\n1165.18\n1356.75\n4269.04\n▇▇▁▁▂\n\n\nSDI\n0\n1\n0.64\n0.07\n0.43\n0.61\n0.65\n0.69\n0.73\n▁▁▃▅▇\n\n\nGDD\n0\n1\n347.29\n409.21\n-112.18\n98.38\n319.40\n404.69\n1285.44\n▇▇▁▁▂\n\n\nQ_chu\n0\n1\n1.20\n0.98\n0.47\n0.54\n0.64\n1.79\n3.05\n▇▁▁▂▂\n\n\nQ_gdd\n0\n1\n7.47\n19.56\n-15.99\n1.79\n2.15\n7.00\n74.52\n▇▇▁▁▁\n\n\nAWDR\n0\n1\n102.83\n68.43\n26.06\n57.67\n77.62\n145.51\n263.99\n▇▃▂▂▁\n\n\n\n\n# Creating a table to visualize results\nkbl(even_summary_daymet) %&gt;%\n  kable_styling(font_size = 7, position = \"center\", \n                latex_options = c(\"scale_down\"))\n\n\n\n\nID\nInterval\nStart.in\nEnd.in\nCrop\nSite\nDur\nPP\nTmean\nRad\nVPD\nET0_HS\nETE\nEPE\nCHU\nSDI\nGDD\nQ_chu\nQ_gdd\nAWDR\n\n\n\n\n1\nPrev\n2002-03-26\n2002-04-24\nCorn\nElora\n29\n95.53\n5.660000\n505.2583\n21.08116\n63.48611\n0\n1\n200.0765\n0.6357661\n6.780\n2.5253259\n74.521875\n60.73474\n\n\n1\nA\n2002-04-25\n2002-06-03\nCorn\nElora\n40\n113.04\n8.802250\n800.8372\n33.52344\n128.07920\n0\n0\n370.5894\n0.6866269\n84.400\n2.1609828\n9.488593\n77.61630\n\n\n1\nB\n2002-06-03\n2002-07-13\nCorn\nElora\n40\n98.94\n19.117375\n856.4385\n62.83969\n202.20827\n5\n0\n1288.3794\n0.6508401\n371.250\n0.6647409\n2.306905\n64.39412\n\n\n1\nC\n2002-07-13\n2002-08-22\nCorn\nElora\n40\n89.36\n20.994750\n752.2604\n69.43155\n194.90035\n7\n0\n1483.4871\n0.5993348\n437.950\n0.5070893\n1.717685\n53.55656\n\n\n1\nD\n2002-08-22\n2002-10-01\nCorn\nElora\n39\n60.83\n17.997436\n604.4711\n53.82624\n138.43587\n4\n0\n1165.1813\n0.4283610\n324.600\n0.5187786\n1.862203\n26.05720\n\n\n2\nPrev\n2005-04-01\n2005-04-30\nCorn\nRidgetown\n29\n105.04\n7.902759\n522.1453\n21.72264\n75.06876\n0\n0\n170.9552\n0.5923778\n41.800\n3.0542811\n12.491513\n62.22337\n\n\n2\nA\n2005-05-01\n2005-09-07\nCorn\nRidgetown\n130\n225.28\n19.555615\n2563.5280\n216.16182\n576.34481\n14\n0\n4269.0377\n0.6940917\n1285.435\n0.6004932\n1.994288\n156.36498\n\n\n2\nB\n2005-09-07\n2006-01-15\nCorn\nRidgetown\n129\n255.66\n6.956744\n992.3342\n115.05132\n174.13068\n0\n2\n1296.1836\n0.6752569\n112.950\n0.7655815\n8.785606\n172.63617\n\n\n2\nC\n2006-01-15\n2006-05-24\nCorn\nRidgetown\n130\n287.94\n4.109692\n1793.2989\n85.09908\n236.08072\n0\n1\n593.9790\n0.6804557\n-112.175\n3.0191285\n-15.986619\n195.93041\n\n\n2\nD\n2006-05-24\n2006-10-01\nCorn\nRidgetown\n129\n364.82\n19.592442\n2341.9490\n218.10287\n536.30800\n8\n2\n4217.6632\n0.7236240\n1249.530\n0.5552717\n1.874264\n263.99249\n\n\n3\nPrev\n2010-04-20\n2010-05-19\nSoybean\nWinchester\n29\n45.94\n11.114483\n586.5492\n23.85418\n106.48366\n0\n0\n411.6609\n0.5915947\n112.350\n1.4248358\n5.220732\n27.17786\n\n\n3\nA\n2010-05-20\n2010-06-25\nSoybean\nWinchester\n36\n119.18\n18.890417\n685.8864\n51.43909\n177.92863\n2\n1\n1134.8709\n0.7315317\n319.395\n0.6043740\n2.147455\n87.18395\n\n\n3\nB\n2010-06-25\n2010-07-31\nSoybean\nWinchester\n36\n85.30\n22.106111\n707.4951\n69.55371\n184.06589\n9\n0\n1417.3120\n0.6402241\n426.640\n0.4991809\n1.658295\n54.61112\n\n\n3\nC\n2010-07-31\n2010-09-05\nSoybean\nWinchester\n36\n168.14\n20.660556\n612.1467\n63.55369\n150.74414\n4\n1\n1290.7796\n0.6259308\n382.745\n0.4742457\n1.599359\n105.24400\n\n\n3\nD\n2010-09-05\n2010-10-11\nSoybean\nWinchester\n36\n191.36\n13.492083\n402.7351\n41.51125\n83.48533\n0\n1\n633.1501\n0.7037089\n165.755\n0.6360815\n2.429701\n134.66174\n\n\n\n\n\n\n\n\n\n3.3.3 Custom\n\n# Run the summary\n# input = dataframe containing the data (from daymet).\n# intervals = type of intervals (season, custom or even)\n\ncustom_summary_daymet &lt;-\n  summary.daymet(input = df_weather_daymet,\n                           intervals = custom_intervals)\n\n# Skim data\nskimr::skim(custom_summary_daymet)\n\n\nData summary\n\n\nName\ncustom_summary_daymet\n\n\nNumber of rows\n12\n\n\nNumber of columns\n21\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n5\n\n\nDate\n2\n\n\nnumeric\n14\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n1\n1\n0\n3\n0\n\n\nInterval\n0\n1\n1\n1\n0\n4\n0\n\n\nName\n0\n1\n4\n9\n0\n4\n0\n\n\nCrop\n0\n1\n4\n7\n0\n2\n0\n\n\nSite\n0\n1\n5\n10\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nStart.in\n0\n1\n2002-03-26\n2010-08-15\n2005-12-10\n12\n\n\nEnd.in\n0\n1\n2002-04-24\n2010-10-10\n2006-07-30\n12\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nDur\n0\n1\n74.92\n118.16\n18.00\n29.00\n40.50\n55.25\n445.00\n▇▁▁▁▁\n\n\nPP\n0\n1\n191.43\n233.36\n45.94\n82.21\n100.29\n188.89\n895.24\n▇▁▁▁▁\n\n\nTmean\n0\n1\n15.79\n5.72\n5.66\n11.36\n16.97\n20.28\n23.58\n▅▅▅▇▇\n\n\nRad\n0\n1\n1214.16\n1723.57\n332.92\n517.92\n653.53\n913.03\n6546.07\n▇▁▁▁▁\n\n\nVPD\n0\n1\n94.38\n133.33\n21.08\n30.15\n66.72\n81.44\n507.83\n▇▁▁▁▁\n\n\nET0_HS\n0\n1\n249.35\n330.83\n63.49\n89.12\n151.66\n222.19\n1261.95\n▇▁▁▁▁\n\n\nETE\n0\n1\n4.42\n5.12\n0.00\n0.00\n3.50\n6.25\n18.00\n▇▅▁▁▁\n\n\nEPE\n0\n1\n0.75\n1.48\n0.00\n0.00\n0.00\n1.00\n5.00\n▇▁▁▁▁\n\n\nCHU\n0\n1\n1638.66\n2112.65\n170.96\n610.25\n1248.18\n1717.42\n8062.31\n▇▂▁▁▁\n\n\nSDI\n0\n1\n0.64\n0.08\n0.52\n0.58\n0.61\n0.72\n0.75\n▆▆▂▂▇\n\n\nGDD\n0\n1\n427.22\n482.32\n6.78\n178.38\n362.19\n483.34\n1848.98\n▇▇▁▁▁\n\n\nQ_chu\n0\n1\n1.03\n0.88\n0.41\n0.51\n0.55\n1.07\n3.05\n▇▂▁▁▁\n\n\nQ_gdd\n0\n1\n9.28\n20.78\n1.30\n1.79\n1.94\n3.96\n74.52\n▇▁▁▁▁\n\n\nAWDR\n0\n1\n133.24\n178.12\n27.18\n44.11\n61.48\n140.08\n668.48\n▇▁▁▁▁\n\n\n\n\n# Creating a table to visualize results\nkbl(custom_summary_daymet) %&gt;%\n  kable_styling(font_size = 7, position = \"center\", \n                latex_options = c(\"scale_down\"))\n\n\n\n\nID\nInterval\nName\nStart.in\nEnd.in\nCrop\nSite\nDur\nPP\nTmean\nRad\nVPD\nET0_HS\nETE\nEPE\nCHU\nSDI\nGDD\nQ_chu\nQ_gdd\nAWDR\n\n\n\n\n1\nA\nPrev\n2002-03-26\n2002-04-24\nCorn\nElora\n29\n95.53\n5.660000\n505.2583\n21.08116\n63.48611\n0\n1\n200.0765\n0.6357661\n6.780\n2.5253259\n74.521875\n60.73474\n\n\n1\nB\nPlant-Flo\n2002-04-25\n2002-07-19\nCorn\nElora\n85\n211.98\n14.478353\n1767.0401\n105.60612\n358.83259\n7\n0\n1868.5814\n0.7117824\n518.900\n0.9456586\n3.405358\n150.88364\n\n\n1\nC\nFlo-SeFi\n2002-07-20\n2002-08-07\nCorn\nElora\n18\n61.48\n21.249444\n333.0742\n32.24373\n89.48994\n3\n0\n676.4427\n0.5459508\n200.385\n0.4923909\n1.662171\n33.56506\n\n\n1\nD\nSeFi-End\n2002-08-08\n2002-09-30\nCorn\nElora\n53\n88.07\n18.649434\n861.4328\n77.13351\n203.26534\n6\n0\n1667.0347\n0.5490199\n471.480\n0.5167456\n1.827082\n48.35218\n\n\n2\nA\nPrev\n2005-04-01\n2005-04-30\nCorn\nRidgetown\n29\n105.04\n7.902759\n522.1453\n21.72264\n75.06876\n0\n0\n170.9552\n0.5923778\n41.800\n3.0542811\n12.491513\n62.22337\n\n\n2\nB\nPlant-Flo\n2005-05-01\n2006-07-20\nCorn\nRidgetown\n445\n895.24\n11.445236\n6546.0731\n507.83287\n1261.94680\n18\n5\n8062.3054\n0.7467051\n1848.980\n0.8119356\n3.540370\n668.48028\n\n\n2\nC\nFlo-SeFi\n2006-07-21\n2006-08-09\nCorn\nRidgetown\n19\n71.87\n23.582632\n332.9171\n42.49005\n87.99388\n4\n0\n808.2634\n0.5904150\n255.540\n0.4118919\n1.302798\n42.43313\n\n\n2\nD\nSeFi-End\n2006-08-10\n2006-09-30\nCorn\nRidgetown\n51\n158.08\n17.779314\n760.1808\n79.45679\n161.56523\n0\n0\n1422.1259\n0.6849177\n407.350\n0.5345383\n1.866161\n108.27178\n\n\n3\nA\nPrev\n2010-04-20\n2010-05-19\nSoybean\nWinchester\n29\n45.94\n11.114483\n586.5492\n23.85418\n106.48366\n0\n0\n411.6609\n0.5915947\n112.350\n1.4248358\n5.220732\n27.17786\n\n\n3\nB\nPlant-Flo\n2010-05-20\n2010-07-14\nSoybean\nWinchester\n55\n181.19\n19.959273\n1067.8207\n87.38554\n278.97376\n8\n1\n1880.1266\n0.7532597\n538.705\n0.5679515\n1.982199\n136.48312\n\n\n3\nC\nFlo-SeFi\n2010-07-15\n2010-08-14\nSoybean\nWinchester\n30\n85.66\n21.524167\n566.9201\n56.30866\n141.75997\n3\n0\n1137.2219\n0.5215225\n346.630\n0.4985132\n1.635519\n44.67362\n\n\n3\nD\nSeFi-End\n2010-08-15\n2010-10-10\nSoybean\nWinchester\n56\n297.13\n16.158571\n720.5205\n77.41198\n163.36417\n4\n2\n1359.1429\n0.7257673\n377.755\n0.5301286\n1.907375\n215.64723",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#locations-and-dates-data",
    "href": "coding/week_06/11_weather.html#locations-and-dates-data",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "4.1 Locations and Dates Data",
    "text": "4.1 Locations and Dates Data\n\n# For historical data (from Jan-01-2000 to Dec-31-2022)\ndf_historical &lt;- data.frame(ID = c('1', '2', '3'),\n                      # Dates as YYYY_MM_DD, using \"_\" to separate\n                      Start = c('2000-01-01', '2000-01-01', '2000-01-01'),\n                      End = c('2022-12-31', '2022-12-31', '2022-12-31')) %&gt;% \n  # Express start and end as dates using \"across\"\n  dplyr::mutate(across(Start:End, ~as.Date(., format = '%Y-%m-%d')))\n\n# Merge for historical weather data\ndf_historical &lt;- df_sites %&gt;% dplyr::left_join(df_historical, by = \"ID\")",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#retrieve-from-daymet",
    "href": "coding/week_06/11_weather.html#retrieve-from-daymet",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "4.2 Retrieve from DAYMET",
    "text": "4.2 Retrieve from DAYMET\n\n# Specify input = dataframe containing historical dates from sites \nhist_weather_daymet &lt;- weather.daymet(input = df_historical)\n\n# This is a large data frame (21900 obs), so good to have an overview\n# Skim data\nskimr::skim(hist_weather_daymet)\n\n\nData summary\n\n\nName\nhist_weather_daymet\n\n\nNumber of rows\n25185\n\n\nNumber of columns\n23\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n3\n\n\nDate\n3\n\n\nnumeric\n17\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nID\n0\n1\n1\n1\n0\n3\n0\n\n\nCrop\n0\n1\n4\n7\n0\n2\n0\n\n\nSite\n0\n1\n5\n10\n0\n3\n0\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nStart\n0\n1\n2000-01-01\n2000-01-01\n2000-01-01\n1\n\n\nEnd\n0\n1\n2022-12-31\n2022-12-31\n2022-12-31\n1\n\n\nDate\n0\n1\n2000-01-01\n2022-12-31\n2011-07-02\n8395\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nlatitude\n0\n1\n43.73\n1.08\n42.45\n42.45\n43.65\n45.08\n45.08\n▇▁▇▁▇\n\n\nlongitude\n0\n1\n-79.21\n2.80\n-81.88\n-81.88\n-80.40\n-75.35\n-75.35\n▇▇▁▁▇\n\n\nDOY\n0\n1\n183.00\n105.37\n1.00\n92.00\n183.00\n274.00\n365.00\n▇▇▇▇▇\n\n\nYear\n0\n1\n2011.00\n6.63\n2000.00\n2005.00\n2011.00\n2017.00\n2022.00\n▇▆▇▆▇\n\n\nMonth\n0\n1\n6.52\n3.45\n1.00\n4.00\n7.00\n10.00\n12.00\n▇▅▅▅▇\n\n\nDay\n0\n1\n15.72\n8.79\n1.00\n8.00\n16.00\n23.00\n31.00\n▇▇▇▇▆\n\n\nDL\n0\n1\n12.00\n2.26\n8.56\n9.80\n12.00\n14.20\n15.44\n▇▅▅▅▇\n\n\nPP\n0\n1\n2.58\n5.27\n0.00\n0.00\n0.00\n2.92\n85.53\n▇▁▁▁▁\n\n\nRad\n0\n1\n13.40\n7.37\n0.74\n6.84\n12.59\n19.32\n32.59\n▇▇▇▆▂\n\n\nSWE\n0\n1\n16.21\n32.83\n0.00\n0.00\n0.00\n12.65\n211.59\n▇▁▁▁▁\n\n\nTmax\n0\n1\n12.75\n11.54\n-22.58\n2.94\n13.55\n23.18\n36.23\n▁▅▇▇▅\n\n\nTmin\n0\n1\n3.03\n10.49\n-31.93\n-3.83\n3.42\n11.72\n25.02\n▁▂▇▇▅\n\n\nVPD\n0\n1\n0.93\n0.59\n0.04\n0.46\n0.77\n1.35\n3.17\n▇▅▃▁▁\n\n\nTmean\n0\n1\n7.89\n10.85\n-26.25\n-0.37\n8.46\n17.42\n29.88\n▁▃▇▇▅\n\n\nET0_HS\n0\n1\n2.42\n1.83\n-0.45\n0.72\n1.97\n4.00\n7.38\n▇▅▅▅▁\n\n\nEPE_i\n0\n1\n0.01\n0.10\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁\n\n\nETE_i\n0\n1\n0.03\n0.17\n0.00\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▁",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#summary-functions",
    "href": "coding/week_06/11_weather.html#summary-functions",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "4.3 Summary functions",
    "text": "4.3 Summary functions\n\n4.3.1 By year\n\n# Defining function to summarize historical weather (years)\n\n# Revised function:\nhistorical.years &lt;- function(hist.data) {\n  # Creates an input tibble with the start and end date for each year a summary is desired\n  # Args:\n  #  hist.data = data frame containing the historical weather data to summarize (must be complete years)\n  # Returns:\n  #  a tibble of monthly summaries for each ID\n  #\n  # By year:\n  hist.data %&gt;% \n    dplyr::group_by(ID, Crop, Site) %&gt;%\n    tidyr::nest() %&gt;%\n    dplyr::mutate(the_Dates = purrr::map(data, function(.data) {.data %&gt;% dplyr::group_by(Year) %&gt;% \n        dplyr::summarise(Start.in = min(Date), End.in = max(Date), .groups = \"drop\")})) %&gt;%\n    dplyr::ungroup() %&gt;%\n    dplyr::select(ID, Site, the_Dates) %&gt;%\n    tidyr::unnest(cols = c(the_Dates))\n}\n\n\n\n4.3.2 By year-month\n\n# Defining function to summarize historical weather (years & months)\n# Revised function:\nhistorical.yearmonths &lt;- function(hist.data) {\n  # Creates an input tibble with the start and end date for each year & month a summary is desired (monthly summaries)\n  # Args:\n  #  hist.data = data frame containing the historical weather data to summarize (must be complete years)\n  # Returns:\n  #  a tibble of monthly summaries for each ID\n  #\n  # By month in year:\n  hist.data %&gt;% \n    dplyr::group_by(ID, Crop, Site) %&gt;%\n    tidyr::nest() %&gt;%\n    dplyr::mutate(the_Dates = purrr::map(data, function(.data) {.data %&gt;% \n        dplyr::group_by(Year, Month) %&gt;% \n        dplyr::summarise(Start.in = min(Date), End.in = max(Date), .groups = \"drop\")})) %&gt;%\n    dplyr::ungroup() %&gt;%\n    dplyr::select(ID, Site, the_Dates) %&gt;%\n    tidyr::unnest(cols = c(the_Dates))\n}",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_06/11_weather.html#run-historical-summaries",
    "href": "coding/week_06/11_weather.html#run-historical-summaries",
    "title": "Retrieving and Processing Agrometeorological Data Using R",
    "section": "4.4 Run Historical Summaries",
    "text": "4.4 Run Historical Summaries\nSummary can be obtained by years or by years.months. User must specify this option at the “intervals” argument of the summary function. \n\n4.4.1 By year\n\n# Specify hist.data = dataframe containing the historical weather data to summarize\nyear_intervals &lt;- historical.years(hist.data = hist_weather_daymet)\n\n# input = dataframe containing the historical weather data.\n# intervals = type of historical intervals (years, years.months)\n\n# Summarizing historical weather\nyear_summary_daymet &lt;-\n  summary.daymet(input = hist_weather_daymet,\n                           intervals = year_intervals)\n\n# Creating a table to visualize data\nkbl(head(year_summary_daymet)) %&gt;%\n  kable_styling(font_size = 7, position = \"center\", latex_options = c(\"scale_down\"))\n\n\n\n\nID\nYear\nStart.in\nEnd.in\nCrop\nSite\nDur\nPP\nTmean\nRad\nVPD\nET0_HS\nETE\nEPE\nCHU\nSDI\nGDD\nQ_chu\nQ_gdd\nAWDR\n\n\n\n\n1\n2000\n2000-01-01\n2000-12-30\nCorn\nElora\n364\n1035.79\n6.784354\n4882.077\n311.9404\n834.4626\n1\n5\n4364.787\n0.7951588\n480.635\n1.1185144\n10.157556\n823.6175\n\n\n1\n2001\n2001-01-01\n2001-12-31\nCorn\nElora\n364\n909.30\n7.786786\n4956.964\n321.2663\n874.0620\n11\n2\n4667.094\n0.7815342\n644.145\n1.0621094\n7.695417\n710.6491\n\n\n1\n2002\n2002-01-01\n2002-12-31\nCorn\nElora\n364\n795.34\n7.495824\n4869.331\n327.4677\n869.5653\n16\n2\n4773.116\n0.7811108\n630.985\n1.0201579\n7.717032\n621.2487\n\n\n1\n2003\n2003-01-01\n2003-12-31\nCorn\nElora\n364\n948.80\n6.212733\n4976.636\n300.1867\n841.3591\n4\n2\n4327.508\n0.7825177\n388.790\n1.1500003\n12.800318\n742.4528\n\n\n1\n2004\n2004-01-01\n2004-12-30\nCorn\nElora\n364\n952.48\n6.537857\n4883.104\n308.5060\n827.3507\n0\n3\n4256.332\n0.8086498\n401.735\n1.1472563\n12.155037\n770.2228\n\n\n1\n2005\n2005-01-01\n2005-12-31\nCorn\nElora\n364\n842.09\n7.185206\n5117.729\n300.0098\n921.0563\n24\n3\n5131.436\n0.7836771\n681.280\n0.9973287\n7.511932\n659.9266\n\n\n\n\n\n\n\n\n\n4.4.2 By year-month\n\n# Specify hist.data = dataframe containing the historical weather data to summarize\nyearmonth_intervals &lt;- historical.yearmonths(hist.data = hist_weather_daymet)\n\n# input = dataframe containing the historical weather data.\n# intervals = type of historical intervals (years, years.months)\n\n# Summarizing historical weather\nyearmonth_summary_daymet &lt;-\n  summary.daymet(input = hist_weather_daymet,\n                           intervals = yearmonth_intervals)\n\n# Creating a table to visualize data\nkbl(head(yearmonth_summary_daymet)) %&gt;%\n  kable_styling(font_size = 7, position = \"center\", latex_options = c(\"scale_down\"))\n\n\n\n\nID\nYear\nMonth\nStart.in\nEnd.in\nCrop\nSite\nDur\nPP\nTmean\nRad\nVPD\nET0_HS\nETE\nEPE\nCHU\nSDI\nGDD\nQ_chu\nQ_gdd\nAWDR\n\n\n\n\n1\n2000\n1\n2000-01-01\n2000-01-31\nCorn\nElora\n30\n44.22\n-7.187333\n191.5335\n8.62155\n12.22926\n0\n0\n0.94134\n0.7172157\n-190.010\n203.4690205\n-1.008018\n31.71528\n\n\n1\n2000\n2\n2000-02-01\n2000-02-29\nCorn\nElora\n28\n57.08\n-4.463036\n269.1460\n9.91130\n19.01688\n0\n0\n6.89583\n0.7480953\n-141.315\n39.0302527\n-1.904582\n42.70128\n\n\n1\n2000\n3\n2000-03-01\n2000-03-31\nCorn\nElora\n30\n44.97\n2.868500\n441.0486\n16.34147\n47.73356\n0\n0\n86.70312\n0.6801023\n-33.830\n5.0868832\n-13.037205\n30.58420\n\n\n1\n2000\n4\n2000-04-01\n2000-04-30\nCorn\nElora\n29\n64.87\n5.135345\n552.8653\n18.09003\n65.36530\n0\n1\n117.08760\n0.5036470\n-1.030\n4.7218089\n-536.762404\n32.67158\n\n\n1\n2000\n5\n2000-05-01\n2000-05-31\nCorn\nElora\n30\n147.43\n12.970667\n584.3621\n31.84376\n114.94758\n0\n2\n505.68054\n0.6533741\n140.385\n1.1555954\n4.162568\n96.32695\n\n\n1\n2000\n6\n2000-06-01\n2000-06-30\nCorn\nElora\n29\n199.88\n17.281207\n560.0957\n41.55868\n133.48935\n1\n1\n787.44879\n0.7668216\n217.885\n0.7112789\n2.570603\n153.27230",
    "crumbs": [
      "Lessons",
      "11-Weather data"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html",
    "href": "coding/week_01/essentials_01.html",
    "title": "Essentials of R coding I",
    "section": "",
    "text": "This page provides an overview of the essential types of elements in R, including examples and explanations for each. Use this as a quick reference to understand the basics of data types and operations.",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#numbers",
    "href": "coding/week_01/essentials_01.html#numbers",
    "title": "Essentials of R coding I",
    "section": "01. Numbers",
    "text": "01. Numbers\n\n20\n\n[1] 20",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#math-operations",
    "href": "coding/week_01/essentials_01.html#math-operations",
    "title": "Essentials of R coding I",
    "section": "02. Math Operations",
    "text": "02. Math Operations\n\n20+1 # addition\n\n[1] 21\n\n20-4 # subtraction\n\n[1] 16\n\n20*5 # multiplication\n\n[1] 100\n\n20/5 # division\n\n[1] 4\n\n2^2 # exponentials\n\n[1] 4\n\nsqrt(9) # square root\n\n[1] 3\n\n# Greater exponents for roots\n# notation is: x^(1/n)\n\n# Cubic root of 27\n27^(1/3)  # Result: 3\n\n[1] 3\n\n# 4th root of 16\n16^(1/4)  # Result: 2\n\n[1] 2\n\n# 5th root of 32\n32^(1/5)  # Result: 2\n\n[1] 2",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#text-or-characters-also-called-strings",
    "href": "coding/week_01/essentials_01.html#text-or-characters-also-called-strings",
    "title": "Essentials of R coding I",
    "section": "03. Text or characters (also called strings)",
    "text": "03. Text or characters (also called strings)\n\n\"coding is fun\"\n\n[1] \"coding is fun\"\n\n\nBut these elements are not stored as objects yet:",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#define-objects",
    "href": "coding/week_01/essentials_01.html#define-objects",
    "title": "Essentials of R coding I",
    "section": "04. Define objects",
    "text": "04. Define objects\n\na &lt;- 20\n10 -&gt; b\n# We can also use equal:\nc = 15\n# But using \"&lt;-\", and leave = only for operations (so you can notice the difference) is considered a better coding practice.",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#print-objects",
    "href": "coding/week_01/essentials_01.html#print-objects",
    "title": "Essentials of R coding I",
    "section": "05. Print objects",
    "text": "05. Print objects\n\na\n\n[1] 20\n\nprint(a)\n\n[1] 20\n\nb\n\n[1] 10\n\nc\n\n[1] 15",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#vectors",
    "href": "coding/week_01/essentials_01.html#vectors",
    "title": "Essentials of R coding I",
    "section": "06. Vectors",
    "text": "06. Vectors\nA vector is one of the most basic data structures. It is a sequence of elements of the same type, such as numbers, characters, or logical values. Vectors are used to store and manipulate collections of data efficiently. \n\na. Creating a vector\nVectors can be created using the c() function (combine function):\n\n# Numeric vector\nnumeric_vector &lt;- c(1, 2, 3, 4.5)\nnumeric_vector\n\n[1] 1.0 2.0 3.0 4.5\n\n# Character vector\ncharacter_vector &lt;- c(\"corn\", \"wheat\", \"soybean\")\ncharacter_vector\n\n[1] \"corn\"    \"wheat\"   \"soybean\"\n\n# Logical vector\nlogical_vector &lt;- c(TRUE, FALSE, TRUE)\nlogical_vector\n\n[1]  TRUE FALSE  TRUE\n\n\n\n\nb. Accessing Elements\nYou can access elements of a vector using square brackets []:\n\n# Access the first element\nnumeric_vector[1]\n\n[1] 1\n\n# Access multiple elements\nnumeric_vector[c(1, 3)]\n\n[1] 1 3\n\n\n\n\nc. Vectorized Operations\nIn R, vector-operations are applied to each element automatically:\n\n# Adding a scalar to a vector\nnumeric_vector + 2\n\n[1] 3.0 4.0 5.0 6.5\n\n# Element-wise addition\nnumeric_vector + c(10, 20, 30, 40)\n\n[1] 11.0 22.0 33.0 44.5\n\n\n\n\nd. Common Functions with Vectors\n\n‘length()’: Get the number of elements in a vector.\n‘typeof()’ or ‘class()’: Determine the type of elements in a vector.\n‘seq()’: Generate a sequence of numbers.\n‘rep()’: Repeat elements to create a vector.",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#lists",
    "href": "coding/week_01/essentials_01.html#lists",
    "title": "Essentials of R coding I",
    "section": "07. Lists",
    "text": "07. Lists\nIn R, a list is a versatile data structure that can contain elements of different types, including vectors, matrices, data frames, and even other lists. Unlike vectors, which are homogeneous, lists are heterogeneous, meaning their elements can be of different data types and lengths. \nKey Characteristics of Lists: \n\nHeterogeneous: Lists can store elements of varying types (numeric, character, logical, etc.) and structures (vectors, data frames, functions, etc.). \nIndexed: Elements in a list are accessed using double square brackets [[ ]] or named elements using $.\n\nWhy Use Lists? \n\nFlexibility: Lists can store complex and nested data structures. \nData Wrangling: Useful for handling results from models, nested data, or any mixed-type collections. \nFunctions: Functions in R often return their output as lists (e.g., lm()). \n\n\na. Creating a list\nLists are created using the list() function:\n\n# Create a list with different types of elements\nmy_list &lt;- list(\n  \"numeric_v\" = numeric_vector,\n  \"character_v\" = character_vector,\n  \"single_number\" = 42,\n  \"logical_value\" = TRUE\n)\n\n\n\nb. Accessing Elements in a List\nYou can access elements in a list by their position or name:\nBy Position:\n\n# Access the first element\nmy_list[[1]]\n\n[1] 1.0 2.0 3.0 4.5\n\n# Access the second element\nmy_list[[2]]\n\n[1] \"corn\"    \"wheat\"   \"soybean\"\n\n\nBy name:\n\n# Access by name\nmy_list$numeric_v\n\n[1] 1.0 2.0 3.0 4.5\n\nmy_list$character_v\n\n[1] \"corn\"    \"wheat\"   \"soybean\"\n\n\nSubelements:\n\n# Access the first value in the numeric vector\nmy_list$numeric_vector[1]\n\nNULL\n\n\n\n\nc. Some functions for lists\n\n# Number of elements in the list\nlength(my_list)\n\n[1] 4\n\n# Names of the elements\nnames(my_list)\n\n[1] \"numeric_v\"     \"character_v\"   \"single_number\" \"logical_value\"\n\n# Structure of the list\nstr(my_list)\n\nList of 4\n $ numeric_v    : num [1:4] 1 2 3 4.5\n $ character_v  : chr [1:3] \"corn\" \"wheat\" \"soybean\"\n $ single_number: num 42\n $ logical_value: logi TRUE",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#data-frame",
    "href": "coding/week_01/essentials_01.html#data-frame",
    "title": "Essentials of R coding I",
    "section": "08. Data frame",
    "text": "08. Data frame\nIn R, a data frame is a two-dimensional data structure used for storing tabular data. It is one of the most commonly used data structures in R for data analysis and manipulation. \nKey Characteristics of a Data Frame \n\nTabular Structure: Data is organized in rows and columns. \nHeterogeneous Columns: Each column can contain different data types (e.g., numeric, character, logical), but all elements in a column must be of the same type. \nRow and Column Names: Rows and columns can have names for easier identification. \n\nWhy Use a Data Frame? \n\nData Analysis: It is ideal for representing structured data like spreadsheets or databases. \nFlexible Operations: Columns can be easily added, removed, or modified. \nIntegration with R Functions: Many R functions for statistical modeling and analysis expect data frames as input. \n\n\na. Creating a Data Frame\nA data frame can be created using the data.frame() function:\n\n# Create a data frame\nmy_data &lt;- data.frame(\n  Crop = c(\"Corn\", \"Wheat\", \"Soybean\"), # Character column\n  Yield = c(180, 90, 50), # Numeric column\n  Legume = c(FALSE, FALSE, TRUE) # Logical column\n)\n\nprint(my_data)\n\n     Crop Yield Legume\n1    Corn   180  FALSE\n2   Wheat    90  FALSE\n3 Soybean    50   TRUE\n\n\n\n\nb. Accessing data in a data frame\nAccessing columns:\n\n# Access a column by name\nmy_data$Crop\n\n[1] \"Corn\"    \"Wheat\"   \"Soybean\"\n\n# Access a column by index\nmy_data[, 2]\n\n[1] 180  90  50\n\n\nAccessing rows:\n\n# Access the first row\nmy_data[1, ]\n\n  Crop Yield Legume\n1 Corn   180  FALSE\n\n# Access specific rows\nmy_data[c(1, 3), ]\n\n     Crop Yield Legume\n1    Corn   180  FALSE\n3 Soybean    50   TRUE\n\n\nAccessing specific elements\n\n# Access the element in the 2nd row, 3rd column\nmy_data[2, 3]\n\n[1] FALSE\n\n# Access specific cells by column name\nmy_data[2, \"Crop\"]\n\n[1] \"Wheat\"\n\n\n\n\nc. Adding a new column\n\nmy_data$Season &lt;- c(\"Summer\", \"Winter\", \"Summer\")\n\n\n\nd. Modify a column\n\nmy_data$Yield &lt;- my_data$Yield + 5\n\n\n\ne. Adding a new row\nIn base R, we can use rbind() to add rows:\n\nnew_row &lt;- data.frame(Crop = \"Barley\", Yield = 80, Legume = FALSE, Season = \"Winter\")\nmy_data &lt;- rbind(my_data, new_row)\n\n\n\nf. Filtering (rows)\nIn base R, we can use subset() to filter rows:\n\nsubset(my_data, Yield &gt; 150)\n\n  Crop Yield Legume Season\n1 Corn   185  FALSE Summer\n\n\nWe can also use logical conditions:\n\nmy_data[my_data$Legume == TRUE, ]\n\n     Crop Yield Legume Season\n3 Soybean    55   TRUE Summer\n\n\n\n\ng. Selecting (columns)\nIn base R, there is no function to select columns. We need to use brackets [] and vectors c():\n\nmy_data[c(\"Crop\", \"Yield\")]\n\n     Crop Yield\n1    Corn   185\n2   Wheat    95\n3 Soybean    55\n4  Barley    80\n\n\n\n\nh. Some functions for data frames\n\nnrow(my_data)        # Number of rows\n\n[1] 4\n\nncol(my_data)        # Number of columns\n\n[1] 4\n\ncolnames(my_data)    # Column names\n\n[1] \"Crop\"   \"Yield\"  \"Legume\" \"Season\"\n\nsummary(my_data)     # Summary statistics\n\n     Crop               Yield          Legume           Season         \n Length:4           Min.   : 55.00   Mode :logical   Length:4          \n Class :character   1st Qu.: 73.75   FALSE:3         Class :character  \n Mode  :character   Median : 87.50   TRUE :1         Mode  :character  \n                    Mean   :103.75                                     \n                    3rd Qu.:117.50                                     \n                    Max.   :185.00",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#matrix",
    "href": "coding/week_01/essentials_01.html#matrix",
    "title": "Essentials of R coding I",
    "section": "09. Matrix",
    "text": "09. Matrix\nIn R, a matrix is a two-dimensional, rectangular data structure that stores elements of the same type. It is similar to a data frame in structure but less flexible, as all elements in a matrix must be of a single data type (e.g., numeric, character, or logical). \nKey Characteristics of a Matrix \n\nHomogeneous: All elements in a matrix must be of the same type. \n2D Structure: A matrix has rows and columns, forming a table-like structure. \nDimensions: Defined by the number of rows and columns. \n\nWhy Use a Matrix? \n\nMathematical Operations: Ideal for linear algebra and mathematical modeling. \nEfficient Storage: Matrices use less memory compared to more complex structures like data frames. \nSimpler Operations: Homogeneous data ensures consistent behavior across elements. \n\n\na. Creating a Matrix\nYou can create a matrix using the matrix() function:\n\n# Create a numeric matrix\nmy_matrix &lt;- matrix(\n  data = 1:9,     # Data values\n  nrow = 3,       # Number of rows\n  ncol = 3,       # Number of columns\n)\n\nprint(my_matrix)\n\n     [,1] [,2] [,3]\n[1,]    1    4    7\n[2,]    2    5    8\n[3,]    3    6    9\n\n\n\n\nb. Accessing elements in a matrix\nAccessing rows:\n\n# Access the first row\nmy_matrix[1, ]\n\n[1] 1 4 7\n\n\nAccessing columns:\n\n# Access the second column\nmy_matrix[, 2]\n\n[1] 4 5 6\n\n\nAccessing specific elements:\n\n# Access the element in the 2nd row, 3rd column\nmy_matrix[2, 3]\n\n[1] 8\n\n\n\n\nc. Adding a new column\n\nnew_col &lt;- c(10, 11, 12) # Create the column\nmy_matrix &lt;- cbind(my_matrix, new_col) # Paste it to the existing\n\n\n\nd. Adding a new row\n\nnew_row &lt;- c(13, 14, 15, 16)\nmy_matrix &lt;- rbind(my_matrix, new_row)",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_01/essentials_01.html#functions",
    "href": "coding/week_01/essentials_01.html#functions",
    "title": "Essentials of R coding I",
    "section": "10. Functions",
    "text": "10. Functions\n\na. Create a function\nWe need to use the syntax function(x) { x as object of a task }. ‘x’ is considered an “argument”, and the function itself is inside the {}. For example:\n\nmy_function &lt;- function(x) { x + 1 }\n\n\n\nb. Check the function\n\nmy_function(9)\n\n[1] 10\n\n\n\n\nc. Write a function with 3 arguments\n\nmy_xyz_function &lt;- function(x, y, z) { x + y - z }\n\n\n\nd. Order of arguments\nNote: R is order sensitive (if you don’t explicitly specify the argument)\n\nmy_xyz_function(12, 3, 4)\n\n[1] 11\n\nmy_xyz_function(12, 4, 3)\n\n[1] 13\n\n\n\n\ne. Specifying arguments with names\nIf you specify the argument name as = to, the order doesn’t matter:\n\nmy_xyz_function(z = 4, x = 12, y = 3)\n\n[1] 11\n\n\n\n\nf. A more complex function\n\nfx &lt;- function(x, y, remove_na = NULL) {\n        # First operation is a sum, removing NAs\n        first &lt;- sum(c(x, y), na.rm = remove_na)\n        # Add a text message\n        text &lt;- \"This function is so cool\"\n        # Store result\n        result &lt;- first + x\n        # Print output\n        print(list(\"Message\" = text,\n                   \"1st\" = first,\n                   \"end\" = result))\n                   }\n\nRun the function with alternative arguments:\n\nfx(x = a, y = b, remove_na = FALSE)\n\n$Message\n[1] \"This function is so cool\"\n\n$`1st`\n[1] 30\n\n$end\n[1] 50\n\nfx(x = a, y = b, remove_na = TRUE)\n\n$Message\n[1] \"This function is so cool\"\n\n$`1st`\n[1] 30\n\n$end\n[1] 50\n\n\nStore the output in an object:\n\nfoo &lt;- fx(x=b, y=a)\n\n$Message\n[1] \"This function is so cool\"\n\n$`1st`\n[1] 30\n\n$end\n[1] 40",
    "crumbs": [
      "Lessons",
      "01-Essentials of R"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html",
    "href": "coding/week_05/09_ggplot2_plus.html",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "",
    "text": "Description\nIn this class, we will explore how to create geographic maps using ggplot2, sf, maps, leaflet, and geojson. We’ll cover techniques for plotting data points on US and Canada maps, customizing map aesthetics, and working with spatial data.",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#us-map-with-state-boundaries",
    "href": "coding/week_05/09_ggplot2_plus.html#us-map-with-state-boundaries",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "2.1 US Map with State Boundaries",
    "text": "2.1 US Map with State Boundaries\n\n# Load US map data\nus_map &lt;- map_data(\"state\")\n\n# Plot US map\nus_plot &lt;- \n  ggplot() +\n  geom_polygon(data = us_map, aes(x = long, y = lat, group = group),\n               fill = \"grey90\", color = \"grey35\") +\n  coord_fixed(1.3) +\n  labs(title = \"Map of the United States\") +\n  theme_base()\n\nus_plot",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#canada-map-with-provincial-boundaries",
    "href": "coding/week_05/09_ggplot2_plus.html#canada-map-with-provincial-boundaries",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "2.2 Canada Map with Provincial Boundaries",
    "text": "2.2 Canada Map with Provincial Boundaries\n\n# Load Canada map data\ncanada_map &lt;- map_data(\"world\", region = \"Canada\")\n\n# Plot Canada map\ncanada_plot &lt;- ggplot() +\n  geom_polygon(data = canada_map, aes(x = long, y = lat, group = group),\n               fill = \"steelblue\", color = \"black\") +\n  coord_fixed(1.3) +\n  labs(title = \"Map of Canada\")\n\ncanada_plot\n\n\n\n\n\n\n\ncanada_cut &lt;- canada_plot +\n  # Cut limits of map\n  scale_y_continuous(limits = c(41, 48))+\n  scale_x_continuous(limits = c(-87, -75))+\n  theme_minimal()\n\ncanada_cut",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#plotting-cities-on-us-map",
    "href": "coding/week_05/09_ggplot2_plus.html#plotting-cities-on-us-map",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "3.1 Plotting Cities on US Map",
    "text": "3.1 Plotting Cities on US Map\n\n# Sample city data\ncities_us &lt;- data.frame(\n  city = c(\"New Jersey\", \"New York\", \"Los Angeles\", \"Chicago\", \"Houston\", \"Phoenix\"),\n  lon = c(-74, -74.006, -118.2437, -87.6298, -95.3698, -112.074),\n  lat = c(40.9, 40.7128, 34.0522, 41.8781, 29.7604, 33.4484)\n)\n\n# Plot US map with cities\nus_plot +\n  geom_point(data = cities_us, aes(x = lon, y = lat), \n             color = \"red\", size = 3) +\n  # geom_label(data = cities_us, aes(x = lon, y = lat, label = city), \n  #                  size = 3, color = \"black\")\n  geom_label_repel(data = cities_us, aes(x = lon, y = lat, label = city), \n                    size = 3, color = \"black\")",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#plotting-cities-on-canada-map",
    "href": "coding/week_05/09_ggplot2_plus.html#plotting-cities-on-canada-map",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "3.2 Plotting Cities on Canada Map",
    "text": "3.2 Plotting Cities on Canada Map\n\n# Sample city data for Canada\ncities_canada &lt;- data.frame(\n  city = c(\"Toronto\", \"Vancouver\", \"Montreal\", \"Calgary\", \"Ottawa\"),\n  lon = c(-79.3832, -123.1216, -73.5673, -114.0719, -75.6972),\n  lat = c(43.6511, 49.2827, 45.5017, 51.0447, 45.4215)\n)\n\n# Plot Canada map with cities\ncanada_plot +\n  geom_point(data = cities_canada, aes(x = lon, y = lat), \n             color = \"blue\", size = 3) +\n  geom_label_repel(data = cities_canada, aes(x = lon, y = lat, label = city), \n                   size = 3, color = \"black\")",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#loading-and-plotting-shapefiles",
    "href": "coding/week_05/09_ggplot2_plus.html#loading-and-plotting-shapefiles",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "4.1 Loading and Plotting Shapefiles",
    "text": "4.1 Loading and Plotting Shapefiles\n\n# Load shapefile (replace 'path_to_shapefile' with your actual path)\n# usa_shapefile &lt;- st_read(\"path_to_shapefile/usa_shapefile.shp\")\n\n# Example using built-in dataset from `sf`\nnc &lt;- st_read(system.file(\"shape/nc.shp\", package = \"sf\"))\n\nReading layer `nc' from data source \n  `/Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/library/sf/shape/nc.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 100 features and 14 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965\nGeodetic CRS:  NAD27\n\n# Plot shapefile\nggplot(nc) +\n  geom_sf(fill = \"lightblue\", color = \"black\") +\n  labs(title = \"Shapefile Example: North Carolina Counties\") +\n  # Adjust scales for limits\n  scale_y_continuous(limits = c(34.5, 36))+\n  scale_x_continuous(limits = c(-82, -78))+\n  theme_minimal()",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#read-shp-of-canada-and-us",
    "href": "coding/week_05/09_ggplot2_plus.html#read-shp-of-canada-and-us",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "4.2 Read shp of Canada and US",
    "text": "4.2 Read shp of Canada and US\n\n## Load shp files\nusa_shp &lt;- st_read(\"shp_map/us/usa.shp\") %&gt;%\n  # Remove non-contiguous and territories\n  filter(!(NAME %in% c(\"Alaska\", \"District of Columbia\", \"Hawaii\", \"Puerto Rico\")))\n\nReading layer `usa' from data source \n  `/Users/acorrend/Documents/GitHub/plnt6800/coding/week_05/shp_map/us/usa.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 52 features and 9 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -179.1473 ymin: 17.88481 xmax: 179.7785 ymax: 71.35256\nGeodetic CRS:  NAD83\n\ncan_shp &lt;- st_read(\"shp_map/can/canada.shp\")\n\nReading layer `canada' from data source \n  `/Users/acorrend/Documents/GitHub/plnt6800/coding/week_05/shp_map/can/canada.shp' \n  using driver `ESRI Shapefile'\nSimple feature collection with 13 features and 6 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: -141.0181 ymin: 41.67695 xmax: -52.5823 ymax: 89.99943\nGeodetic CRS:  NAD83",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#create-objects-for-maps",
    "href": "coding/week_05/09_ggplot2_plus.html#create-objects-for-maps",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "4.3 Create objects for maps",
    "text": "4.3 Create objects for maps\n\n# Create list of selected provinces\nselected_provinces &lt;- c(\"Ontario\", \"Manitoba\", \"Quebec\")\n\n# Define coordinates for Ontario cities\nontario_cities &lt;- data.frame(\n  city = c(\"Toronto\", \"Ottawa\", \"Hamilton\", \"London\", \"Kingston\"),\n  lon = c(-79.3832, -75.6972, -79.8711, -81.2497, -76.4880),\n  lat = c(43.6511, 45.4215, 43.2557, 42.9834, 44.2312)\n)",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#define-function-to-customize-plot",
    "href": "coding/week_05/09_ggplot2_plus.html#define-function-to-customize-plot",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "4.4 Define function to customize plot",
    "text": "4.4 Define function to customize plot\n\ngeo_plot &lt;- function(x, y, z, title = NULL){\n  ggplot()+\n    geom_sf(data=x, fill = \"white\", color = \"black\") + # Provinces map\n  geom_sf(data=y, fill = \"white\", color = \"black\")+ # US map\n  # Adjust scales for lat and lon\n  scale_y_continuous(limits = c(41.8, 46))+\n  scale_x_continuous(limits = c(-84, -75), breaks = seq(-84,-74, by=1)) +\n  # Add cities with points\n  geom_point(data = z, aes(x = lon, y = lat, fill = city), \n             color = \"grey25\", shape = 21, size = 3, alpha = 0.95) +\n  # Scalebar\n  annotation_scale(tick_height = 0.3)+\n  # Text Notes for names of cities\n  geom_text_repel(data = z, \n                  aes(x=lon, y=lat, label = city), size = 3)+\n  # Name of PROVINCE\n  annotate(\"text\", x = -78, y = 45, label = \"ONTARIO\", \n           size = 4, fontface = \"bold\")+\n  # Name of Lakes\n  ## Ontario\n  annotate(\"text\", x = -77.8, y = 43.7, label = \"Lake Ontario\", \n           size = 3, fontface = \"italic\")+\n  ## Huron \n  annotate(\"text\", x = -82.5, y = 44.5, label = \"Lake \\nHuron\", \n           size = 3, fontface = \"italic\")+\n  # Add labels\n  labs(title = title, \n       x = \"Longitude\", y = \"Latitude\")+\n  # Adjust theme\n  theme_base()+\n  # reduce axis text size\n  theme(\n    panel.background = element_rect(fill = \"#bde0fe\"),\n    title = element_text(size = rel(.7)),\n    axis.title =  element_text(size = rel(.9), face = \"bold\"),\n    axis.text = element_text(size = rel(.5))\n    )\n}",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#plot",
    "href": "coding/week_05/09_ggplot2_plus.html#plot",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "4.5 Plot",
    "text": "4.5 Plot\n\n# Plot from function\ngeo_plot(x = can_shp, y = usa_shp, z = ontario_cities, \n         title = \"Ontario Map from SHP\")",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#loading-geojson-data",
    "href": "coding/week_05/09_ggplot2_plus.html#loading-geojson-data",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "5.1 Loading GeoJSON Data",
    "text": "5.1 Loading GeoJSON Data\n\n# Load Canada GeoJSON (replace with actual file path if available)\n# Read geojson for Canada\ncan_geojson &lt;- read_sf(\"geojson_maps/canada_provinces.geojson\")  %&gt;%  \n  # dplyr::filter(name == \"Ontario\")  %&gt;% \n  dplyr::filter(name %in% selected_provinces)  %&gt;% \n  dplyr::mutate(Province = name, \n                GEOID = cartodb_id)  %&gt;%  \n  dplyr::select(GEOID, Province, geometry)\n\n# Read geojson for US\nusa_geojson &lt;- read_sf(\"geojson_maps/us-states.json\")",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#plot-geojson",
    "href": "coding/week_05/09_ggplot2_plus.html#plot-geojson",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "5.2 Plot GEOJSON",
    "text": "5.2 Plot GEOJSON\n\n# Plot from function\ngeo_plot(x = can_geojson, y = usa_geojson, z = ontario_cities, \n         title = \"Ontario Map from GEOJSON\")",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#explanation",
    "href": "coding/week_05/09_ggplot2_plus.html#explanation",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "5.3 Explanation:",
    "text": "5.3 Explanation:\n\ngeojson_read(): Reads the GeoJSON file.\nst_as_sf(): Converts the data into an sf object for plotting.\ngeom_sf(): Plots the GeoJSON data.",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#ontario-map-with-leaflet",
    "href": "coding/week_05/09_ggplot2_plus.html#ontario-map-with-leaflet",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "6.1 Ontario Map with leaflet",
    "text": "6.1 Ontario Map with leaflet\n\n# Create interactive map\nontario_cities %&gt;%\nleaflet() %&gt;%\n  addTiles() %&gt;%\n# Add PINS\naddMarkers(~lon, ~lat, popup = ~city) %&gt;%\naddCircleMarkers(~lon, ~lat, popup = ~city, radius = 5, color = \"gold\",\n                  fillOpacity = 0.7) %&gt;%\n# Configure initial view of the map\nsetView(lng = -80, lat = 44, zoom = 6)",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_05/09_ggplot2_plus.html#explanation-1",
    "href": "coding/week_05/09_ggplot2_plus.html#explanation-1",
    "title": "Data Viz III: Geographic Mapping with ggplot2",
    "section": "6.2 Explanation:",
    "text": "6.2 Explanation:\n\naddTiles(): Adds the base map layer.\naddMarkers(): Plots city locations with popups displaying city names.\nsetView(): Centers the map on Toronto with a specified zoom level.",
    "crumbs": [
      "Lessons",
      "09-Data viz III"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html",
    "href": "coding/week_02/02_fundamentals_rpackages.html",
    "title": "Fundamentals of R Packages",
    "section": "",
    "text": "i. What Are R Packages?\nR packages are collections of functions, data, and documentation that extend the capabilities of R. They are designed to solve specific problems or add functionalities, such as data visualization, statistical modeling, or handling specific types of data.\nAnalogy: Think of R as a toolbox 🧰 and packages as individual tools 🔧 you can add to enhance its utility.\n\n\n\n\n\n\nImportant\n\n\n\nCore Components:\n\nFunctions: Ready-made commands to perform tasks.\nData: Preloaded datasets for analysis or examples.\nDocumentation: Manuals explaining how to use the package.\n\n\n\nii. Why Are R Packages Important?\n\nThey extend functionality beyond base features.\nEnable efficient workflows by using pre-written and optimized code.\nProvide community-contributed solutions for a wide variety of domains (e.g., agriculture, bioinformatics, machine learning).\n\niii. Where to Find R Packages?\n\nCRAN (Comprehensive R Archive Network): The primary repository for R packages. Well-maintained and includes thousands of packages.\nBioconductor: Specialized in bioinformatics and genomics.\nGitHub: A platform where developers host and share experimental or in-development packages.",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#a.-installing-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#a.-installing-packages",
    "title": "Fundamentals of R Packages",
    "section": "a. Installing packages",
    "text": "a. Installing packages\nTo install a package from CRAN, use:\n\ninstall.packages(\"dplyr\")\n\nTo install a development version of a package from GitHub, use:\n\ndevtools::install_github(\"rstudio/ggplot2\")\n\nChecking installed packages\n\ninstalled.packages()",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#b.-loading-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#b.-loading-packages",
    "title": "Fundamentals of R Packages",
    "section": "b. Loading Packages",
    "text": "b. Loading Packages\nOnce installed, load a package using:\n\nlibrary(dplyr)\n\nOr alternatively, you may use packages like pacman:\n\nlibrary(pacman)\npacman::p_load(dplyr, ggplot2)\n\nOr easypackages:\n\nlibrary(easypackages)\neasypackages::libraries(dplyr, ggplot2)",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#c.-updating-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#c.-updating-packages",
    "title": "Fundamentals of R Packages",
    "section": "c. Updating packages",
    "text": "c. Updating packages\n\nupdate.packages()",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#d.-unload-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#d.-unload-packages",
    "title": "Fundamentals of R Packages",
    "section": "d. Unload packages",
    "text": "d. Unload packages\n\ndetach(\"package:ggplot2\", unload = TRUE)",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#e.-uninstall-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#e.-uninstall-packages",
    "title": "Fundamentals of R Packages",
    "section": "e. Uninstall packages",
    "text": "e. Uninstall packages\n\nremove.packages(\"ggplot2\")",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#a.-start-with-the-right-packages",
    "href": "coding/week_02/02_fundamentals_rpackages.html#a.-start-with-the-right-packages",
    "title": "Fundamentals of R Packages",
    "section": "a. Start with the Right Packages:",
    "text": "a. Start with the Right Packages:\nUse foundational and well supported packages (e.g. tidyverse, data.table).",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#b.-stay-curious",
    "href": "coding/week_02/02_fundamentals_rpackages.html#b.-stay-curious",
    "title": "Fundamentals of R Packages",
    "section": "b. Stay Curious:",
    "text": "b. Stay Curious:\nExplore new packages via CRAN Task Views (e.g., Agriculture Task View).",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#c.-version-control",
    "href": "coding/week_02/02_fundamentals_rpackages.html#c.-version-control",
    "title": "Fundamentals of R Packages",
    "section": "c. Version Control:",
    "text": "c. Version Control:\nWhen becoming an advanced user, you could implement renv or packrat to manage package versions for reproducible analysis.",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#a.-ggplot2-for-data-visualization",
    "href": "coding/week_02/02_fundamentals_rpackages.html#a.-ggplot2-for-data-visualization",
    "title": "Fundamentals of R Packages",
    "section": "a. ggplot2 for data visualization:",
    "text": "a. ggplot2 for data visualization:\n\nlibrary(ggplot2)\nggplot(mtcars, aes(x = mpg, y = hp)) + geom_point()",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#b.-dplyr-for-data-manipulation",
    "href": "coding/week_02/02_fundamentals_rpackages.html#b.-dplyr-for-data-manipulation",
    "title": "Fundamentals of R Packages",
    "section": "b. dplyr for data manipulation:",
    "text": "b. dplyr for data manipulation:\n\nlibrary(dplyr)\nmtcars %&gt;% filter(mpg &gt; 20) %&gt;% summarize(mean_hp = mean(hp))\n\n  mean_hp\n1    88.5",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#c.-agridat",
    "href": "coding/week_02/02_fundamentals_rpackages.html#c.-agridat",
    "title": "Fundamentals of R Packages",
    "section": "c. agridat",
    "text": "c. agridat\nThe agridat package contains datasets related to agriculture, such as crop yields, experimental designs, and climate data. Let’s use an example from this package:\n\n# Load the package\nlibrary(agridat)\n# Load an example dataset\ndata(rothamsted.oats, package = 'agridat')\nhead(rothamsted.oats)\n\n  block trt  grain straw row col\n1     x  oa 61.375  83.0  12   1\n2     x 2me 68.750 130.0  12   2\n3     x 2sl 64.250 100.0  12   3\n4     x  ob 65.500  96.0  12   4\n5     w 2sl 79.625 130.5  12   5\n6     w  oa 79.250 122.0  12   6\n\n# Visualize crop yields\nlibrary(ggplot2)\nggplot(rothamsted.oats, aes(x = trt, y = grain, fill = as.factor(block))) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(\n    title = \"Grain Yields in Rothamsted Oats Experiment\",\n    x = \"Treatment\",\n    y = \"Grain Yield (grams/plot)\",\n    fill = \"Block\"\n  ) +\n  theme_minimal()",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#d.-agricolae",
    "href": "coding/week_02/02_fundamentals_rpackages.html#d.-agricolae",
    "title": "Fundamentals of R Packages",
    "section": "d. agricolae",
    "text": "d. agricolae\nThe agricolae package in R is a comprehensive toolset designed for statistical analysis and visualization of agricultural experiments. It is particularly useful for researchers and practitioners working in crop science, agronomy, and other fields of agricultural research.\nIt provides methods for designing experiments, analyzing experimental data, and visualizing results, particularly for data collected in agricultural and biological research.\n\n\n\n\n\n\nNote\n\n\n\nIt supports:\n\nExperimental Designs: Generate designs for field experiments like randomized complete block design (RCBD), Latin square, factorial experiments, and others.\nStatistical Analysis: Analyze variance (ANOVA), perform post-hoc tests (e.g., LSD, Tukey HSD), and assess experimental data.\nVisualization: Create plots for results, including mean comparisons, dendrograms, and histograms.\nAgronomic Tools: Calculate indices like stability for crop yields or pest/disease control measures.\n\n\n\n\ni. Data analysis\n\n# Load agricolae package\nlibrary(agricolae)\n\n# Simulate agricultural data\ndata &lt;- data.frame(\n  treatment = rep(c(\"A\", \"B\", \"C\"), each = 5),\n  yield = c(50, 55, 52, 51, 54,   # Yields for Treatment A\n            60, 62, 59, 61, 63,   # Yields for Treatment B\n            48, 46, 50, 49, 47)   # Yields for Treatment C\n)\n\n# Display the dataset\nprint(data)\n\n   treatment yield\n1          A    50\n2          A    55\n3          A    52\n4          A    51\n5          A    54\n6          B    60\n7          B    62\n8          B    59\n9          B    61\n10         B    63\n11         C    48\n12         C    46\n13         C    50\n14         C    49\n15         C    47\n\n# Perform ANOVA\nanova_result &lt;- aov(yield ~ treatment, data = data)\nsummary(anova_result)\n\n            Df Sum Sq Mean Sq F value   Pr(&gt;F)    \ntreatment    2  437.2   218.6   70.52 2.32e-07 ***\nResiduals   12   37.2     3.1                     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n# Perform LSD test for pairwise comparison\nlsd_result &lt;- LSD.test(anova_result, \"treatment\", console = TRUE)\n\n\nStudy: anova_result ~ \"treatment\"\n\nLSD t Test for yield \n\nMean Square Error:  3.1 \n\ntreatment,  means and individual ( 95 %) CI\n\n  yield      std r        se     LCL     UCL Min Max Q25 Q50 Q75\nA  52.4 2.073644 5 0.7874008 50.6844 54.1156  50  55  51  52  54\nB  61.0 1.581139 5 0.7874008 59.2844 62.7156  59  63  60  61  62\nC  48.0 1.581139 5 0.7874008 46.2844 49.7156  46  50  47  48  49\n\nAlpha: 0.05 ; DF Error: 12\nCritical Value of t: 2.178813 \n\nleast Significant Difference: 2.426223 \n\nTreatments with the same letter are not significantly different.\n\n  yield groups\nB  61.0      a\nA  52.4      b\nC  48.0      c\n\n# Could also run Tukey HSD, & Duncan's Test\n\n# Plot LSD results\nplot(lsd_result, main = \"LSD Test Results for Treatment Yields\")\n\n\n\n\n\n\n\n\n\n\nii. Design of experiments\nYou can generate layouts for randomized complete block designs (RCBD), Latin squares, Graeco-Latin squares, factorial experiments, and split-plot designs\n\ndesign &lt;- design.rcbd(trt = c(\"A\", \"B\", \"C\"), r = 3)\nprint(design)\n\n$parameters\n$parameters$design\n[1] \"rcbd\"\n\n$parameters$trt\n[1] \"A\" \"B\" \"C\"\n\n$parameters$r\n[1] 3\n\n$parameters$serie\n[1] 2\n\n$parameters$seed\n[1] 2000902035\n\n$parameters$kinds\n[1] \"Super-Duper\"\n\n$parameters[[7]]\n[1] TRUE\n\n\n$sketch\n     [,1] [,2] [,3]\n[1,] \"A\"  \"B\"  \"C\" \n[2,] \"A\"  \"C\"  \"B\" \n[3,] \"C\"  \"A\"  \"B\" \n\n$book\n  plots block c(\"A\", \"B\", \"C\")\n1   101     1                A\n2   102     1                B\n3   103     1                C\n4   201     2                A\n5   202     2                C\n6   203     2                B\n7   301     3                C\n8   302     3                A\n9   303     3                B",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_02/02_fundamentals_rpackages.html#e.-soiltestcorr",
    "href": "coding/week_02/02_fundamentals_rpackages.html#e.-soiltestcorr",
    "title": "Fundamentals of R Packages",
    "section": "e. soiltestcorr",
    "text": "e. soiltestcorr\nThis package assists users on reproducible regression analysis of relationships between crop relative yield (ry) and soil test values (stv) under different approaches.\nFor example, we can fit a linear-plateu model the a dataset with:\n\nlibrary(soiltestcorr)\n\ndata_freitas &lt;- soiltestcorr::freitas1966\n\nplot_lp &lt;- linear_plateau(data = data_freitas,\n                          stv = STK, ry = RY, plot = TRUE)\n\nplot_lp",
    "crumbs": [
      "Lessons",
      "02-Fundamentals of packages"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html",
    "href": "coding/week_03/04_datawrangling_01.html",
    "title": "Transforming Ag data with dplyr",
    "section": "",
    "text": "This lesson introduces the concept of tidy data, and a few basic data wrangling techniques using dplyr package. Today, we are using dplyr and datasets from the agridat package. If you don’t have them installed, you can do so by running:\n\n\n\nlibrary(pacman)\np_load(agridat) # Agridat datasets\np_load(dplyr) # dplyr for data wrangling\np_load(skimr) # skimr for quick exploration of the data",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#required-packages-for-today",
    "href": "coding/week_03/04_datawrangling_01.html#required-packages-for-today",
    "title": "Transforming Ag data with dplyr",
    "section": "",
    "text": "library(pacman)\np_load(agridat) # Agridat datasets\np_load(dplyr) # dplyr for data wrangling\np_load(skimr) # skimr for quick exploration of the data",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#what-is-a-data-frame",
    "href": "coding/week_03/04_datawrangling_01.html#what-is-a-data-frame",
    "title": "Transforming Ag data with dplyr",
    "section": "2.1 What is a Data Frame?",
    "text": "2.1 What is a Data Frame?\nA data frame is a two-dimensional table-like structure in R, where columns can contain different types of data (e.g., numeric, character). It is the default structure for datasets loaded from CSV files or data packages.\n\n2.1.1 open a data frame\n\n# Load the wheat dataset from agricolae (which is a data frame)\nwheat_data &lt;- agridat::payne.wheat\n\n# Check the structure of the data frame\nstr(wheat_data)\n\n'data.frame':   480 obs. of  4 variables:\n $ rotation: Factor w/ 6 levels \"AB\",\"AF\",\"Lc3\",..: 1 1 1 1 2 2 2 2 5 5 ...\n $ nitro   : int  0 70 140 210 0 70 140 210 0 70 ...\n $ year    : int  1981 1981 1981 1981 1981 1981 1981 1981 1981 1981 ...\n $ yield   : num  3.84 6.59 7.49 7.39 3.06 6.32 7.61 7.78 5.82 7.52 ...",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#what-is-a-tibble",
    "href": "coding/week_03/04_datawrangling_01.html#what-is-a-tibble",
    "title": "Transforming Ag data with dplyr",
    "section": "2.2 What is a Tibble?",
    "text": "2.2 What is a Tibble?\nA tibble is a modern version of a data frame, introduced by the tibble package. It offers several improvements:\n•   Tibbles don’t convert characters to factors by default.\n•   Printing is more concise and doesn’t overwhelm you with too much data.\n•   Tibbles are more explicit with column types when printed.\n\n2.2.1 create a tibble\n\n# Convert the wheat data frame to a tibble\nwheat_tibble &lt;- as_tibble(wheat_data)\n\n# Check the structure of the tibble\nwheat_tibble\n\n# A tibble: 480 × 4\n   rotation nitro  year yield\n   &lt;fct&gt;    &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1 AB           0  1981  3.84\n 2 AB          70  1981  6.59\n 3 AB         140  1981  7.49\n 4 AB         210  1981  7.39\n 5 AF           0  1981  3.06\n 6 AF          70  1981  6.32\n 7 AF         140  1981  7.61\n 8 AF         210  1981  7.78\n 9 Ln3          0  1981  5.82\n10 Ln3         70  1981  7.52\n# ℹ 470 more rows",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#iii.-key-differences-between-data-frames-and-tibbles",
    "href": "coding/week_03/04_datawrangling_01.html#iii.-key-differences-between-data-frames-and-tibbles",
    "title": "Transforming Ag data with dplyr",
    "section": "2.3 iii. Key Differences between Data Frames and Tibbles",
    "text": "2.3 iii. Key Differences between Data Frames and Tibbles\n1.  **Printing**:\n• Data Frames print the entire dataset unless you limit the number of rows. No information about column types is displayed. • Tibbles print only the first 10 rows and automatically show column types.\n\n2.3.1 Example:\n\n# Print the entire data frame\nprint(wheat_data)\n\n    rotation nitro year yield\n1         AB     0 1981  3.84\n2         AB    70 1981  6.59\n3         AB   140 1981  7.49\n4         AB   210 1981  7.39\n5         AF     0 1981  3.06\n6         AF    70 1981  6.32\n7         AF   140 1981  7.61\n8         AF   210 1981  7.78\n9        Ln3     0 1981  5.82\n10       Ln3    70 1981  7.52\n11       Ln3   140 1981  8.12\n12       Ln3   210 1981  7.40\n13       Ln8     0 1981  4.71\n14       Ln8    70 1981  6.52\n15       Ln8   140 1981  8.03\n16       Ln8   210 1981  7.83\n17       Lc3     0 1981  5.35\n18       Lc3    70 1981  6.70\n19       Lc3   140 1981  7.69\n20       Lc3   210 1981  7.53\n21       Lc8     0 1981  6.47\n22       Lc8    70 1981  7.84\n23       Lc8   140 1981  7.98\n24       Lc8   210 1981  7.68\n25        AB     0 1982  4.47\n26        AB    70 1982  6.38\n27        AB   140 1982  7.82\n28        AB   210 1982  8.13\n29        AF     0 1982  4.30\n30        AF    70 1982  6.82\n31        AF   140 1982  8.16\n32        AF   210 1982  8.52\n33       Ln3     0 1982  5.37\n34       Ln3    70 1982  7.91\n35       Ln3   140 1982  7.53\n36       Ln3   210 1982  8.46\n37       Ln8     0 1982  5.55\n38       Ln8    70 1982  8.04\n39       Ln8   140 1982  8.27\n40       Ln8   210 1982  7.31\n41       Lc3     0 1982  5.16\n42       Lc3    70 1982  7.81\n43       Lc3   140 1982  8.38\n44       Lc3   210 1982  7.40\n45       Lc8     0 1982  6.56\n46       Lc8    70 1982  8.36\n47       Lc8   140 1982  8.60\n48       Lc8   210 1982  8.41\n49        AB     0 1983  4.11\n50        AB    70 1983  6.28\n51        AB   140 1983  8.70\n52        AB   210 1983  8.17\n53        AF     0 1983  3.76\n54        AF    70 1983  6.79\n55        AF   140 1983  8.50\n56        AF   210 1983  9.43\n57       Ln3     0 1983  3.86\n58       Ln3    70 1983  7.05\n59       Ln3   140 1983  8.06\n60       Ln3   210 1983  8.28\n61       Ln8     0 1983  4.45\n62       Ln8    70 1983  7.23\n63       Ln8   140 1983  7.48\n64       Ln8   210 1983  6.93\n65       Lc3     0 1983  6.36\n66       Lc3    70 1983  9.67\n67       Lc3   140 1983  9.34\n68       Lc3   210 1983  8.40\n69       Lc8     0 1983  7.39\n70       Lc8    70 1983  9.64\n71       Lc8   140 1983  8.80\n72       Lc8   210 1983  8.66\n73        AB     0 1984  3.66\n74        AB    70 1984  6.56\n75        AB   140 1984  7.74\n76        AB   210 1984  9.41\n77        AF     0 1984  4.28\n78        AF    70 1984  8.94\n79        AF   140 1984  9.12\n80        AF   210 1984  9.35\n81       Ln3     0 1984  4.92\n82       Ln3    70 1984  7.66\n83       Ln3   140 1984  9.75\n84       Ln3   210 1984 10.35\n85       Ln8     0 1984  5.46\n86       Ln8    70 1984  8.68\n87       Ln8   140 1984  9.20\n88       Ln8   210 1984 10.33\n89       Lc3     0 1984  7.18\n90       Lc3    70 1984 11.06\n91       Lc3   140 1984 10.52\n92       Lc3   210 1984  9.88\n93       Lc8     0 1984  7.51\n94       Lc8    70 1984  9.66\n95       Lc8   140 1984 11.04\n96       Lc8   210 1984  9.36\n97        AB     0 1985  2.39\n98        AB    70 1985  5.90\n99        AB   140 1985  7.76\n100       AB   210 1985  8.62\n101       AF     0 1985  2.03\n102       AF    70 1985  5.46\n103       AF   140 1985  7.72\n104       AF   210 1985  9.20\n105      Ln3     0 1985  4.24\n106      Ln3    70 1985  7.26\n107      Ln3   140 1985  8.26\n108      Ln3   210 1985  9.69\n109      Ln8     0 1985  4.07\n110      Ln8    70 1985  6.98\n111      Ln8   140 1985  8.39\n112      Ln8   210 1985  8.55\n113      Lc3     0 1985  4.97\n114      Lc3    70 1985  7.64\n115      Lc3   140 1985  9.57\n116      Lc3   210 1985  8.84\n117      Lc8     0 1985  4.44\n118      Lc8    70 1985  8.08\n119      Lc8   140 1985  8.76\n120      Lc8   210 1985 10.19\n121       AB     0 1986  4.17\n122       AB    70 1986  6.91\n123       AB   140 1986  7.21\n124       AB   210 1986  8.53\n125       AF     0 1986  4.08\n126       AF    70 1986  5.08\n127       AF   140 1986  6.32\n128       AF   210 1986  7.88\n129      Ln3     0 1986  3.36\n130      Ln3    70 1986  5.65\n131      Ln3   140 1986  6.62\n132      Ln3   210 1986  6.05\n133      Ln8     0 1986  4.68\n134      Ln8    70 1986  6.55\n135      Ln8   140 1986  7.20\n136      Ln8   210 1986  6.84\n137      Lc3     0 1986  6.14\n138      Lc3    70 1986  7.15\n139      Lc3   140 1986  6.89\n140      Lc3   210 1986  6.20\n141      Lc8     0 1986  6.09\n142      Lc8    70 1986  7.31\n143      Lc8   140 1986  6.85\n144      Lc8   210 1986  6.75\n145       AB     0 1987  4.39\n146       AB    70 1987  6.18\n147       AB   140 1987  6.75\n148       AB   210 1987  7.84\n149       AF     0 1987  3.02\n150       AF    70 1987  5.56\n151       AF   140 1987  6.60\n152       AF   210 1987  6.43\n153      Ln3     0 1987  4.41\n154      Ln3    70 1987  6.55\n155      Ln3   140 1987  7.59\n156      Ln3   210 1987  7.13\n157      Ln8     0 1987  4.80\n158      Ln8    70 1987  6.74\n159      Ln8   140 1987  7.86\n160      Ln8   210 1987  7.00\n161      Lc3     0 1987  5.51\n162      Lc3    70 1987  7.24\n163      Lc3   140 1987  7.74\n164      Lc3   210 1987  7.61\n165      Lc8     0 1987  5.26\n166      Lc8    70 1987  7.48\n167      Lc8   140 1987  8.31\n168      Lc8   210 1987  8.13\n169       AB     0 1988  2.98\n170       AB    70 1988  6.28\n171       AB   140 1988  6.77\n172       AB   210 1988  6.20\n173       AF     0 1988  3.09\n174       AF    70 1988  6.60\n175       AF   140 1988  6.63\n176       AF   210 1988  6.61\n177      Ln3     0 1988  4.01\n178      Ln3    70 1988  6.77\n179      Ln3   140 1988  7.12\n180      Ln3   210 1988  6.14\n181      Ln8     0 1988  4.34\n182      Ln8    70 1988  6.73\n183      Ln8   140 1988  7.46\n184      Ln8   210 1988  7.23\n185      Lc3     0 1988  5.68\n186      Lc3    70 1988  7.39\n187      Lc3   140 1988  7.54\n188      Lc3   210 1988  7.51\n189      Lc8     0 1988  5.26\n190      Lc8    70 1988  7.87\n191      Lc8   140 1988  6.94\n192      Lc8   210 1988  7.06\n193       AB     0 1989  1.16\n194       AB    70 1989  3.94\n195       AB   140 1989  4.58\n196       AB   210 1989  4.74\n197       AF     0 1989  2.80\n198       AF    70 1989  4.92\n199       AF   140 1989  5.17\n200       AF   210 1989  5.82\n201      Ln3     0 1989  4.04\n202      Ln3    70 1989  5.94\n203      Ln3   140 1989  6.10\n204      Ln3   210 1989  6.04\n205      Ln8     0 1989  3.77\n206      Ln8    70 1989  5.58\n207      Ln8   140 1989  5.56\n208      Ln8   210 1989  4.91\n209      Lc3     0 1989  5.45\n210      Lc3    70 1989  6.28\n211      Lc3   140 1989  6.12\n212      Lc3   210 1989  5.81\n213      Lc8     0 1989  4.91\n214      Lc8    70 1989  6.69\n215      Lc8   140 1989  6.39\n216      Lc8   210 1989  5.06\n217       AB     0 1990  1.47\n218       AB    70 1990  4.94\n219       AB   140 1990  5.83\n220       AB   210 1990  6.33\n221       AF     0 1990  1.38\n222       AF    70 1990  5.72\n223       AF   140 1990  6.30\n224       AF   210 1990  5.18\n225      Ln3     0 1990  1.73\n226      Ln3    70 1990  4.94\n227      Ln3   140 1990  5.43\n228      Ln3   210 1990  6.17\n229      Ln8     0 1990  2.62\n230      Ln8    70 1990  5.79\n231      Ln8   140 1990  5.08\n232      Ln8   210 1990  5.25\n233      Lc3     0 1990  3.59\n234      Lc3    70 1990  6.06\n235      Lc3   140 1990  7.20\n236      Lc3   210 1990  6.42\n237      Lc8     0 1990  3.31\n238      Lc8    70 1990  6.51\n239      Lc8   140 1990  6.65\n240      Lc8   210 1990  6.99\n241       AB     0 1991  4.48\n242       AB    70 1991  8.56\n243       AB   140 1991  9.94\n244       AB   210 1991 10.23\n245       AF     0 1991  3.46\n246       AF    70 1991  8.00\n247       AF   140 1991  9.75\n248       AF   210 1991 10.57\n249      Ln3     0 1991  6.75\n250      Ln3    70 1991  8.85\n251      Ln3   140 1991  9.96\n252      Ln3   210 1991 10.41\n253      Ln8     0 1991  5.94\n254      Ln8    70 1991  8.83\n255      Ln8   140 1991  9.64\n256      Ln8   210 1991  9.75\n257      Lc3     0 1991  6.47\n258      Lc3    70 1991  9.37\n259      Lc3   140 1991 10.46\n260      Lc3   210 1991 10.48\n261      Lc8     0 1991  6.08\n262      Lc8    70 1991  8.81\n263      Lc8   140 1991  9.63\n264      Lc8   210 1991 10.10\n265       AB     0 1992  6.31\n266       AB    70 1992  7.84\n267       AB   140 1992  7.21\n268       AB   210 1992  6.81\n269       AF     0 1992  3.82\n270       AF    70 1992  8.05\n271       AF   140 1992  8.21\n272       AF   210 1992  7.59\n273      Ln3     0 1992  2.73\n274      Ln3    70 1992  6.47\n275      Ln3   140 1992  7.49\n276      Ln3   210 1992  7.26\n277      Ln8     0 1992  4.19\n278      Ln8    70 1992  7.17\n279      Ln8   140 1992  7.54\n280      Ln8   210 1992  6.67\n281      Lc3     0 1992  6.33\n282      Lc3    70 1992  7.48\n283      Lc3   140 1992  6.13\n284      Lc3   210 1992  4.79\n285      Lc8     0 1992  7.11\n286      Lc8    70 1992  6.65\n287      Lc8   140 1992  6.45\n288      Lc8   210 1992  6.14\n289       AB     0 1993  3.11\n290       AB    70 1993  5.92\n291       AB   140 1993  5.89\n292       AB   210 1993  6.63\n293       AF     0 1993  2.86\n294       AF    70 1993  5.79\n295       AF   140 1993  6.72\n296       AF   210 1993  7.37\n297      Ln3     0 1993  3.13\n298      Ln3    70 1993  5.40\n299      Ln3   140 1993  6.60\n300      Ln3   210 1993  6.52\n301      Ln8     0 1993  3.42\n302      Ln8    70 1993  5.16\n303      Ln8   140 1993  6.47\n304      Ln8   210 1993  6.55\n305      Lc3     0 1993  5.58\n306      Lc3    70 1993  7.01\n307      Lc3   140 1993  7.69\n308      Lc3   210 1993  7.91\n309      Lc8     0 1993  6.08\n310      Lc8    70 1993  7.03\n311      Lc8   140 1993  7.20\n312      Lc8   210 1993  7.69\n313       AB     0 1994  0.93\n314       AB    70 1994  3.94\n315       AB   140 1994  4.04\n316       AB   210 1994  3.51\n317       AF     0 1994  1.80\n318       AF    70 1994  5.32\n319       AF   140 1994  8.08\n320       AF   210 1994  8.55\n321      Ln3     0 1994  4.76\n322      Ln3    70 1994  6.16\n323      Ln3   140 1994  7.35\n324      Ln3   210 1994  7.14\n325      Ln8     0 1994  3.64\n326      Ln8    70 1994  5.14\n327      Ln8   140 1994  7.00\n328      Ln8   210 1994  7.16\n329      Lc3     0 1994  5.06\n330      Lc3    70 1994  6.00\n331      Lc3   140 1994  6.28\n332      Lc3   210 1994  7.50\n333      Lc8     0 1994  3.46\n334      Lc8    70 1994  6.48\n335      Lc8   140 1994  6.07\n336      Lc8   210 1994  7.53\n337       AB     0 1995  1.30\n338       AB    70 1995  4.21\n339       AB   140 1995  4.35\n340       AB   210 1995  4.35\n341       AF     0 1995  1.27\n342       AF    70 1995  3.82\n343       AF   140 1995  4.60\n344       AF   210 1995  4.96\n345      Ln3     0 1995  2.17\n346      Ln3    70 1995  5.01\n347      Ln3   140 1995  5.39\n348      Ln3   210 1995  5.79\n349      Ln8     0 1995  2.52\n350      Ln8    70 1995  5.71\n351      Ln8   140 1995  5.36\n352      Ln8   210 1995  6.53\n353      Lc3     0 1995  2.57\n354      Lc3    70 1995  5.70\n355      Lc3   140 1995  6.46\n356      Lc3   210 1995  5.78\n357      Lc8     0 1995  3.52\n358      Lc8    70 1995  6.60\n359      Lc8   140 1995  6.36\n360      Lc8   210 1995  6.14\n361       AB     0 1996  1.19\n362       AB    70 1996  7.24\n363       AB   140 1996  7.80\n364       AB   210 1996  8.43\n365       AF     0 1996  0.65\n366       AF    70 1996  6.60\n367       AF   140 1996  7.69\n368       AF   210 1996  7.79\n369      Ln3     0 1996  3.82\n370      Ln3    70 1996  7.19\n371      Ln3   140 1996  7.15\n372      Ln3   210 1996  8.41\n373      Ln8     0 1996  6.37\n374      Ln8    70 1996  8.23\n375      Ln8   140 1996  8.77\n376      Ln8   210 1996  8.46\n377      Lc3     0 1996  5.23\n378      Lc3    70 1996  7.76\n379      Lc3   140 1996  8.19\n380      Lc3   210 1996  8.67\n381      Lc8     0 1996  5.73\n382      Lc8    70 1996  7.97\n383      Lc8   140 1996  8.48\n384      Lc8   210 1996  8.28\n385       AB     0 1997  1.58\n386       AB    70 1997  5.73\n387       AB   140 1997  7.37\n388       AB   210 1997  7.88\n389       AF     0 1997  2.40\n390       AF    70 1997  6.52\n391       AF   140 1997  9.25\n392       AF   210 1997  9.24\n393      Ln3     0 1997  1.74\n394      Ln3    70 1997  3.83\n395      Ln3   140 1997  5.15\n396      Ln3   210 1997  5.02\n397      Ln8     0 1997  2.53\n398      Ln8    70 1997  6.20\n399      Ln8   140 1997  6.93\n400      Ln8   210 1997  7.25\n401      Lc3     0 1997  4.40\n402      Lc3    70 1997  7.70\n403      Lc3   140 1997  8.01\n404      Lc3   210 1997  8.30\n405      Lc8     0 1997  4.10\n406      Lc8    70 1997  6.78\n407      Lc8   140 1997  7.36\n408      Lc8   210 1997  7.43\n409       AB     0 1998  3.21\n410       AB    70 1998  6.70\n411       AB   140 1998  9.35\n412       AB   210 1998 10.26\n413       AF     0 1998  2.52\n414       AF    70 1998  6.35\n415       AF   140 1998  8.80\n416       AF   210 1998  9.72\n417      Ln3     0 1998  3.77\n418      Ln3    70 1998  7.13\n419      Ln3   140 1998  8.67\n420      Ln3   210 1998  9.62\n421      Ln8     0 1998  4.97\n422      Ln8    70 1998  7.77\n423      Ln8   140 1998  9.21\n424      Ln8   210 1998  9.24\n425      Lc3     0 1998  4.78\n426      Lc3    70 1998  7.48\n427      Lc3   140 1998  8.50\n428      Lc3   210 1998  8.75\n429      Lc8     0 1998  4.11\n430      Lc8    70 1998  7.55\n431      Lc8   140 1998  9.01\n432      Lc8   210 1998  8.98\n433       AB     0 1999  0.00\n434       AB    70 1999  1.97\n435       AB   140 1999  3.44\n436       AB   210 1999  2.28\n437       AF     0 1999  0.52\n438       AF    70 1999  6.55\n439       AF   140 1999  7.53\n440       AF   210 1999  8.48\n441      Ln3     0 1999  1.69\n442      Ln3    70 1999  6.58\n443      Ln3   140 1999  7.58\n444      Ln3   210 1999  7.83\n445      Ln8     0 1999  3.42\n446      Ln8    70 1999  6.59\n447      Ln8   140 1999  8.26\n448      Ln8   210 1999  6.51\n449      Lc3     0 1999  4.42\n450      Lc3    70 1999  7.27\n451      Lc3   140 1999  8.65\n452      Lc3   210 1999  9.54\n453      Lc8     0 1999  1.79\n454      Lc8    70 1999  4.65\n455      Lc8   140 1999  5.54\n456      Lc8   210 1999  4.95\n457       AB     0 2000  1.45\n458       AB    70 2000  4.54\n459       AB   140 2000  4.52\n460       AB   210 2000  5.53\n461       AF     0 2000  0.96\n462       AF    70 2000  4.87\n463       AF   140 2000  6.28\n464       AF   210 2000  7.39\n465      Ln3     0 2000  3.40\n466      Ln3    70 2000  7.06\n467      Ln3   140 2000  8.64\n468      Ln3   210 2000  8.71\n469      Ln8     0 2000  3.42\n470      Ln8    70 2000  6.58\n471      Ln8   140 2000  7.22\n472      Ln8   210 2000  7.49\n473      Lc3     0 2000  5.05\n474      Lc3    70 2000  8.24\n475      Lc3   140 2000  8.96\n476      Lc3   210 2000 10.33\n477      Lc8     0 2000  4.31\n478      Lc8    70 2000  7.47\n479      Lc8   140 2000  8.95\n480      Lc8   210 2000  9.65\n\n# Print the tibble (shows only first 10 rows and column types)\nprint(wheat_tibble)\n\n# A tibble: 480 × 4\n   rotation nitro  year yield\n   &lt;fct&gt;    &lt;int&gt; &lt;int&gt; &lt;dbl&gt;\n 1 AB           0  1981  3.84\n 2 AB          70  1981  6.59\n 3 AB         140  1981  7.49\n 4 AB         210  1981  7.39\n 5 AF           0  1981  3.06\n 6 AF          70  1981  6.32\n 7 AF         140  1981  7.61\n 8 AF         210  1981  7.78\n 9 Ln3          0  1981  5.82\n10 Ln3         70  1981  7.52\n# ℹ 470 more rows",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#why-using-r-packages",
    "href": "coding/week_03/04_datawrangling_01.html#why-using-r-packages",
    "title": "Transforming Ag data with dplyr",
    "section": "3.1 Why using R Packages? 💡",
    "text": "3.1 Why using R Packages? 💡\n\nEfficiency: Avoid rewriting code for common tasks.\nConsistency: Standardized code structure and naming conventions.\nReproducibility: Ensures that your work is easier to share and reproduce.\nIntuitive: R packages use functions with intuitive names of functions, so you can spend less time learning the code & more time learning to solve practical problems.",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#example-1-mutate",
    "href": "coding/week_03/04_datawrangling_01.html#example-1-mutate",
    "title": "Transforming Ag data with dplyr",
    "section": "3.2 Example 1: mutate()",
    "text": "3.2 Example 1: mutate()\n\nPackages like dplyr simplify tasks by providing clean, concise code for data manipulation.\n\n\n\n1. Create a new column: total, which is the sum of two existing columns (var1 and var2).\n\n\n\n3.2.0.1 Base R version\n\n\n# Sample data\ndf &lt;- data.frame(var1 = c(1, 2, 3), var2 = c(4, 5, 6))\n\n# Adding a new column using base R\ndf$total &lt;- df$var1 + df$var2\n\n\n\n\n\n3.2.0.2 dplyr package (Tidyverse)\nlibrary(dplyr)\n\n# Using mutate to add a new column\ndf &lt;- df %&gt;%\n  mutate(total = var1 + var2)",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#example-2-filter",
    "href": "coding/week_03/04_datawrangling_01.html#example-2-filter",
    "title": "Transforming Ag data with dplyr",
    "section": "3.3 Example 2: filter()",
    "text": "3.3 Example 2: filter()\n\n2. Filtering: get values of var1 greater than 2.\n\n\n\n3.3.0.1 Base R version\n\n# Filter rows using base R\nfiltered_df &lt;- df[df$var1 &gt; 2, ]\n\n\n\n\n\n3.3.0.2 dplyr package (Tidyverse)\n# Filter rows using dplyr\nfiltered_df &lt;- filter(data = df, var1 &gt; 2)",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#example-3-select",
    "href": "coding/week_03/04_datawrangling_01.html#example-3-select",
    "title": "Transforming Ag data with dplyr",
    "section": "3.4 Example 3: select()",
    "text": "3.4 Example 3: select()\n\n3. Select specific variables: get var1 and var3.\n\n\n\n\n3.4.0.1 Base R version\n# Select columns using base R\nselected_df &lt;- df[ , c(\"var1\",\"var3\")]\n\n\n\n\n\n3.4.0.2 dplyr package (Tidyverse)\n# Filter rows using dplyr\nfiltered_df &lt;- select(data = df, var1, var3)",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#inspect-data",
    "href": "coding/week_03/04_datawrangling_01.html#inspect-data",
    "title": "Transforming Ag data with dplyr",
    "section": "4.1 Inspect data",
    "text": "4.1 Inspect data\n\n4.1.1 glimpse\nThe glimpse() function provides an overview of the dataset, including variable names and data types.\n\n# Inspect the dataset\nglimpse(corn_data)\n\nRows: 3,443\nColumns: 9\n$ year  &lt;int&gt; 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999, 1999…\n$ lat   &lt;dbl&gt; -33.05113, -33.05115, -33.05116, -33.05117, -33.05118, -33.05120…\n$ long  &lt;dbl&gt; -63.84886, -63.84879, -63.84872, -63.84865, -63.84858, -63.84851…\n$ yield &lt;dbl&gt; 72.14, 73.79, 77.25, 76.35, 75.55, 70.24, 76.17, 69.17, 69.77, 6…\n$ nitro &lt;dbl&gt; 131.5, 131.5, 131.5, 131.5, 131.5, 131.5, 131.5, 131.5, 131.5, 1…\n$ topo  &lt;fct&gt; W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W, W…\n$ bv    &lt;dbl&gt; 162.60, 170.49, 168.39, 176.68, 171.46, 170.56, 172.94, 171.86, …\n$ rep   &lt;fct&gt; R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, R1, …\n$ nf    &lt;fct&gt; N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, N5, …\n\n\n\n\n4.1.2 skim\nThe skim() function from the ‘skimr’ allows to take a deeper look to all the variables (columns), creating a quick summary that reports the presence of missing values, etc., etc.\n\nskimr::skim(corn_data)\n\n\nData summary\n\n\nName\ncorn_data\n\n\nNumber of rows\n3443\n\n\nNumber of columns\n9\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n3\n\n\nnumeric\n6\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\ntopo\n0\n1\nFALSE\n4\nW: 1043, LO: 885, HT: 785, E: 730\n\n\nrep\n0\n1\nFALSE\n3\nR3: 1149, R1: 1147, R2: 1147\n\n\nnf\n0\n1\nFALSE\n6\nN1: 577, N3: 575, N5: 575, N0: 573\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nyear\n0\n1\n1999.99\n1.00\n1999.00\n1999.00\n1999.00\n2001.00\n2001.00\n▇▁▁▁▇\n\n\nlat\n0\n1\n-33.05\n0.00\n-33.05\n-33.05\n-33.05\n-33.05\n-33.05\n▃▇▆▃▁\n\n\nlong\n0\n1\n-63.85\n0.00\n-63.85\n-63.85\n-63.85\n-63.84\n-63.84\n▇▇▇▇▇\n\n\nyield\n0\n1\n69.83\n19.83\n12.66\n54.54\n66.63\n84.68\n117.90\n▁▅▇▃▃\n\n\nnitro\n0\n1\n64.57\n42.60\n0.00\n29.00\n66.00\n106.00\n131.50\n▅▇▇▂▇\n\n\nbv\n0\n1\n174.42\n9.68\n91.74\n168.48\n173.08\n179.39\n213.82\n▁▁▁▇▁",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#adding-new-variables-with-mutate",
    "href": "coding/week_03/04_datawrangling_01.html#adding-new-variables-with-mutate",
    "title": "Transforming Ag data with dplyr",
    "section": "4.2 Adding New Variables with mutate()",
    "text": "4.2 Adding New Variables with mutate()\nYou can add new columns to your dataset with mutate(). Let’s calculate the yield in tons per hectare (assuming the current yield is in kilograms):\n\n# Add a column for yield in tons\ncorn_data &lt;- corn_data %&gt;% \n  # New column, `yield_tons`, with the transformed yield values.\n  mutate(yield_tons = yield / 1000)\n\nhead(corn_data)\n\n  year       lat      long yield nitro topo     bv rep nf yield_tons\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5    0.07214\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5    0.07379\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5    0.07725\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5    0.07635\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5    0.07555\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5    0.07024",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#filtering-data",
    "href": "coding/week_03/04_datawrangling_01.html#filtering-data",
    "title": "Transforming Ag data with dplyr",
    "section": "4.3 Filtering Data",
    "text": "4.3 Filtering Data\nTo focus on specific data, we can use filter(). For example, let’s filter the data to include only rows where the nitrogen applied (nitro) is greater than 100:\n\n# Filter rows with nitro &gt; 100\nhigh_nitro &lt;- corn_data %&gt;%\n  # only rows where the `nitro` column has values greater than 100.\n  filter(nitro &gt; 100)\n\nhead(high_nitro)\n\n  year       lat      long yield nitro topo     bv rep nf yield_tons\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5    0.07214\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5    0.07379\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5    0.07725\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5    0.07635\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5    0.07555\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5    0.07024",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#selecting-columns",
    "href": "coding/week_03/04_datawrangling_01.html#selecting-columns",
    "title": "Transforming Ag data with dplyr",
    "section": "4.4 Selecting columns",
    "text": "4.4 Selecting columns\nTo select specific variables, we use select(), which selects specific columns from the dataset.\n\n# Select specific columns\nselected_data &lt;- corn_data %&gt;% select(yield, nitro, topo)\nhead(selected_data)\n\n  yield nitro topo\n1 72.14 131.5    W\n2 73.79 131.5    W\n3 77.25 131.5    W\n4 76.35 131.5    W\n5 75.55 131.5    W\n6 70.24 131.5    W",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#renaming-columns",
    "href": "coding/week_03/04_datawrangling_01.html#renaming-columns",
    "title": "Transforming Ag data with dplyr",
    "section": "4.5 Renaming columns",
    "text": "4.5 Renaming columns\nWhen we need to change names of columns, we can use rename():\n\n# Rename a column\nrenamed_data &lt;- corn_data %&gt;% rename(Nitrogen = nitro)\nhead(renamed_data)\n\n  year       lat      long yield Nitrogen topo     bv rep nf yield_tons\n1 1999 -33.05113 -63.84886 72.14    131.5    W 162.60  R1 N5    0.07214\n2 1999 -33.05115 -63.84879 73.79    131.5    W 170.49  R1 N5    0.07379\n3 1999 -33.05116 -63.84872 77.25    131.5    W 168.39  R1 N5    0.07725\n4 1999 -33.05117 -63.84865 76.35    131.5    W 176.68  R1 N5    0.07635\n5 1999 -33.05118 -63.84858 75.55    131.5    W 171.46  R1 N5    0.07555\n6 1999 -33.05120 -63.84851 70.24    131.5    W 170.56  R1 N5    0.07024",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#arranging-data",
    "href": "coding/week_03/04_datawrangling_01.html#arranging-data",
    "title": "Transforming Ag data with dplyr",
    "section": "4.6 Arranging data",
    "text": "4.6 Arranging data\nTo reorder the data based on specific criteria, we can use arrange(), which will arrange rows by a variable in ascending or descending order.\n\n# Arrange data by yield in descending order\narranged_data &lt;- corn_data %&gt;% arrange(desc(yield))\nhead(arranged_data)\n\n  year       lat      long  yield nitro topo     bv rep nf yield_tons\n1 2001 -33.05086 -63.84317 117.90  99.8   LO 162.17  R3 N4    0.11790\n2 2001 -33.05125 -63.84245 117.19 124.6   LO 165.81  R3 N5    0.11719\n3 2001 -33.05181 -63.84323 116.64 124.6   LO 159.75  R1 N5    0.11664\n4 2001 -33.05084 -63.84324 114.94  99.8   LO 166.27  R3 N4    0.11494\n5 2001 -33.05134 -63.84299 114.46  99.8   LO 164.58  R2 N4    0.11446\n6 2001 -33.05127 -63.84238 114.08 124.6   LO 170.94  R3 N5    0.11408",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#finding-unique-values",
    "href": "coding/week_03/04_datawrangling_01.html#finding-unique-values",
    "title": "Transforming Ag data with dplyr",
    "section": "4.7 Finding unique values",
    "text": "4.7 Finding unique values\nTo find out what are the unique values of a variable, we can use distinct(), which will return the unique values within a column.\n\n# Unique values in topo\nunique_topo &lt;- corn_data %&gt;% distinct(topo)\nunique_topo\n\n  topo\n1    W\n2   HT\n3    E\n4   LO",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#counting",
    "href": "coding/week_03/04_datawrangling_01.html#counting",
    "title": "Transforming Ag data with dplyr",
    "section": "4.8 Counting",
    "text": "4.8 Counting\nThe function count() counts the number of observations within a group.\n\n# Count observations by topo\ntopo_count &lt;- corn_data %&gt;% count(topo)\ntopo_count\n\n  topo    n\n1    E  730\n2   HT  785\n3   LO  885\n4    W 1043",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_03/04_datawrangling_01.html#summarizing-data",
    "href": "coding/week_03/04_datawrangling_01.html#summarizing-data",
    "title": "Transforming Ag data with dplyr",
    "section": "4.9 Summarizing Data",
    "text": "4.9 Summarizing Data\nTo get a quick overview of your data, you can use summarize() in combination with group_by(). For example, let’s calculate the average yield for each topographical category (topo):\n\n# Average yield by topography\naverage_yield_topo &lt;- corn_data %&gt;%\n  group_by(topo) %&gt;%\n  summarize(avg_yield = mean(yield, na.rm = TRUE))\naverage_yield_topo\n\n# A tibble: 4 × 2\n  topo  avg_yield\n  &lt;fct&gt;     &lt;dbl&gt;\n1 E          78.7\n2 HT         48.6\n3 LO         84.9\n4 W          66.8\n\n# Average yield by year and topography\naverage_yield_topoyear &lt;- corn_data %&gt;%\n  group_by(year, topo) %&gt;%\n  summarize(avg_yield = mean(yield, na.rm = TRUE))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\naverage_yield_topoyear\n\n# A tibble: 8 × 3\n# Groups:   year [2]\n   year topo  avg_yield\n  &lt;int&gt; &lt;fct&gt;     &lt;dbl&gt;\n1  1999 E          64.8\n2  1999 HT         53.4\n3  1999 LO         71.2\n4  1999 W          66.0\n5  2001 E          92.7\n6  2001 HT         44.7\n7  2001 LO         99.9\n8  2001 W          67.7\n\n\nThis groups the data by topo and calculates the mean yield for each group.",
    "crumbs": [
      "Lessons",
      "04-Data Wrangling I"
    ]
  },
  {
    "objectID": "coding/week_04/06_datawrangling_03.html",
    "href": "coding/week_04/06_datawrangling_03.html",
    "title": "Advanced Data Wrangling in R",
    "section": "",
    "text": "Description\nThis class dives deeper into the world of R data wrangling, covering advanced techniques and their applications. We’ll explore complex functions and join operations essential for real-world data analysis.\nRequired packages for today\nlibrary(pacman)\np_load(dplyr, tidyr, stringr, lubridate, janitor)",
    "crumbs": [
      "Lessons",
      "06-Data Wrangling III"
    ]
  },
  {
    "objectID": "coding/week_04/06_datawrangling_03.html#example-merging-weather-and-crop-yield-data",
    "href": "coding/week_04/06_datawrangling_03.html#example-merging-weather-and-crop-yield-data",
    "title": "Advanced Data Wrangling in R",
    "section": "2.1 Example: Merging Weather and Crop Yield Data",
    "text": "2.1 Example: Merging Weather and Crop Yield Data\n\nleft_join(): Includes all records from the left dataset and the matched records from the right dataset. If there is no match, the result is NA in the columns of the right dataset.\n\n\nweather_data &lt;- tibble(\n  date = seq(as.Date(\"2024-04-01\"), as.Date(\"2024-10-01\"), by = \"month\"),\n  precipitation = c(20, 40, 60, 80, 50, 30, 2),\n  temperature = c(15, 18, 25, 30, 22, 16, 12)\n)\n\nforage_data &lt;- tibble(\n  date = seq(as.Date(\"2024-04-01\"), as.Date(\"2024-10-01\"), by = \"month\"),\n  forage_yield = c(500, 1200, 3000, 4000, 2800, 1500, 0)\n)\n\n# Merge data\nleft_joined_data &lt;- left_join(weather_data, forage_data, by = \"date\")\n\n\nright_join(): Includes all records from the right dataset and the matched records from the left dataset. If there is no match, the result is NA in the columns of the left dataset.\n\n\n# Merge data\nright_joined_data &lt;- right_join(weather_data, forage_data, by = \"date\")\n\n\nfull_join(): Includes all records when there is a match in the keys of the left or right datasets. If there is no match, the result is NA in the columns of the dataset that does not have a match.\n\n\n# Merge data\nfull_joined_data &lt;- full_join(weather_data, forage_data, by = \"date\")",
    "crumbs": [
      "Lessons",
      "06-Data Wrangling III"
    ]
  },
  {
    "objectID": "outline/calendar.html",
    "href": "outline/calendar.html",
    "title": "PLNT6800|01 - Calendar",
    "section": "",
    "text": "Days: Wednesdays and Fridays\nTime: 1:00 pm - 2:20 pm\nLocation: CRSC 202",
    "crumbs": [
      "Calendar",
      "Schedule"
    ]
  },
  {
    "objectID": "outline/calendar.html#calendar",
    "href": "outline/calendar.html#calendar",
    "title": "PLNT6800|01 - Calendar",
    "section": "Calendar",
    "text": "Calendar\nThe course runs on Wednesdays and Fridays from 1:00 PM to 2:20 PM. Below is the tentative schedule. Please, note the schedule may vary depending on the progress of the class.\n\n\n\nWeek\nDate\nTopic\nCode\nLesson\n\n\n\n\n1\nJan 8\nIntroductions, Reproducibility\n-\n-\n\n\n\nJan 10\nEssentials of RStudio, R coding\n🌐\n🎥\n\n\n2\nJan 15\nFundamentals of R packages\n🌐\n🎥\n\n\n\nJan 17\nBasics of version control & GitHub\n🌐\n🎥\n\n\n3\nJan 22\nData Wrangling I\n🌐\n🎥\n\n\n\nJan 24\nData Wrangling II\n🌐\n🎥\n\n\n4\nJan 29\nData Wrangling III\n🌐\n🎥\n\n\n\nJan 31\nData Viz I: ggplot2 basics\n🌐\n🎥\n\n\n5\nFeb 5\nData Viz II: Multiple plots\n🌐\n🎥\n\n\n\nFeb 7\nData Viz III: Advanced plots, maps\n🌐\n🎥\n\n\n6\nFeb 12\nIteration: Loops & Mapping\n🌐\n🎥\n\n\n\nFeb 14\nWeather Data: Retrieving & Processing\n🌐\n🎥\n\n\n\n\nWinter Break begins after the end of class\n\n\n\n\n7\nFeb 26\nModels I: Key concepts\n🌐\n🎥\n\n\n\nFeb 28\nModels II: Explanatory vs. Predictive\n🌐\n🎥\n\n\n8\nMar 5\nModels III: Linear Models\n🌐\n🎥\n\n\n\nMar 7\nModels IV: Fixed, Random, Mixed Effects\n🌐\n🎥\n\n\n9\nMar 12\nModels V: Regression I\n🌐\n🎥\n\n\n\nMar 14\nModels VI: Regression II\n🌐\n🎥\n\n\n10\nMar 19\nModels VII: Review LMs\n🌐\n🎥\n\n\n\nMar 21\nModels VIII: Principal Components\n🌐\n🎥\n\n\n11\nMar 26\nQuarto / Rmarkdown tricks\n🌐\n🎥\n\n\n\nMar 28\nGeneral Review class\n🌐\n🎥\n\n\n12\nApr 2\nSemester Projects Presentations I\n🌐\n\n\n\n\nApr 4\nSemester Projects Presentations II\n🌐\n\n\n\n13\nApr 11\nFinal Exam Due (11.59 pm)\n🌐",
    "crumbs": [
      "Calendar",
      "Schedule"
    ]
  },
  {
    "objectID": "slides/day1.html",
    "href": "slides/day1.html",
    "title": "Reproducible Ag Data Science with R",
    "section": "",
    "text": "Goal: Gain foundational knowledge and understand how data science can improve agricultural practices.\nLet’s dive into it with an emphasis on reproducibility and data literacy.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nRemember: Questions and discussions are encouraged! 💬",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#welcome",
    "href": "slides/day1.html#welcome",
    "title": "Reproducible Ag Data Science with R",
    "section": "",
    "text": "Goal: Gain foundational knowledge and understand how data science can improve agricultural practices.\nLet’s dive into it with an emphasis on reproducibility and data literacy.\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nRemember: Questions and discussions are encouraged! 💬",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#objectives-for-today",
    "href": "slides/day1.html#objectives-for-today",
    "title": "Reproducible Ag Data Science with R",
    "section": "Objectives for Today 📌",
    "text": "Objectives for Today 📌\n\nDefine core concepts:\n\nData Science,\nData Literacy,\nReproducibility.\n\nUnderstand the role of reproducible data science in agriculture.\nExplore challenges and opportunities.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#what-is-data-science-in-agriculture",
    "href": "slides/day1.html#what-is-data-science-in-agriculture",
    "title": "Reproducible Ag Data Science with R",
    "section": "What is Data Science in Agriculture? 🌱",
    "text": "What is Data Science in Agriculture? 🌱\n\nApplying data engineering, analysis, statistics, and machine learning to solve agricultural problems.\nExamples: Precision agriculture, yield forecasting, environmental monitoring.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#key-definitions",
    "href": "slides/day1.html#key-definitions",
    "title": "Reproducible Ag Data Science with R",
    "section": "Key Definitions 📖",
    "text": "Key Definitions 📖\n\n\n\nData Science: Extracting insights from data using algorithms and statistical methods. \nData Literacy: Skills to read, interpret, and analyze data. \nReproducibility: Ensuring analyses can be recreated by others.\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nWhy does reproducibility matter?\n\nTrustworthy results,\ntransparency, &\ncollaboration in research.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#challenges-in-data-literacy",
    "href": "slides/day1.html#challenges-in-data-literacy",
    "title": "Reproducible Ag Data Science with R",
    "section": "Challenges in Data Literacy 🌐",
    "text": "Challenges in Data Literacy 🌐\n\nDiverse data sources (weather, soil, crop data)\nStandardization issues across datasets\nData skills gap among ag professionals",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#why-does-it-matter",
    "href": "slides/day1.html#why-does-it-matter",
    "title": "Reproducible Ag Data Science with R",
    "section": "Why does it matter?",
    "text": "Why does it matter?\n\n\nIt is the #1 skill-gap in the job market: \n\nAcademia,\nIndustry,\nGovernment, NGOs, etc.\n\n\n\n\n\n\n\nIs there a REPRODUCIBILITY CRISIS in science?\nYES\nA Nature survey with ~1,600 researchers found that\n\n+70% failure rate to reproduce another scientist’s experiments\n+50% have failed to reproduce their own experiments\nMain causes: selective reporting, weak stats, code/data unavailability, etc.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#good-news-is",
    "href": "slides/day1.html#good-news-is",
    "title": "Reproducible Ag Data Science with R",
    "section": "GOOD NEWS IS…",
    "text": "GOOD NEWS IS…",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#why-reproducibility-in-agriculture",
    "href": "slides/day1.html#why-reproducibility-in-agriculture",
    "title": "Reproducible Ag Data Science with R",
    "section": "Why Reproducibility in Agriculture?",
    "text": "Why Reproducibility in Agriculture?\n\nAgriculture research relies heavily on environmental data, often variable and complex.\nWe have complex challenges 🗒️\n\nVariability due to environmental factors, soil types, and weather patterns.\nComplex datasets involving long-term studies, geographical variability.\n\nOpportunities ✅\n\nReproducibility helps stakeholders make reliable, data-driven decisions.\nEnsures scientific findings are reliable and valid.\nFacilitates collaboration, accountability, and efficiency among researchers and practitioners.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#challenges-in-ag-research",
    "href": "slides/day1.html#challenges-in-ag-research",
    "title": "Reproducible Ag Data Science with R",
    "section": "Challenges in Ag-research",
    "text": "Challenges in Ag-research\n\n\nREPRODUCIBILITY 💻\n\nLimited capability to reproduce analyses & results\nDATA are rarely shared, CODES even less\n\n\n\n\n\nACCESSIBILITY 📲\n\nYet we are not translating enough science into flexible, and transparent decision tools.\n\n\n\n\n“But it all starts with …”\n\n\n\nEDUCATION 🎓\n\nLimited curriculum in applied data science",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#discussion-prompt",
    "href": "slides/day1.html#discussion-prompt",
    "title": "Reproducible Ag Data Science with R",
    "section": "Discussion Prompt 💬",
    "text": "Discussion Prompt 💬\n\n\n\ni. Where do you think improved data literacy & reproducibility could impact agriculture the most?\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nConsider areas like resource management, market predictions, and farm management.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#what-is-r",
    "href": "slides/day1.html#what-is-r",
    "title": "Reproducible Ag Data Science with R",
    "section": "What is R? 🧮",
    "text": "What is R? 🧮\n\n\nR is a programming language and environment primarily for statistical analysis, data visualization, and data science.\nKnown for its extensive statistical libraries, data manipulation capabilities, and graphics.\nWidely used in fields like data science, bioinformatics, agriculture, and social sciences.\n\n\n\n\nBrief History 📜\n\nOrigin: Developed in the early 1990s by Ross Ihaka and Robert Gentleman at the University of Auckland, New Zealand.\nInspiration: R is an implementation of the S language, designed at Bell Laboratories for data analysis.\nOpen Source: Released as free, open-source software, leading to a large community of users and contributors.\nPopularity: Today, R is one of the top programming languages for statistical analysis and data science.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#r-vs.-excel-for-data-wrangling",
    "href": "slides/day1.html#r-vs.-excel-for-data-wrangling",
    "title": "Reproducible Ag Data Science with R",
    "section": "R vs. Excel for Data Wrangling 📊",
    "text": "R vs. Excel for Data Wrangling 📊\n\n\n\nExcel: Known for ease of use, popular among business and finance professionals.\n\nPros: Intuitive, good for small datasets and quick analysis.\nCons: Limited in handling large datasets, lacks reproducibility.\n\nR: Provides powerful data manipulation packages (e.g., dplyr, tidyr).\n\nPros: Handles large datasets efficiently, supports complex transformations, fully reproducible.\nCons: Requires programming knowledge, steeper learning curve than Excel.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\n\nTip: R is highly scalable and is ideal for projects requiring automation, reproducibility, and handling large datasets.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#r-vs.-sas-for-statistical-analysis",
    "href": "slides/day1.html#r-vs.-sas-for-statistical-analysis",
    "title": "Reproducible Ag Data Science with R",
    "section": "R vs. SAS for Statistical Analysis 📉",
    "text": "R vs. SAS for Statistical Analysis 📉\n\n\n\nSAS: A powerful statistical software suite used widely in industries such as healthcare and finance.\n\nPros: Robust for regulatory environments, highly standardized.\nCons: Proprietary and costly, limited community contributions.\n\nR: Offers a vast array of statistical packages and flexibility in method implementation.\n\nPros: Free and open-source, customizable, strong community support.\nCons: Requires more coding and configuration for regulatory standards.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nComparison: R is often chosen for research and academia due to its flexibility and customization, while SAS remains strong in industries needing strict compliance and control.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#r-vs-python",
    "href": "slides/day1.html#r-vs-python",
    "title": "Reproducible Ag Data Science with R",
    "section": "R vs Python 🔍",
    "text": "R vs Python 🔍\n\nR, & Python are popular languages in data science and research.\nEach language has unique strengths, ideal use cases, and licensing considerations.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#r-strengths-and-use-cases",
    "href": "slides/day1.html#r-strengths-and-use-cases",
    "title": "Reproducible Ag Data Science with R",
    "section": "R: Strengths and Use Cases 🧮",
    "text": "R: Strengths and Use Cases 🧮\n\n\n\nDesigned for Statistics: R is optimized for statistical analysis, making it ideal for research and academia.\nVisualization: Excellent data visualization libraries like ggplot2.\nLicensing: Licensed under GPL; many packages are also GPL, with some using MIT or BSD.\n\n\n\nIdeal Use Cases:\n\nData analysis, visualization, and complex statistical modeling.\nResearch and academia where open-source, reproducible code is needed.\nLicensing in Production: GPL may restrict proprietary use; check package licenses carefully.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#python-strengths-and-use-cases",
    "href": "slides/day1.html#python-strengths-and-use-cases",
    "title": "Reproducible Ag Data Science with R",
    "section": "Python: Strengths and Use Cases 🐍",
    "text": "Python: Strengths and Use Cases 🐍\n\n\n\nGeneral-Purpose Language: Python is popular for both data science and software development.\nMachine Learning & AI: Extensive libraries for ML and AI, such as scikit-learn, TensorFlow.\nLicensing: PSFL (Python Software Foundation License), highly permissive for proprietary use.\n\n\n\nIdeal Use Cases:\n\nEnd-to-end development, from data wrangling to ML and web development.\nProduction-ready ML and AI applications.\nLicensing in Production: Permissive licenses allow closed-source use, making Python production-friendly.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#comparison-summary",
    "href": "slides/day1.html#comparison-summary",
    "title": "Reproducible Ag Data Science with R",
    "section": "Comparison Summary 📊",
    "text": "Comparison Summary 📊\n\n\n\n\n\n\n\nNote\n\n\n\n\nR: Best for statistical analysis and visualization, but GPL license may restrict use in proprietary products.\nExcel: User-friendly, ideal for simple tasks, but limited for complex data wrangling.\nSAS: Industry-standard for statistical analysis with regulatory requirements, but costly and less flexible than R.\nPython: Strong in ML and AI with highly permissive licensing, making it ideal for production.\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeature\nR\nPython\n\n\n\n\nPrimary Strength\nStatistics & Visualization\nGeneral-purpose, ML, AI\n\n\nPerformance\nModerate\nModerate\n\n\nLicensing\nGPL (core), MIT, BSD (some)\nPSFL, highly permissive\n\n\nProduction Use\nLimited by GPL\nVery friendly for proprietary\n\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nChoosing the right tool depends on your project’s requirements, team skills, and licensing needs for research vs. production.",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "slides/day1.html#thank-you",
    "href": "slides/day1.html#thank-you",
    "title": "Reproducible Ag Data Science with R",
    "section": "THANK YOU!",
    "text": "THANK YOU!\nacorrend@uoguelph.ca\n\nAdrian A. Correndo\nAssistant Professor\nSustainable Cropping Systems\nDepartment of Plant Agriculture\nUniversity of Guelph\n\n\nRm 226, Crop Science Bldg | Department of Plant Agriculture\nOntario Agricultural College | University of Guelph | 50 Stone Rd E, Guelph, ON-N1G 2W1, Canada.\n\n\nContact me",
    "crumbs": [
      "Slides",
      "Reproducibility"
    ]
  },
  {
    "objectID": "software/software.html",
    "href": "software/software.html",
    "title": "Required Software & Accounts",
    "section": "",
    "text": "R & RStudio IDEGitGitHubGitHub DesktopPosit Cloud\n\n\nBefore starting with the course, it is important that you install R and R Studio in your computer. Please, follow these simple steps:\nDownload the latest version of R from CRAN, here Download the latest version of RStudio from posit, here Run and install in the downloaded files in the same order. There are plenty of useful tutorials on the internet such as:\n\nhttps://rstudio-education.github.io/hopr/starting.html\nhttps://www.youtube.com/watch?v=Tb3R4GLJ45U\n\n\n\nWhat is Git?\nGit is a powerful version control system that helps you track changes in your code, collaborate with others, and manage your projects effectively.\nHow to Install Git:\nFollow these steps to install Git on your computer:\n\nVisit the official Git website (https://git-scm.com/);to download the installer for your operating system.\nFor detailed guidance, read the official tutorial to install git (https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).\nYou may use these step-by-step videos for installation:\n\n• Installing Git on Windows (https://www.youtube.com/watch?v=iYkLrXobBbA)\n• Installing Git on Mac (https://www.youtube.com/watch?v=B4qsvQ5IqWk)\nOnce installed, verify by typing git –version in your terminal to ensure Git is ready to use!\n\n\nWhat is GitHub?\nGitHub is a web-based interface (nowadays own by Microsoft) that facilitates the use of Git, an open source version control software. This lets multiple people make separate changes to projects and have control over them. GitHub is to Git the equivalent of what RStudio is to R.\nFor this course, it is required that you create your GitHub account. Preferably, using your University email (##@uoguelph.ca). Please, follow the steps detailed on this official link from GitHub:\nhttps://docs.github.com/en/get-started/start-your-journey/creating-an-account-on-github\nYou may also find multiple useful YouTube tutorials like this one:\nhttps://www.youtube.com/watch?v=h5cKAd94QNo\n\n\nWhat is GitHub Desktop?\nGitHub Desktop is a user-friendly application that helps you interact with Git and GitHub through a simple graphical interface, making it easier to manage your repositories.\nHow to Install GitHub Desktop:\nFollow these steps to install GitHub Desktop on your computer:\n\nVisit the GitHub Desktop website (https://desktop.github.com); and download the application for your operating system.\nRun the installer and follow the on-screen instructions to complete the installation.\nAfter installation, sign in to your GitHub account or create one if you don’t have it.\n\nFor additional help, check out these videos:\n• Installing GitHub Desktop on Windows (https://www.youtube.com/watch?v=3JdDAJ2YPeU)\n• Installing GitHub Desktop on Mac (https://www.youtube.com/watch?v=C0n6O4d0ccw)\nOnce installed, you can easily clone repositories, commit changes, and sync your work with GitHub!\n\n\nWhat is Posit Cloud?\nPosit Cloud is an online platform that allows you to run RStudio “online”. It helps to write and execute R code directly in your browser, making it easy to learn and work on data science projects without installing software locally.\nHow to Create a Free Posit Cloud Account:\nFollow these steps to set up your free account:\n\nVisit Posit Cloud website at https://posit.cloud.\nClick on Sign Up and choose to create an account using your UoG email. THIS IS IMPORTANT, USE YOUR UOG EMAIL!\nComplete the registration form and verify your email if required.\nOnce registered, log in to your Posit Cloud account and start exploring R projects directly in your browser.\nMore instructions about our course workspace will be provided during the semester.\n\nFor a hint of what PositCloud does, you may watch with this video:\nhttps://www.youtube.com/watch?v=-fzwm4ZhVQQ With Posit Cloud, you’ll have a convenient environment to learn and work on your R programming assignments!",
    "crumbs": [
      "Software",
      "Instructions"
    ]
  },
  {
    "objectID": "outline/outline.html",
    "href": "outline/outline.html",
    "title": "PLNT6800|01 - Course Outline",
    "section": "",
    "text": "Course Code: PLNT6800\nCourse Title: Reproducible Ag Data Science with R\nTerm: Winter\nCredits: 0.50\n\n\n\n\nDays: Wednesdays and Fridays\nTime: 1:00 pm - 2:20 pm\nLocation: CRSC 202\n\n\n\n\n\nDr. Adrian Correndo\nEmail: acorrend@uoguelph.ca",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#course-information",
    "href": "outline/outline.html#course-information",
    "title": "PLNT6800|01 - Course Outline",
    "section": "",
    "text": "Course Code: PLNT6800\nCourse Title: Reproducible Ag Data Science with R\nTerm: Winter\nCredits: 0.50\n\n\n\n\nDays: Wednesdays and Fridays\nTime: 1:00 pm - 2:20 pm\nLocation: CRSC 202\n\n\n\n\n\nDr. Adrian Correndo\nEmail: acorrend@uoguelph.ca",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#course-description",
    "href": "outline/outline.html#course-description",
    "title": "PLNT6800|01 - Course Outline",
    "section": "2. Course Description",
    "text": "2. Course Description\nReproducible Ag Data Science with R is designed for graduate students in crop and soil sciences to develop key skills in data science using R. This course emphasizes reproducibility in data analysis, ensuring that results can be consistently replicated. Students will learn essential data science concepts, and how to use functions, packages, and version control to effectively manage their data and collaborate with peers. Following tidy principles, the course promotes best coding practices for data wrangling, effective visualization, and clean deployment of statistical models common in agriculture. By the end of the course, students will be equipped to handle a variety of agricultural datasets and produce reliable, reproducible research outcomes.\n\nPrerequisite(s)\nA basic understanding of R or any programming language is recommended but not required. Basic statistical theory is also recommended.\n\n\nTextbooks and Resources\nRecommended:\n\nR for Data Science by Hadley Wickham & Garrett Grolemund.\nOnline resources and package documentation will be provided throughout the course.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#course-learning-outcomes",
    "href": "outline/outline.html#course-learning-outcomes",
    "title": "PLNT6800|01 - Course Outline",
    "section": "3. Course Learning Outcomes",
    "text": "3. Course Learning Outcomes\nBy the end of this course, students will be able to:\n\nUnderstand and apply the principles of reproducible research in data science.\nUse version control tools like GitHub for managing code and collaborative projects.\nDevelop proficiency in R, including data wrangling, data visualization, and the use of relevant packages for agricultural datasets.\nApply statistical models to agricultural data and interpret the results.\nProduce professional reports using RMarkdown and Quarto, ensuring reproducibility and clarity.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#calendar",
    "href": "outline/outline.html#calendar",
    "title": "PLNT6800|01 - Course Outline",
    "section": "4. Calendar",
    "text": "4. Calendar\nSee http://adriancorrendo.github.io/plnt6800/calendar.html\n\nLast Day to Drop Course\nTBD",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#assessment-breakdown",
    "href": "outline/outline.html#assessment-breakdown",
    "title": "PLNT6800|01 - Course Outline",
    "section": "5. Assessment Breakdown",
    "text": "5. Assessment Breakdown\n\n\n\n\n\n\n\n\nComponent\nWeight (%)\nDetails\n\n\n\n\nWeekly Exercises\n30%\nHands-on exercises to practice skills covered in each week’s topic.\n\n\nSemester Project\n50%\nComplete data analysis project, report, and presentation.\n\n\nFinal Exam\n20%\nCumulative assessment covering all topics from the course.\n\n\n\n\nFinal Exam\n\nDate: Apr 11, 11.59 pm.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#course-grading-policies",
    "href": "outline/outline.html#course-grading-policies",
    "title": "PLNT6800|01 - Course Outline",
    "section": "6. Course Grading Policies",
    "text": "6. Course Grading Policies\n\na. Late Submissions\nAssignments submitted late will be penalized 5% per day, up to six days. Extensions granted only for valid reasons.\n\n\nb. Use of Devices\nElectronic recording of classes is forbidden without prior permission from the instructor.\n\n\nc. Academic honesty\nPlease adhere to the following guidelines when working on assignments for this course:\n\nIndividual and Team Assignments: You are welcome to discuss individual homework and lab assignments with other students; however, direct sharing or copying of code or written work is not permitted. For team assignments, collaboration is allowed freely within your team. Sharing or copying code or written content between teams is prohibited. Any unauthorized sharing or copying will be treated as a violation for all parties involved.\nExams: Collaboration or discussion with others during exams is strictly prohibited. Unauthorized collaboration or use of unapproved materials will be considered a violation for all students involved.\nReusing Code: Unless specified otherwise, you may refer to online resources (e.g., StackOverflow) for coding examples in assignments. If you use code from an external source directly or take inspiration from it, you must clearly cite the source. The use of AI to complete tasks is not prohibited but it must be disclosed. Failure to cite reused code will be considered plagiarism.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#course-statements",
    "href": "outline/outline.html#course-statements",
    "title": "PLNT6800|01 - Course Outline",
    "section": "7. Course Statements",
    "text": "7. Course Statements\n\nA. Communication with instructor\nDuring the course, your instructor will interact with you on various course matters on the course website using the following ways of communication:\n\nAnnouncements: The instructor will use Announcements on the Course Home page to provide you with course reminders and updates. Pleasecheck this section frequently for course updates from your instructor.\nEmail: If you have a conflict that prevents you from completing course requirements, or have a question concerning a personal matter, you cansend your instructor a private message by email. The instructor will attempt to respond to your email within 24 hours.\nVideo Call: If you have a complex question you would like to discuss with your instructor, you may book a video meeting on Zoom or Teams. Video meetings depend on the availability and are booked on a first come first served basis.\n\n\n\nB. Course Technology Requirements\nThis course will use a variety of technologies and resources. To successfully participate in and complete this course, students will need access to the following\n\n1. Communication tools:\nCourseLink. This platform will be used as the main Course-Home Page. If you need any assistance with the software tools or the CourseLink website, contact CourseLink Support. Email: courselink@uoguelph.ca Tel: 519-824-4120 ext. 56939 Toll-Free (CAN/USA): 1-866- 275-1478. Support Hours (Eastern Time): Monday thru Friday: 8:30 am–8:30 pm; Saturday: 10:00 am–4:00 pm; Sunday: 12:00 pm–6:00 pm\nZoom. This course will use Zoom for lectures when in-person class is not possible. Check your system requirements to ensure you will be able to participate (https://opened.uoguelph.ca/student-resources/system-and-software-requirements/). A Zoom link for the class will be provided before the first day of class. Please, check Home-Page and announcements on CourseLink, and emails from the instructor (acorrend@uoguelph.ca).\n\n\n2. Software & Tools:\n\nR (latest stable version, available at CRAN).\nRStudio/Posit IDE (desktop or cloud-based version for writing and running R code).\nCourse-Specific Libraries and Packages: Students will be required to install R packages. Detailed instructions will be provided in class.\nVersion Control and Collaboration Tools: Git (for version control) and a free GitHub account for collaborative project work and sharing code.\n\n\n\n3. Computing Requirements:\nA laptop or desktop computer capable of running R and RStudio (Windows, MacOS, or Linux). Minimum specifications include:\n\nProcessor: At least a dual-core processor.\nRAM: 8 GB or more (16 GB recommended for handling larger datasets).\nStorage: 10 GB of free space for software installation, course files, and datasets.\n\n\n\n4. Internet Access:\nReliable high-speed internet for accessing online sessions, resources, downloading software, and using cloud-based platforms (e.g., Posit Cloud, GitHub).\n\n\n\n\nC. Data Usage Policy for the Semester Project\nStudents are encouraged to use data from their own research projects for the semester project. However, it is essential to ensure the integrity and privacy of the data, as well as compliance with the policies of their research lab or institution. To safeguard data privacy and integrity: \n\nData Sharing Restrictions: Students are NOT allowed to upload raw research data directly to the instructor, peers, GitHub repositories, Posit Cloud, or any other external platform.\nDe-Identification and Transformation: Before using or sharing the data for the semester project, students must de-identify and transform the data as necessary. This process should ensure that sensitive information or identifying details are removed or anonymized. All data preparation must be performed locally on the student’s machine before incorporating it into the project. \nDocumentation Requirement: Students must include a clear description of the steps taken to de-identify and transform the data in their project report or presentation. This demonstrates adherence to ethical data handling practices.\n\nBy following these guidelines, students can apply their learning to real-world datasets while respecting ethical and institutional standards. The instructor is not responsible for students’ violations to the integrity and privacy of their research data. Non-compliance with this policy may result in disqualification of the project or additional academic consequences.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#accessibility",
    "href": "outline/outline.html#accessibility",
    "title": "PLNT6800|01 - Course Outline",
    "section": "8. Accessibility",
    "text": "8. Accessibility\nStudents requiring accommodations must register with Student Accessibility Services. Contact the instructor early in the semester to arrange accommodations.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "outline/outline.html#land-acknowledgement",
    "href": "outline/outline.html#land-acknowledgement",
    "title": "PLNT6800|01 - Course Outline",
    "section": "9. Land Acknowledgement",
    "text": "9. Land Acknowledgement\nThe University of Guelph resides on the ancestral lands of the Attawandaron people and the treaty lands and territory of the Mississaugas of the Credit. We recognize the significance of the Dish with One Spoon Covenant to this land and offer respect to our Anishinaabe, Haudenosaunee, and Métis neighbours. Today, this gathering place is home to many First Nations, Inuit, and Métis peoples, and acknowledging them reminds us of our important connection to this land where we work and learn.",
    "crumbs": [
      "Course Outline",
      "Outline"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html",
    "href": "coding/week_04/07_ggplot2_intro.html",
    "title": "Data Viz I",
    "section": "",
    "text": "Description\nIn this class, we will explore advanced visualization techniques using ggplot2. You’ll learn how to fine-tune plots by modifying shapes, lines, legends, and adding custom titles and annotations. We will continue working with the agridat::lasrosas.corn dataset.",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html#define-custom-palettes",
    "href": "coding/week_04/07_ggplot2_intro.html#define-custom-palettes",
    "title": "Data Viz I",
    "section": "3.1 Define custom palettes",
    "text": "3.1 Define custom palettes\n\nmy_colors &lt;- c(\"#1e6091\", \"#f9c74f\", \"#9b2226\",  \"#599999\",  \"#8e5572\")",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html#histogram-with-adjusted-transparency-and-custom-bins",
    "href": "coding/week_04/07_ggplot2_intro.html#histogram-with-adjusted-transparency-and-custom-bins",
    "title": "Data Viz I",
    "section": "3.2 Histogram with Adjusted Transparency and Custom Bins",
    "text": "3.2 Histogram with Adjusted Transparency and Custom Bins\n\n# Density\ndensity_01 &lt;- \ncorn_data %&gt;% \nggplot(aes(x = yield)) +\n  geom_density(aes(fill = Year), color = \"grey15\", alpha = 0.5)+\n  labs(title = \"Yield Distribution Across Years\", x = \"Yield (qq/ha)\", y = \"Count\") +\n  scale_fill_manual(values = my_colors)+\n  theme_classic()\n\n# Histogram\nhisto_01 &lt;-\nggplot(corn_data, aes(x = yield)) +\n  geom_histogram(aes(fill = Year), bins = 20, alpha = 0.6, color = \"black\") +\n  labs(title = \"Yield Distribution Across Years\", x = \"Yield (qq/ha)\", y = \"Count\") +\n  scale_fill_manual(values = my_colors)+\n  geom_rug(aes(color = Year), alpha = 0.5)+\n  scale_color_manual(values = my_colors)+\n  theme_classic()\n\nhisto_01\n\n\n\n\n\n\n\n# Faceting by Year\nhisto_02 &lt;-\ncorn_data %&gt;% \nggplot(aes(x = yield)) +\n  geom_histogram(aes(fill = Year), bins = 30, alpha = 0.6, color = \"black\") +\n  labs(title = \"Yield Distribution Across Years\", x = \"Yield (qq/ha)\", y = \"Count\") +\n  scale_fill_manual(values = my_colors)+\n  geom_rug(aes(color = topo), alpha = 0.5)+\n  scale_color_manual(values = my_colors)+\n  facet_wrap(~topo)+\n  theme_classic()+\n  theme(legend.position = \"none\")\nhisto_02\n\n\n\n\n\n\n\ncorn_data %&gt;% \nggplot(aes(x = yield)) +\n  geom_histogram(aes(fill = topo), bins = 20, alpha = 0.6, color = \"black\") +\n  labs(title = \"Yield Distribution Across Years\", x = \"Yield (qq/ha)\", y = \"Count\") +\n  scale_fill_manual(values = my_colors)+\n  geom_rug(aes(color = topo), alpha = 0.5)+\n  scale_color_manual(values = my_colors)+\n  facet_wrap(~topo)+\n  theme_classic()+\n  theme(legend.position = \"none\")",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html#columnbar-plot",
    "href": "coding/week_04/07_ggplot2_intro.html#columnbar-plot",
    "title": "Data Viz I",
    "section": "3.3 Column/Bar plot",
    "text": "3.3 Column/Bar plot\n\n# Prepare summarized data frame\naggregated_corn &lt;- corn_data %&gt;% group_by(Year, year, nitro, nf) %&gt;% \n  summarize(yield_mean = mean(yield),\n            sd_yield = sd(yield))\n\n`summarise()` has grouped output by 'Year', 'year', 'nitro'. You can override\nusing the `.groups` argument.\n\n# Column plot\ncolplot_01 &lt;- \n  aggregated_corn %&gt;% \nggplot() +\n  geom_col(aes(x = nf, y = yield_mean, fill = Year), \n           color = \"grey25\") + # Triangle shape\n  scale_fill_manual(values = my_colors)+\n  labs(title = \"Yield vs. Nitrogen Levels\", x = \"Nitrogen (kg/ha)\", y = \"Yield (qq/ha)\") +\n  facet_wrap(~Year)+\n  theme_classic()\n\ncolplot_01\n\n\n\n\n\n\n\n# Add SD bars\ncolplot_02 &lt;-\ncolplot_01 +\n  geom_errorbar(data = aggregated_corn, \n                aes(ymin = yield_mean - sd_yield,\n                    ymax = yield_mean + sd_yield, \n                    x = nf),\n                width = .25)\n  \n\ncolplot_02\n\n\n\n\n\n\n\n# facet by topography\naggregated_topo &lt;- corn_data %&gt;% group_by(Year, year, nitro, nf, topo) %&gt;% \n  summarize(yield_mean = mean(yield),\n            sd_yield = sd(yield))\n\n`summarise()` has grouped output by 'Year', 'year', 'nitro', 'nf'. You can\noverride using the `.groups` argument.\n\n# dacet by topography and Year\ncolplot_03 &lt;- \naggregated_topo %&gt;% \nggplot() +\n  geom_col(aes(x = nf, y = yield_mean, fill = topo), \n           color = \"grey25\", alpha = 0.5) + # Triangle shape\n  geom_errorbar(aes(ymin = yield_mean - sd_yield,\n                    ymax = yield_mean + sd_yield, x = nf),\n                width = .25)+\n  labs(title = \"Yield vs. Nitrogen Levels\", x = \"Nitrogen (kg/ha)\", y = \"Yield (qq/ha)\") +\n  facet_grid(topo~Year)+\n  scale_fill_manual(values = my_colors)+\n  theme_classic()\n\ncolplot_03",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html#scatter-plot-with-custom-shapes-and-line-types",
    "href": "coding/week_04/07_ggplot2_intro.html#scatter-plot-with-custom-shapes-and-line-types",
    "title": "Data Viz I",
    "section": "3.4 Scatter Plot with Custom Shapes and Line Types",
    "text": "3.4 Scatter Plot with Custom Shapes and Line Types\n\ncorn_data %&gt;%\nggplot(aes(x = nitro, y = yield, color = factor(year))) +\n  geom_point(size = 3, shape = 17) + # Triangle shape\n  geom_smooth(method = \"lm\", se = FALSE, linetype = \"dashed\") +\n  labs(title = \"Yield vs. Nitrogen Levels\", x = \"Nitrogen (kg/ha)\", y = \"Yield (qq/ha)\") +\n  theme_minimal()\n\n`geom_smooth()` using formula = 'y ~ x'",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_04/07_ggplot2_intro.html#boxplot-with-custom-shapes-and-line-types",
    "href": "coding/week_04/07_ggplot2_intro.html#boxplot-with-custom-shapes-and-line-types",
    "title": "Data Viz I",
    "section": "3.5 BoxPlot with Custom Shapes and Line Types",
    "text": "3.5 BoxPlot with Custom Shapes and Line Types\n\ncorn_data %&gt;% \nggplot(aes(x = nf, y = yield)) +\n  geom_boxplot(aes(fill = Year), color = \"grey15\", size = 0.5) +\n  geom_jitter(aes(x = nf, y = yield, color=Year), size = 0.1)+\n  scale_fill_brewer(palette=2, type = \"qual\")+\n  scale_color_brewer(palette=2, type = \"qual\")+\n  labs(title = \"Yield vs. Nitrogen Levels\", \n       x = \"Nitrogen (kg/ha)\", y = \"Yield (qq/ha)\") +\n  facet_wrap(~Year)+\n  theme_classic()",
    "crumbs": [
      "Lessons",
      "07-Data viz I"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html",
    "href": "coding/week_03/05_datawrangling_02.html",
    "title": "Transforming Ag data in R II",
    "section": "",
    "text": "This lesson builds on our previous session by introducing more advanced data wrangling techniques using tidyr, stringr, and forcats. We will explore how to manipulate and transform data for efficient analysis. Additionally, we introduce lubridate for handling dates effectively.\n\n\n\nlibrary(pacman)\np_load(agridat, dplyr, tidyr, stringr, forcats, skimr, lubridate)",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#required-packages-for-today",
    "href": "coding/week_03/05_datawrangling_02.html#required-packages-for-today",
    "title": "Transforming Ag data in R II",
    "section": "",
    "text": "library(pacman)\np_load(agridat, dplyr, tidyr, stringr, forcats, skimr, lubridate)",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#aggregation-with-group_by-and-summarize",
    "href": "coding/week_03/05_datawrangling_02.html#aggregation-with-group_by-and-summarize",
    "title": "Transforming Ag data in R II",
    "section": "2.1 Aggregation with group_by() and summarize()",
    "text": "2.1 Aggregation with group_by() and summarize()\n\ndata_corn &lt;- agridat::lasrosas.corn\nsummary_data &lt;- data_corn %&gt;% \n  group_by(topo, year) %&gt;% \n  summarize(mean_yield = mean(yield, na.rm = TRUE), .groups = \"drop\")\nsummary_data\n\n# A tibble: 8 × 3\n  topo   year mean_yield\n  &lt;fct&gt; &lt;int&gt;      &lt;dbl&gt;\n1 E      1999       64.8\n2 E      2001       92.7\n3 HT     1999       53.4\n4 HT     2001       44.7\n5 LO     1999       71.2\n6 LO     2001       99.9\n7 W      1999       66.0\n8 W      2001       67.7",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#applying-functions-to-multiple-columns-using-across",
    "href": "coding/week_03/05_datawrangling_02.html#applying-functions-to-multiple-columns-using-across",
    "title": "Transforming Ag data in R II",
    "section": "2.2 Applying Functions to Multiple Columns using across()",
    "text": "2.2 Applying Functions to Multiple Columns using across()\n\ndata_across &lt;- data_corn %&gt;% \n  mutate(across(c(lat, long), ~ round(.x, digits=1), .names = \"rounded_{.col}\")) # Rounding values to 1 decimal place for better readability\nhead(data_across)\n\n  year       lat      long yield nitro topo     bv rep nf rounded_lat\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5       -33.1\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5       -33.1\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5       -33.1\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5       -33.1\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5       -33.1\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5       -33.1\n  rounded_long\n1        -63.8\n2        -63.8\n3        -63.8\n4        -63.8\n5        -63.8\n6        -63.8",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#creating-conditional-columns-with-case_when",
    "href": "coding/week_03/05_datawrangling_02.html#creating-conditional-columns-with-case_when",
    "title": "Transforming Ag data in R II",
    "section": "2.3 Creating Conditional Columns with case_when()",
    "text": "2.3 Creating Conditional Columns with case_when()\n\ndata_casewhen &lt;- data_corn %&gt;% \n  mutate(yield_category = case_when(\n    yield &gt; 10 ~ \"High\",\n    yield &gt; 5 ~ \"Medium\",\n    TRUE ~ \"Low\"\n  ))\nhead(data_casewhen)\n\n  year       lat      long yield nitro topo     bv rep nf yield_category\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5           High\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5           High\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5           High\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5           High\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5           High\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5           High",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#slicing-data-with-slice",
    "href": "coding/week_03/05_datawrangling_02.html#slicing-data-with-slice",
    "title": "Transforming Ag data in R II",
    "section": "2.4 Slicing data with slice():",
    "text": "2.4 Slicing data with slice():\n\n# Selecting the first 3 rows\nfirst_rows &lt;- data_corn %&gt;% slice(1:3)\nhead(first_rows)\n\n  year       lat      long yield nitro topo     bv rep nf\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5\n\n# Selecting the last 3 rows\nlast_rows &lt;- data_corn %&gt;% slice_tail(n = 3)\nhead(last_rows)\n\n  year       lat      long yield nitro topo     bv rep nf\n1 2001 -33.05110 -63.84189 92.33    39   LO 166.75  R3 N1\n2 2001 -33.05112 -63.84182 88.98    39   LO 163.59  R3 N1\n3 2001 -33.05115 -63.84175 85.74    39   LO 163.48  R3 N1\n\n# Selecting 3 random rows\nrandom_rows &lt;- data_corn %&gt;% slice_sample(n = 3)\nhead(random_rows)\n\n  year       lat      long yield nitro topo     bv rep nf\n1 2001 -33.05006 -63.84804 90.68  75.4    W 193.82  R1 N3\n2 1999 -33.05079 -63.84613 58.94  66.0   HT 181.90  R3 N3\n3 1999 -33.05155 -63.84387 66.83  66.0    E 171.07  R2 N3\n\n# Selecting every 2nd row\nevery_second_row &lt;- data_corn %&gt;% slice(seq(1, n(), by = 2))\nhead(every_second_row)\n\n  year       lat      long yield nitro topo     bv rep nf\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5\n2 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5\n3 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5\n4 1999 -33.05121 -63.84844 76.17 131.5    W 172.94  R1 N5\n5 1999 -33.05123 -63.84830 69.77 131.5    W 171.88  R1 N5\n6 1999 -33.05126 -63.84816 71.05 131.5    W 173.02  R1 N5",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#working-with-time-series-data-lead-and-lag",
    "href": "coding/week_03/05_datawrangling_02.html#working-with-time-series-data-lead-and-lag",
    "title": "Transforming Ag data in R II",
    "section": "2.5 Working with Time-Series Data: lead() and lag()",
    "text": "2.5 Working with Time-Series Data: lead() and lag()\n\ndata_lag &lt;- data_corn %&gt;% \n  arrange(year, topo) %&gt;% \n  mutate(yield_change = yield - lag(yield))\nhead(data_lag)\n\n  year       lat      long yield nitro topo     bv rep nf yield_change\n1 1999 -33.05174 -63.84532 59.94 131.5    E 182.12  R1 N5           NA\n2 1999 -33.05175 -63.84525 58.96 131.5    E 182.57  R1 N5        -0.98\n3 1999 -33.05176 -63.84518 61.77 131.5    E 178.07  R1 N5         2.81\n4 1999 -33.05178 -63.84511 66.41 131.5    E 177.83  R1 N5         4.64\n5 1999 -33.05179 -63.84504 66.06 131.5    E 176.17  R1 N5        -0.35\n6 1999 -33.05180 -63.84497 62.13 131.5    E 176.56  R1 N5        -3.93",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#gathering-and-spreading-data",
    "href": "coding/week_03/05_datawrangling_02.html#gathering-and-spreading-data",
    "title": "Transforming Ag data in R II",
    "section": "3.1 Gathering and Spreading Data",
    "text": "3.1 Gathering and Spreading Data\n\n# Convert from wide to long format using pivot_longer\nlong_data &lt;- data_corn %&gt;% \n  pivot_longer(cols = c(yield, nitro), \n               names_to = \"measurement\", # name of the column with description\n               values_to = \"value\") # name of the column with values\nhead(long_data)\n\n# A tibble: 6 × 9\n   year   lat  long topo     bv rep   nf    measurement value\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt;       &lt;dbl&gt;\n1  1999 -33.1 -63.8 W      163. R1    N5    yield        72.1\n2  1999 -33.1 -63.8 W      163. R1    N5    nitro       132. \n3  1999 -33.1 -63.8 W      170. R1    N5    yield        73.8\n4  1999 -33.1 -63.8 W      170. R1    N5    nitro       132. \n5  1999 -33.1 -63.8 W      168. R1    N5    yield        77.2\n6  1999 -33.1 -63.8 W      168. R1    N5    nitro       132. \n\n# Convert back from long to wide format using pivot_wider\nwide_data &lt;- long_data %&gt;% \n  pivot_wider(names_from = measurement, \n              values_from = value)\nhead(wide_data)\n\n# A tibble: 6 × 9\n   year   lat  long topo     bv rep   nf    yield nitro\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt;\n1  1999 -33.1 -63.8 W      163. R1    N5     72.1  132.\n2  1999 -33.1 -63.8 W      170. R1    N5     73.8  132.\n3  1999 -33.1 -63.8 W      168. R1    N5     77.2  132.\n4  1999 -33.1 -63.8 W      177. R1    N5     76.4  132.\n5  1999 -33.1 -63.8 W      171. R1    N5     75.6  132.\n6  1999 -33.1 -63.8 W      171. R1    N5     70.2  132.",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#separating-and-uniting-columns",
    "href": "coding/week_03/05_datawrangling_02.html#separating-and-uniting-columns",
    "title": "Transforming Ag data in R II",
    "section": "3.2 Separating and Uniting Columns",
    "text": "3.2 Separating and Uniting Columns\n\n# Example dataset with a combined column\nexample_data &lt;- data_corn %&gt;% \n  mutate(topo_year = paste(topo, year, sep = \"_\"))\n\n# Splitting 'topo_year' into two columns\nseparated_data &lt;- example_data %&gt;% \n  separate(topo_year, into = c(\"topo\", \"year\"), sep = \"_\")\nhead(separated_data)\n\n        lat      long yield nitro     bv rep nf topo year\n1 -33.05113 -63.84886 72.14 131.5 162.60  R1 N5    W 1999\n2 -33.05115 -63.84879 73.79 131.5 170.49  R1 N5    W 1999\n3 -33.05116 -63.84872 77.25 131.5 168.39  R1 N5    W 1999\n4 -33.05117 -63.84865 76.35 131.5 176.68  R1 N5    W 1999\n5 -33.05118 -63.84858 75.55 131.5 171.46  R1 N5    W 1999\n6 -33.05120 -63.84851 70.24 131.5 170.56  R1 N5    W 1999\n\n# Combining 'topo' and 'year' back into a single column\nunited_data &lt;- separated_data %&gt;% \n  unite(\"topo_year\", topo, year, sep = \"-\")\nhead(united_data)\n\n        lat      long yield nitro     bv rep nf topo_year\n1 -33.05113 -63.84886 72.14 131.5 162.60  R1 N5    W-1999\n2 -33.05115 -63.84879 73.79 131.5 170.49  R1 N5    W-1999\n3 -33.05116 -63.84872 77.25 131.5 168.39  R1 N5    W-1999\n4 -33.05117 -63.84865 76.35 131.5 176.68  R1 N5    W-1999\n5 -33.05118 -63.84858 75.55 131.5 171.46  R1 N5    W-1999\n6 -33.05120 -63.84851 70.24 131.5 170.56  R1 N5    W-1999",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#nesting-and-unnesting-data",
    "href": "coding/week_03/05_datawrangling_02.html#nesting-and-unnesting-data",
    "title": "Transforming Ag data in R II",
    "section": "3.3 Nesting and Unnesting Data",
    "text": "3.3 Nesting and Unnesting Data\n\nnested_data &lt;- data_corn %&gt;% \n  group_by(topo) %&gt;% \n  nest()\nhead(nested_data)\n\n# A tibble: 4 × 2\n# Groups:   topo [4]\n  topo  data                \n  &lt;fct&gt; &lt;list&gt;              \n1 W     &lt;tibble [1,043 × 8]&gt;\n2 HT    &lt;tibble [785 × 8]&gt;  \n3 E     &lt;tibble [730 × 8]&gt;  \n4 LO    &lt;tibble [885 × 8]&gt;  \n\nunnested_data &lt;- nested_data %&gt;% \n  unnest(cols = c(data))\nhead(unnested_data)\n\n# A tibble: 6 × 9\n# Groups:   topo [1]\n  topo   year   lat  long yield nitro    bv rep   nf   \n  &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;\n1 W      1999 -33.1 -63.8  72.1  132.  163. R1    N5   \n2 W      1999 -33.1 -63.8  73.8  132.  170. R1    N5   \n3 W      1999 -33.1 -63.8  77.2  132.  168. R1    N5   \n4 W      1999 -33.1 -63.8  76.4  132.  177. R1    N5   \n5 W      1999 -33.1 -63.8  75.6  132.  171. R1    N5   \n6 W      1999 -33.1 -63.8  70.2  132.  171. R1    N5",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#detecting-and-extracting-strings",
    "href": "coding/week_03/05_datawrangling_02.html#detecting-and-extracting-strings",
    "title": "Transforming Ag data in R II",
    "section": "4.1 Detecting and Extracting Strings",
    "text": "4.1 Detecting and Extracting Strings\n\nnames &lt;- c(\"Wheat Field\", \"Corn Field\", \"Soybean Farm\")\nstr_detect(names, \"Field\") # Check if 'Field' is present\n\n[1]  TRUE  TRUE FALSE\n\nstr_subset(names, \"Corn\") # Extract values containing 'Corn'\n\n[1] \"Corn Field\"",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#modifying-strings",
    "href": "coding/week_03/05_datawrangling_02.html#modifying-strings",
    "title": "Transforming Ag data in R II",
    "section": "4.2 Modifying Strings",
    "text": "4.2 Modifying Strings\n\nnames &lt;- str_replace(names, \"Field\", \"Plot\")\nnames\n\n[1] \"Wheat Plot\"   \"Corn Plot\"    \"Soybean Farm\"\n\ncapitalized_names &lt;- str_to_title(names)\nhead(capitalized_names)\n\n[1] \"Wheat Plot\"   \"Corn Plot\"    \"Soybean Farm\"\n\ndata_clean &lt;- data_corn %&gt;% \n  mutate(topo_clean = str_replace_all(topo, \"[^a-zA-Z0-9]\", \"_\"))\n\nhead(data_clean)\n\n  year       lat      long yield nitro topo     bv rep nf topo_clean\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5          W\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5          W\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5          W\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5          W\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5          W\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5          W",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#splitting-strings",
    "href": "coding/week_03/05_datawrangling_02.html#splitting-strings",
    "title": "Transforming Ag data in R II",
    "section": "4.3 Splitting Strings",
    "text": "4.3 Splitting Strings\n\nwords &lt;- \"Wheat,Corn,Soybean\"\nsplit_words &lt;- str_split(words, \",\")\nhead(split_words)\n\n[[1]]\n[1] \"Wheat\"   \"Corn\"    \"Soybean\"",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#reordering-factors",
    "href": "coding/week_03/05_datawrangling_02.html#reordering-factors",
    "title": "Transforming Ag data in R II",
    "section": "5.1 Reordering Factors",
    "text": "5.1 Reordering Factors\n\nlibrary(forcats)\ncrops &lt;- factor(c(\"soybean\", \"corn\", \"wheat\"), levels = c(\"wheat\", \"corn\", \"soybean\"))\ncrops &lt;- fct_relevel(crops, \"corn\") # Moves 'corn' to first position\nhead(crops)\n\n[1] soybean corn    wheat  \nLevels: corn wheat soybean",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#lump-rare-categories-together",
    "href": "coding/week_03/05_datawrangling_02.html#lump-rare-categories-together",
    "title": "Transforming Ag data in R II",
    "section": "5.2 Lump Rare Categories Together",
    "text": "5.2 Lump Rare Categories Together\n\nset.seed(123)\ndata &lt;- data.frame(crop = sample(c(\"corn\", \"soybean\", \"wheat\", \"barley\", \"oats\"), 20, replace = TRUE))\n\n# Using mutate() to lump rare categories together\nfactor_data &lt;- data %&gt;%\n  mutate(crop_lumped = fct_lump_n(crop, n = 3)) # Keep top 3 categories, lump others into 'Other'\nfactor_data\n\n      crop crop_lumped\n1    wheat       wheat\n2    wheat       wheat\n3  soybean     soybean\n4  soybean     soybean\n5    wheat       wheat\n6     oats       Other\n7   barley       Other\n8     corn        corn\n9  soybean     soybean\n10   wheat       wheat\n11    oats       Other\n12   wheat       wheat\n13   wheat       wheat\n14    corn        corn\n15  barley       Other\n16    corn        corn\n17    corn        corn\n18    oats       Other\n19   wheat       wheat\n20 soybean     soybean",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#extracting-date-components",
    "href": "coding/week_03/05_datawrangling_02.html#extracting-date-components",
    "title": "Transforming Ag data in R II",
    "section": "6.1 Extracting Date Components",
    "text": "6.1 Extracting Date Components\n\nyear(parsed_dates)\n\n[1] 2023 2024 2025\n\nmonth(parsed_dates)\n\n[1] 6 1 7\n\nday(parsed_dates)\n\n[1] 15 20  4",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_03/05_datawrangling_02.html#parsing-and-extracting-date-components",
    "href": "coding/week_03/05_datawrangling_02.html#parsing-and-extracting-date-components",
    "title": "Transforming Ag data in R II",
    "section": "6.2 Parsing and Extracting Date Components",
    "text": "6.2 Parsing and Extracting Date Components\n\ndates_corn &lt;- data_corn %&gt;% \n  mutate(date = ymd(paste(year, \"01\", \"01\", sep = \"-\")))\nhead(dates_corn)\n\n  year       lat      long yield nitro topo     bv rep nf       date\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5 1999-01-01\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5 1999-01-01\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5 1999-01-01\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5 1999-01-01\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5 1999-01-01\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5 1999-01-01",
    "crumbs": [
      "Lessons",
      "05-Data Wrangling II"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html",
    "href": "coding/week_02/03_versioncontrol.html",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "",
    "text": "Have you ever struggled with:\n\nMessy file versions? 📂 Naming files like code.R, code_final.R, code_final_final.R, codefinal3.R, or code_seethis.R? 🤯\nLost in email threads? 📧 Collaborating with colleagues by sending multiple file versions via email, leading to confusion and mistakes?\nUntracked changes? 🔄 Making edits but forgetting what changed and why?\n\nIf so, you’re not alone! These are common challenges in agriculture data science and research projects. Fortunately, Git and GitHub provide an efficient way to manage and collaborate on code without the chaos.",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html#install-git",
    "href": "coding/week_02/03_versioncontrol.html#install-git",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "5.1 1️⃣ Install Git",
    "text": "5.1 1️⃣ Install Git\nGit is a version control system that runs locally on your computer. To install it:\n\n📥 Download Git from git-scm.com\nFollow the installation instructions for your OS (Windows, macOS, Linux)\nOpen RStudio, go to the “Terminal” tab,\nVerify the installation by running this line:\n\ngit --version",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html#create-a-github-account",
    "href": "coding/week_02/03_versioncontrol.html#create-a-github-account",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "5.2 2️⃣ Create a GitHub Account",
    "text": "5.2 2️⃣ Create a GitHub Account\nGitHub is a cloud-based platform that stores your Git repositories online.\n\n🌍 Go to GitHub and sign up.\nSet up your GitHub profile and SSH key (optional but recommended for authentication).",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html#creating-a-github-repository",
    "href": "coding/week_02/03_versioncontrol.html#creating-a-github-repository",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "9.1 ✅ Creating a GitHub Repository",
    "text": "9.1 ✅ Creating a GitHub Repository\n\nOpen GitHub and click New Repository ➕.\nName the repository (e.g., my-first-repo) and choose Public or Private.\nClick Create Repository 🚀.",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html#creating-an-r-script-and-committing-changes",
    "href": "coding/week_02/03_versioncontrol.html#creating-an-r-script-and-committing-changes",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "9.2 📂 Creating an R Script and Committing Changes",
    "text": "9.2 📂 Creating an R Script and Committing Changes\n\nOpen GitHub Desktop and click Clone a Repository.\nSelect your repository and choose a local directory.\nOpen RStudio and create a new file named hello.R.\nAdd the following content:\nprint(\"Hello R world!\")\nSave the file and return to GitHub Desktop.\nYou should see the file listed under Changes.\nWrite a commit message (e.g., “Added hello.R”) and click Commit to main.\nClick Push Origin to upload the changes to GitHub.",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_02/03_versioncontrol.html#cloning-or-pulling-changes",
    "href": "coding/week_02/03_versioncontrol.html#cloning-or-pulling-changes",
    "title": "🌱 Getting Started with Git and GitHub for Ag Data Science",
    "section": "9.3 🔄 Cloning or Pulling Changes",
    "text": "9.3 🔄 Cloning or Pulling Changes\n\nIf you want to work on an existing repository, click Clone Repository in GitHub Desktop.\nSelect a repository and choose a local directory.\nIf changes have been made remotely, click Fetch Origin and then Pull Origin to update your local version.",
    "crumbs": [
      "Lessons",
      "03-Git & GitHub"
    ]
  },
  {
    "objectID": "coding/week_05/08_ggplot2_adv.html",
    "href": "coding/week_05/08_ggplot2_adv.html",
    "title": "Data Viz II",
    "section": "",
    "text": "Description\nIn this session, we’ll explore advanced visualization techniques using ggplot2, focusing on secondary axes, polygons for data segmentation, and mathematical annotations. These skills will help you create more dynamic and insightful visual representations.",
    "crumbs": [
      "Lessons",
      "08-Data viz II"
    ]
  },
  {
    "objectID": "coding/week_05/08_ggplot2_adv.html#explanation",
    "href": "coding/week_05/08_ggplot2_adv.html#explanation",
    "title": "Data Viz II",
    "section": "2.1 Explanation:",
    "text": "2.1 Explanation:\n\nPrimary Y-axis: Displays precipitation in mm.\nSecondary Y-axis: Converts temperature to °C using a conversion factor.\nAnnotations: Temperature and precipitation values are labeled for clarity.",
    "crumbs": [
      "Lessons",
      "08-Data viz II"
    ]
  },
  {
    "objectID": "coding/week_05/08_ggplot2_adv.html#explanation-1",
    "href": "coding/week_05/08_ggplot2_adv.html#explanation-1",
    "title": "Data Viz II",
    "section": "3.1 Explanation:",
    "text": "3.1 Explanation:\n\nannotate(\"rect\"): Creates colored polygons for each quadrant.\nLabels: Descriptive labels are added to clarify each region.",
    "crumbs": [
      "Lessons",
      "08-Data viz II"
    ]
  },
  {
    "objectID": "coding/week_05/08_ggplot2_adv.html#explanation-2",
    "href": "coding/week_05/08_ggplot2_adv.html#explanation-2",
    "title": "Data Viz II",
    "section": "4.1 Explanation:",
    "text": "4.1 Explanation:\n\nlm() fits a linear model to the data.\nannotate() displays the regression equation on the plot.",
    "crumbs": [
      "Lessons",
      "08-Data viz II"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html",
    "href": "coding/week_06/10_iteration.html",
    "title": "Iteration in R: The Power of purrr",
    "section": "",
    "text": "Description\nThis lesson explores iteration in R, focusing on the power of the purrr package for functional programming. We’ll compare traditional for loops with purrr’s map() functions to illustrate more efficient and readable approaches to iteration.\nRequired packages for today\nlibrary(pacman) # to install and load packages faster\np_load(dplyr, tidyr) # data wrangling\np_load(purrr) # iteration mapping\np_load(ggplot2) # plots\np_load(agridat) # data\np_load(nlme, broom.mixed, car, performance) # mixed models work\np_load(emmeans, multcomp, multcompView) # multiple comparisons",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#understanding-the-difference-between-map-and-map_dbl",
    "href": "coding/week_06/10_iteration.html#understanding-the-difference-between-map-and-map_dbl",
    "title": "Iteration in R: The Power of purrr",
    "section": "4.1 Understanding the Difference Between map() and map_dbl()",
    "text": "4.1 Understanding the Difference Between map() and map_dbl()\n\nmap_dbl() guarantees that the output is a numeric vector.\n\nSimilarly:\n\nmap_chr() returns a character vector.\nmap_lgl() produces a logical vector.\nmap_int() yields an integer vector.\n\n\nmap(), the most general form, returns a list by default.\n\nThese functions are part of an iterative approach where a function is mapped over elements of a list or vector.",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#practical-application",
    "href": "coding/week_06/10_iteration.html#practical-application",
    "title": "Iteration in R: The Power of purrr",
    "section": "5.1 Practical Application",
    "text": "5.1 Practical Application\nA common workflow involves combining group_by() and nest() to create nested data frames for iteration. You can then use mutate() along with map() to apply a function to each nested data frame:\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\n\ndata %&gt;%\n  group_by(group_variable) %&gt;%\n  nest() %&gt;%\n  mutate(results = map(data, your_function))\nThis approach is very powerful for applying custom functions to subsets of data efficiently.\nLet’s see that in practice…",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#load-the-data",
    "href": "coding/week_06/10_iteration.html#load-the-data",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.1 Load the data",
    "text": "6.1 Load the data\n\ndata_corn_00 &lt;- agridat::lasrosas.corn\nhead(data_corn_00)\n\n  year       lat      long yield nitro topo     bv rep nf\n1 1999 -33.05113 -63.84886 72.14 131.5    W 162.60  R1 N5\n2 1999 -33.05115 -63.84879 73.79 131.5    W 170.49  R1 N5\n3 1999 -33.05116 -63.84872 77.25 131.5    W 168.39  R1 N5\n4 1999 -33.05117 -63.84865 76.35 131.5    W 176.68  R1 N5\n5 1999 -33.05118 -63.84858 75.55 131.5    W 171.46  R1 N5\n6 1999 -33.05120 -63.84851 70.24 131.5    W 170.56  R1 N5",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#prepare-the-data",
    "href": "coding/week_06/10_iteration.html#prepare-the-data",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.2 Prepare the data",
    "text": "6.2 Prepare the data\n\ndata_corn_01 &lt;- data_corn_00 %&gt;% \n  # Select only necessary variables\n  dplyr::select(year, topo, rep, nf, yield) %&gt;% \n  # Group by\n  group_by(year, topo) %&gt;% \n  # Create nested data frames\n  nest(my_data = c(rep, nf, yield))",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#create-functions",
    "href": "coding/week_06/10_iteration.html#create-functions",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.3 Create functions",
    "text": "6.3 Create functions\n\n6.3.1 Rep (block) as fixed\n\n# SIMPLEST MODEL\nfit_block_fixed &lt;- function(x){\n  lm(# Response variable\n     yield ~ \n       # Fixed (treatment)\n       nf + \n       # Block as fixed too\n       rep,\n     # Data\n     data = x)\n}\n\n\n\n6.3.2 Rep (block) as random\n\n# RANDOM BLOCK (mixed model)\nfit_block_random &lt;- function(x){\n  nlme::lme(# Response variable\n    yield ~\n    # Fixed\n    nf,\n    # Random\n    random = ~1|rep,\n    # Data\n    data = x)\n  }",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#fit-models-with-mapping",
    "href": "coding/week_06/10_iteration.html#fit-models-with-mapping",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.4 Fit models with mapping",
    "text": "6.4 Fit models with mapping\n\nmodels &lt;- data_corn_01 %&gt;% \n  # BLOCK as FIXED \n  mutate(model_1 = map(my_data, fit_block_fixed)) %&gt;% \n  # BLOCK as RANDOM\n  mutate(model_2 = map(my_data, fit_block_random)) %&gt;% \n    \n  # Data wrangling\n  pivot_longer(cols = c(model_1:model_2), # show alternative 'contains' model\n               names_to = \"model_id\",\n               values_to = \"model\") %&gt;% \n  # Map over model column\n  mutate(results = map(model, broom.mixed::augment )) %&gt;% \n  # Performance\n  mutate(performance = map(model, broom.mixed::glance )) %&gt;% \n  # Extract AIC\n  mutate(AIC = map(performance, ~.x$AIC)) %&gt;% \n  ungroup()",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#model-selection",
    "href": "coding/week_06/10_iteration.html#model-selection",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.5 Model selection",
    "text": "6.5 Model selection\nCompare models performance\n\n# Visual model selection\nbest_models &lt;- \n  models %&gt;% \n  group_by(year, topo) %&gt;% \n  # Use case_when to identify the best model\n  mutate(best_model = \n           case_when(AIC == min(as.numeric(AIC)) ~ \"Yes\",\n                     TRUE ~ \"No\")) %&gt;% \n  ungroup()\n\n# Plot\nbest_models %&gt;% \n  ggplot()+\n  geom_point(aes(x = model_id, y = as.numeric(AIC), \n                 color = best_model, shape = best_model), \n             size = 3)+\n  facet_wrap(year~topo)+\n  theme_bw()\n\n\n\n\n\n\n\n# Final models\nselected_models &lt;- best_models %&gt;% dplyr::filter(best_model == \"Yes\")",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#run-anova",
    "href": "coding/week_06/10_iteration.html#run-anova",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.6 Run ANOVA",
    "text": "6.6 Run ANOVA\nEstimate the effects of factor under study\n\nmodels_effects &lt;- \n  selected_models %&gt;%\n  # Type 3 Sum of Squares (Partial SS, when interactions are present)\n  mutate(ANOVA = map(model, ~Anova(., type = 3)) )\n\n# Extract ANOVAS\nmodels_effects$ANOVA[[1]]\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: yield\n              Chisq Df Pr(&gt;Chisq)    \n(Intercept) 5729.92  1  &lt; 2.2e-16 ***\nnf           164.03  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodels_effects$ANOVA[[2]]\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: yield\n              Chisq Df Pr(&gt;Chisq)    \n(Intercept) 6089.64  1  &lt; 2.2e-16 ***\nnf           318.03  5  &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodels_effects$ANOVA[[3]]\n\nAnova Table (Type III tests)\n\nResponse: yield\n            Sum Sq  Df  F value    Pr(&gt;F)    \n(Intercept) 158985   1 7299.604 &lt; 2.2e-16 ***\nnf            1975   5   18.136 4.699e-16 ***\nrep            691   2   15.858 2.509e-07 ***\nResiduals     7841 360                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nmodels_effects$ANOVA[[8]]\n\nAnalysis of Deviance Table (Type III tests)\n\nResponse: yield\n                Chisq Df Pr(&gt;Chisq)    \n(Intercept) 18282.200  1  &lt; 2.2e-16 ***\nnf             72.431  5  3.194e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  },
  {
    "objectID": "coding/week_06/10_iteration.html#means-comparison",
    "href": "coding/week_06/10_iteration.html#means-comparison",
    "title": "Iteration in R: The Power of purrr",
    "section": "6.7 Means comparison",
    "text": "6.7 Means comparison\n\n# MULTCOMPARISON\n# emmeans and cld multcomp\n# We need to specify ourselves the most important interaction to perform the comparisons\nmult_comp &lt;- \n  models_effects %&gt;% \n  # Comparisons estimates (emmeans)\n  mutate(mc_estimates = map(model, ~emmeans(., ~ nf))) %&gt;% \n  # Assign letters and p-value adjustment (multcomp)\n  mutate(mc_letters = \n           map(mc_estimates, \n               ~as.data.frame( \n                 # By specifies a strata or level to assign the letters\n                 cld(., decreasing = TRUE, details=FALSE,\n                     reversed=TRUE, alpha=0.05,  adjust = \"tukey\", Letters=LETTERS))))\n\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons\nNote: adjust = \"tukey\" was changed to \"sidak\"\nbecause \"tukey\" is only appropriate for one set of pairwise comparisons",
    "crumbs": [
      "Lessons",
      "10-Iteration"
    ]
  }
]